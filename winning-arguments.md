# Winning Arguments

## Table of Contents

* [Acknowledgements](#acknowledgements)
* [How to use this text](#how-to-use-this-text)
* [Introduction: arguments and debates](#introduction-arguments-and-debates)
* [Games](#games)
* [Rules and laws](#rules-and-laws)
* [Winning](#winning)
* [Winning debates](#winning-debates)
* [Winning arguments](#winning-arguments-1)
* [Language](#language)
* [Statements](#statements)
* [Speech acts](#speech-acts)
* [Truth](#truth)
* [Epistemology](#epistemology)
* [Meaning](#meaning)
* [Rationality](#rationality)
* [Reasons](#reasons)
* [Logic](#logic)
* [Fallacies](#fallacies)
* [Biases](#biases)
* [Induction](#induction)
* [Probability](#probability)
* [Statistics](#statistics)
* [Beliefs](#beliefs)
* [Persuasion](#persuasion)
* [Paradoxes](#paradoxes)
* [Foundations of math](#foundations-of-math)
* [Faith](#faith)

## Acknowledgements

Morgan Thomas is the author. I am indebted to everybody whose work I have drawn upon here, who has done philosophy with me, whose philosophy I have read, or whose example has inspired me philosophically. They are too many to name, but they include (in no particular order) my parents Amy and Spencer Thomas; my sibling Esty; Lao Tzu; [JR](http://www.crazywisdomjournal.com/featuredstories/2014/8/22/the-crazy-wisdom-interview-with-jim-robert-of-pioneer-high-school); my friends Arian, Alexis, Thoi, Chloe, Becca, Graeme, Daniel S., Eric A., Khayree Billingslea, Isaac S.; Eliezer Yudkowsky; [Carla L. Rueckert, Don Elkins, and James McCarty](http://www.llresearch.org/aboutus.aspx); Ra; Aleister Crowley; various great Eastern mystics; the members of the Zen Buddhist Temples in Ann Arbor, MI and Tempe, AZ around 2010--2013; Crispin Wright; Graham Priest; Jc Beall; Michael Dummett; Nathan Kellen; Andrew Parisi; Hanna Gunn; Madiha Hamdi; Junyeol Kim; Teresa Allen; David Baldwin; Emma Björngard; Rasa Davidaviciute; Joel Hamkins; Alycia LaGuardia-LoBianco; Joseph Lurie; Colin McCollough-Benner; Tom Meagher; Dana Francisco Miranda; Jordan Ochs; David Pruitt; Nate Sheff; Andrew Tedder; Daniel Silvermint; Donald Baxter; Suzy Killmister; Mitch Green; Hallie Liberto; Bill Lycan; Michael Lynch; Edmund Husserl; Dave Ripley; Marcus Rossberg; Susan Schneider; Stewart Shapiro; Daniel Silvermint; Keith Simmons; Samuel Wheeler; Ruth Millikan; Immanuel Kant; Jean-Paul Sartre; Jordan Peterson; Paul Grice; Martin Heidegger; Ludwig Wittgenstein; Gottlob Frege; Bertrand Russell; Kurt Gödel; Damir Dzhafarov; Reed Solomon; Paul Grice; Paul Horwich; Alfred Tarski; Kurt Gödel; Douglas Hofstadter; Alan Turing; Joseph P. Foy; Michel Foucault; Alvin Plantinga; Clare Levijoki; Manolo Lago; Edmund Gettier; Grace Paterson; Gregg J.; Bethany B.; Jeremy W.; Kate S.; Luis Anderson; Richard Newton; Socrates; Plato; Aristotle; Stefan Molyneux; Sargon of Akkad; Tim Pool; Hal Kierstead; Brad Armendt; John Devlin; [Philosophical Overdose podcast](https://www.youtube.com/user/soultorment27); [The Partially Examined Life podcast](https://www.youtube.com/user/shinobirastafari); and many others, too many to name.

## How to use this text

You can use this text as a practical guide to winning arguments, to reasoning about any subject, to seeking the truth about any subject, and to misleading people about any subject.

The text is a philosophical study of language, reasoning, argumentation, and related topics, with the practical aim stated above. The same theories that explain how to win arguments on any subject also explain how to reason about any subject, how to seek the truth about any subject, and how to mislead people about any subject. The same knowledge can be used for any of these purposes, and it's up to the person who has it to use it responsibly.

The author advises the reader against the use of any techniques to deliberately mislead people, as the author believes misleading people almost invariably leads, in the long haul, to consequences more deplorable than what would have resulted if one told the truth.

The text contains exercises, which the author feels will be likely to further the reader's learning, and which the reader is encouraged to do when they feel they will further their learning. The greatest exercise, of course, is life, where you can fruitfully exercise the skills of reasoning, critical thinking, and argumentation you can learn in this text in almost any context of life.

This text is meant to be read from start to finish without skipping around. It is cumulative; each piece builds upon preceding pieces. In general you shouldn't expect to fully understand a part of the text unless you understand the text up to that point. 

For those who have not read much philosophy before, I apologize for the abstract, hair-splitting, and sometimes exhaustingly detailed and compact nature of the text, which will probably be a challenge for some people new to philosophy. I would like to offer some words of advice on how to read the text.

* Start out by reading one sentence at a time. Make sure you understand what each sentence is saying, before moving on to the next sentence. You can relax this rule if you're comfortable that you're following the text.
* If you understand what's being said but not why it's being said, you can just plow forward and imagine it will eventually become clear. I considered it too complex and distracting to try to explain, before each thing that's said, why it's being said. Therefore I ask for the reader's trust that they are being led on a purposeful path towards my understanding of winning arguments. If we take a shortcut through a strange, dark tunnel where the reader can only see two inches in front of their face, the reader is asked to take courage and keep their attention on those two inches.
* If there's a sentence or a section that's giving you too much difficulty, you can skip it.
* If you get totally lost and stop being able to follow what's being said, you can go back to the last point in the text up to which you're comfortable you've understood things, and re-read from there.
* If you come across a word you don't know, whose meaning you can't infer from context, then you should look up a definition for the word.
* If you come across a word whose meaning you don't understand in the particular context it's used, then look for a standard dictionary definition of the word and see if that fits.

To those who are new to philosophy, I recommend patience with the speed of one's understanding if it proves to try one's patience. Philosophical thoughts are usually developed by going over the same problems again and again over the course of years, and understanding philosophical writing often requires reading it multiple times and thinking about it over time.

In this text we will engage in an activity we call "conceptual analysis." Conceptual analysis is analysis of the meaning of words or concepts with the aim of clarifying their meaning and understanding it more deeply. In general, and in this text, conceptual analysis falls somewhere between the two poles of purely *descriptive* analysis, describing how various people have used a word or concept, and purely *prescriptive* analysis, defining a meaning for the term which the author uses and argues that readers should use.

Descriptive conceptual analysis is useful for uncovering the many layers of meaning that are often present in everyday terms. Prescriptive conceptual analysis, used judiciously, is useful for establishing clear communication and laying linguistic foundations that can be built on. A gentle and careful blending of descriptive and prescriptive conceptual analysis provides, in my experience, a powerful and versatile ingredient for philosophical argumentation. This text is or aims to be, among other things, a study in the method of conceptual analysis, and a large proportion of the text is conceptual analysis.

## Introduction: arguments and debates

Winning arguments is what I aim to show how to do in this text. I will show how this can be done by constructing winning arguments. As just illustrated, the phrase "winning arguments" has at least two important senses.

First, "winning arguments" can be interpreted to refer to an activity, the activity of winning arguments, where "argument" here is used in the sense of "debate."

Second, "winning arguments" can be interpreted as a noun phrase, where "argument" is used in the sense of "a series of statements designed to provide reason to believe some conclusion(s)." In this interpretation of the phrase, "winning" is an adjective, presumably meaning something like "persuasive."

A great deal of importance has been introduced in the preceding three paragraphs, so let's unpack the ideas further.

The first item of importance is the distinction between two senses of the word "argument."

Arguments in the first sense of the word are debates. By "debates," I mean exchanges of communication where participants discuss with each other the merits and demerits of some claims that they are mutually interested in and believe themselves to disagree about or are uncertain about.

Arguments in the second sense of the term are series of statements designed to provide reason to believe some conclusion(s). Henceforth, in this text I will consistently use the term "argument" to refer to arguments in this second sense, and I will use the term "debate" in order to retire the first sense of the term "argument."

Here is an example of an argument:

**(Question Science)** You shouldn't uncritically accept the conclusions of all scientific studies you come across. [Ioannidis (2005)](http://journals.plos.org/plosmedicine/article?id=10.1371/journal.pmed.0020124) is a scientific study which claims that most published research findings are false. If you should uncritically accept the conclusions of all scientific studies you come across, then you should accept Ioannidis (2005). But if you uncritically accept Ioannidis (2005), then you accept that most scientific studies draw false conclusions. That means you shouldn't uncritically accept the conclusions of all scientific studies you come across, because if you do, you can expect to be adopting a lot of false beliefs.

Let's analyze this argument, which I will refer to as Question Science. Question Science seeks to prove that you should not uncritically accept the conclusions of all scientific studies you come across. It proceeds by assuming for the sake of argument the opposite of what it seeks to prove, and deriving an absurd result. It assumes for the sake of argument that we should uncritically accept the conclusions of all scientific studies we come across, and ends by deriving the absurd conclusion that you should do something which will lead to you adopting a lot of false beliefs.

Let's step through the argument. We begin with the assumption for the sake of argument that you should uncritically accept all scientific studies you come across. The next move is based on the observation that if somebody thinks that way, you can make them believe anything that's said in a published scientific paper. The next move is to point out a paper, Ioannidis (2005), which will make us believe, under our sake-of-argument assumption, that most scientific studies conclude things that are false. This tells us that the thing we assumed we should do will lead us to hold many false beliefs. With the further assumption that we should not uncritically accept information that's likely to be false, we can refute the statement that we started out by assuming. In other words we can conclude that we should not uncritically accept the conclusions of all scientific studies we come across.

Question Science is an example of a *reductio ad absurdum* argument. A *reductio ad absurdum* argument, in a strict sense, is one that proceeds by assuming the negation of its conclusion, and deriving a logical contradiction thereby. In a looser sense, a *reductio ad absurdum* argument can derive, instead of a logical contradiction, an absurd consequence that will probably be unacceptable to the audience of the argument, leading the audience to reject the assumption that leads to that consequence.

Question Science is a *reductio ad absurdum* argument in the looser sense. In Question Science, we first assume the view we wish to refute, and with a modest amount of information and background assumptions, we get to the conclusion that our assumption will likely lead us to accept many false things as true, something which makes most people want to back out of the assumption.

Question Science is an example of a winning argument. I expect the reader agrees: it is hard to disagree with the reasoning, or the conclusion. I haven't encountered anybody who finds this argument unpersuasive. One reason the argument is so strong is the simplicity and effectiveness of its structure, which is based on the *reductio ad absurdum* idea that is the basis of many good arguments stretching back to ancient times.

Let's round out this discussion with an example of an argument which is a *reductio ad absurdum* in the strict sense: that is, an argument which proceeds by assuming the opposite of that which it seeks to prove, and deriving a logical contradiction from that assumption. As our example, we will do an informal version of the classic proof, due to Euclid, that there are infinitely many prime numbers.

**(Infinitude of Primes)** Recall that a prime number is a whole number greater than one which is divisible only by itself and one. Suppose, towards reaching a contradiction, that there are finitely many prime numbers. Let *x* be the number resulting from multiplying together all the prime numbers and adding one. Since *x* is evidently larger than all prime numbers, *x* is not prime. The fact that *x* is not prime means, by definition, that *x* is divisible by at least one prime number. Pick a prime number that *x* is divisible by, and call it *p*. We know that the remainder of dividing *x* by *p* is 0, since that's what it means for *x* to be divisible by *p*. However, we also know that the remainder of dividing *x* by *p* is 1, because of how we produced *x*. This is a contradiction, demonstrating that our original assumption was false, or in other words that there are infinitely many prime numbers.

Why is it true (as we said at the second to last sentence of the argument) that the remainder of dividing *x* by *p* is 1? We produced *x* by multiplying together all the (finitely many) prime numbers and adding one. Therefore *p* goes into (*x*-1) evenly, i.e. the remainder of the division (*x*-1)/*p* is zero, and therefore the remainder of the division *x*/*p* is 1.

Infinitude of Primes is another example of a winning argument. Mathematical theorems, like the theorem that there are infinitely many prime numbers, are extraordinarily uncontroversial. This can be explained at least in part by the statement that math is a game that has simple and essentially agreed upon rules. By describing math as a game, I do not mean to imply that math is not an activity of seeking truth. I don't mean to take any position in this text on whether or not math is an activity of seeking the truth.

Nonetheless, correct mathematical proofs are some of the best examples we have of winning arguments, due to their seemingly very reliable persuasive power.

We've dug a bit into the concept of arguments, in the sense of series of statements designed to provide reason to believe some conclusion(s). Let's now return to the distinction we made between debates and arguments.

Debates almost always involve the participants making arguments. Can arguments occur anywhere except in the context of debates? 

One place where you can find arguments is in books, especially non-fiction books. One can argue that an argument in a book is not in the context of any particular debate, because a book is an inanimate object that can exist in many copies in different places and times. Books are objects which are incapable of participating reciprocally in debates. You can, in a certain sense, let a book make arguments to you by reading it. You can also respond to the book's arguments, mentally, in your journal, to other people, to the author, etc. But the book cannot respond to your responses to its arguments. The author might be able to, if they're still alive, but that's another issue. This is what I mean when I say that books cannot participate reciprocally in debates. For these and many other reasons, you might say that arguments in books do not necessarily occur in the context of any debate, or perhaps that they never do.

Nonetheless, you might argue that arguments in books usually do occur in the context of some debate or another. This idea is palatable if we accept, as examples of debates, ongoing public debates. An ongoing public debate on a question, roughly, is a situation where lots of people make arguments on and have debates on the question, across a significant slice of space and time, probably across a region or the world for years. If you accept ongoing public debates as examples of debates, then you will probably accept that most arguments in most books occur in the context of some debate.

A possible exception to this generalization is the (hypothetical) case where somebody writes a book which makes arguments on a topic nobody else has discussed, and then nobody reads the book. In this case, you could for the sake of uniformity say that the book occurs in the context of a debate involving one person, the author. However, this might be odd to say because there seems to be something inherently interactive, social, multi-personal about debates. I think most people are going to be inclined to say that the arguments in this book do not occur in the context of any debate.

The possibility of such an exception to the generalization that arguments in books occur in the context of some debate makes more sense when we consider the plausibility of the idea that an argument in a book can occur in the context of multiple debates. For example, a single book about climate change can be involved in the overall public debate on climate change, while simultaneously being involved in many particular interpersonal debates about climate change, each occurring between a specific group of people together in one location in physical space or cyberspace. It seems reasonable to talk in this way and to say that the book is involved in multiple debates on one subject. If the number of debates a book is involved in can vary in number, then it seems only natural that the number could in principle equal zero, though that probably isn't common in reality.

So far we've reached three generalizations about the relationship between arguments and debates:

* Arguments usually occur in the context of debates.
* Debates usually contain arguments.
* Arguments can, in principle, occur outside the context of debates.

In my estimation, all of these points are important. That arguments usually occur in the context of debates, and debates usually contain arguments, tells us that arguments and debates are importantly related to each other and we need to understand them together. That arguments can, in principle, occur outside the context of debates tells us that arguments can be understood independently from debates (though it doesn't tell us whether that's the most useful way to understand them). It's probably not the case, on the other hand, that debates can be understood independently from arguments, since skilled debates are almost always in essence exchanges of arguments.

We will take both of the available approaches to understanding arguments. One can understand arguments either within the context of debates, or independently from debates. We will do both. Studying arguments outside the context of debates helps us focus in on arguments' intrinsic properties, and thereby understand arguments themselves much better. However, the perspective is unbalanced if we don't also study arguments in the practical context of debates as they occur in reality.

Hopefully that discussion of the relationships between debates and arguments has clarified for the reader the distinction between debates and arguments, as well as helping to clarify each concept individually.

Let's return to our original task of clarifying the meaning of the first three paragraphs of this Introduction. So far we've clarified the meanings of two critical words, "debate" and "argument." Yet many words of nebulous, dubious, or unclear meaning remain. First and foremost, "winning," but also (with the evident nebulousness, dubiousness or unclarity depending in part on where and how deep you've traveled into philosophy) "true," "reason," "believe," "persuasive," and "statement." Let's analyze the meanings of these words, starting with "winning."

What is winning? For starters, winning is most often something that happens to people in the context of games (chess, baseball, etc.).

Question: is winning something that ever happens to people *except* in the context of some game?

To make a start on what's going to be a highly roundabout answer to this question, let's consider the phrase "winning at life." Winning at life is a form of winning, at least on a surface inspection of the phrase. One can also hypothesize that "winning at life" is in some usages a phrase with its own particular meaning that doesn't decompose as winning in the context of life, in the same way that a "close shave" doesn't always refer to a shave that was close.

If winning at life is winning in the context of life, and winning only ever happens in the context of some game, then it follows that life is a game. So, then, is life a game? 

"Life is a game" is a truism, a statement that people are liable to spout as a form of shallow wisdom, perhaps without much reflection on how true it really is. How true is the truism? To answer that, we need to ask, what does the truism mean? To answer that, we need to ask, what do the words in the truism "life is a game" mean? "Life" seems to refer to human life, and probably it's clear enough what we're referring to there. What about "game?"

## Games

What is a game? Let's try to make a start on this question by identifying some things that are games, and also some things that are not games, which fail to be games in ways that are interesting and tell us something about games. A lot of the judgment as to which is which is going to be subjective, but the judgments on particular cases aren't in the end the important thing, but rather what's important is the general picture of games that emerges from the analysis.

Popular and typical examples of games include soccer, chess, poker, dice, solitaire, World of Warcraft, and slot machines. Childrens' games include [peekaboo](https://en.wikipedia.org/wiki/Peekaboo), [tag](https://en.wikipedia.org/wiki/Tag_(game)), [ring around the rosie](https://en.wikipedia.org/wiki/Ring_a_Ring_o'_Roses), and two people sitting on the ground and rolling a ball back and forth between each other. Unusual examples of games include [war games](https://en.wikipedia.org/wiki/Military_exercise), the [Olympic Games](https://en.wikipedia.org/wiki/Olympic_Games), [Roman gladiatorial combat](https://en.wikipedia.org/wiki/Gladiator), TV game or reality shows such as [The Celebrity Apprentice](https://en.wikipedia.org/wiki/The_Celebrity_Apprentice), [Chopped](https://en.wikipedia.org/wiki/Chopped_(TV_series)#Format), and [Lost](https://en.wikipedia.org/wiki/Lost_(game_show)), and abstract theoretical games like the [prisoner's dilemma](https://en.wikipedia.org/wiki/Prisoner's_dilemma) which are studied in [game theory](https://en.wikipedia.org/wiki/Game_theory). There's a whole category of more analogical usages of "game," such as the game of life, the game of capitalism, the game of courtship and romantic love, and the game of war.

By inspecting this list we can immediately state some generalizations that are not true about all games. Not all games are frivolous in purpose; some, such as war games, are serious in purpose. Even games that are superficially frivolous in purpose can be games where you're competing for your own life, as shown by the example of Roman gladiatorial combat. Non-lethal games can involve considerable stakes of money and glory, as exemplified in professional poker and in the Olympic Games.

Roman gladiatorial combat was a game played to entertain people. In that sense it was frivolous in purpose. But, it was gruesome, violent, lethal, and expensive, so presumably there was some significant reason people went to the trouble and difficulty of putting on the games.

One hypothesis I've heard is the following. Rome contained a large class of poor people who lived on welfare and therefore were not occupied with useful work, and it was found to be necessary to entertain them to prevent them from engaging in crime and disruption. If entertaining poor unemployed people to prevent them from causing disruption was the primary purpose of the games for some of the people who funded them, then certainly there was nothing frivolous about the games for those funders. For the people watching the games, the main purpose seems to have been entertainment.

Another hypothesis one can put forth is that the gladiatorial games embodied the Roman values of violence, domination, and heroism, and like most civilizations the Romans felt it was a worthwhile effort to put on events which could stand as monuments to their values. If we think of this as the primary purpose of the games, then one's inclined to say that the purpose is not frivolous, either for the funders or for the audience members.

If you think of the funders and the watchers of the Roman gladiatorial games as different sets of players in the game (expanding the conceptual boundaries of the game beyond the combat ring itself), one can venture that for the funders, the purpose of the games was often not frivolous, whereas for the watchers, the purpose of the games was most often the frivolous purpose of entertainment.

I am not asserting that any of these interpretations of the purposes of the Roman gladiatorial games are correct. However, each of these interpretations could (from a perspective of ignorance of relevant historical facts) be correct, and each one is a conceptually possible example of the purposes of a game.

The example of the Roman games illustrates the principle that a game can have multiple purposes, some explicit and some implicit, and different players in a game can have different purposes. The explicit purpose(s) of a game, being explicit, are typically apparent to all. In contrast, probably in most cases it's unclear to all or almost all observers of a game what all of the implicit purposes of the game are. This is because implicit purposes are, by definition, not stated, and since we can't read each other's thoughts we have no reliable way of knowing each other's unstated motivations.

Furthermore, people can be unaware of their own motivations. It is widely agreed, particularly among experts in psychology, that most of people's mental activity is unconscious, i.e. not witnessed or observed by their conscious minds. This view holds that among people's motivations for things they do, there are their unconscious motivations. Some argue that most or all things we do are influenced at least in part, or even mostly, by unconscious motivations.

This is not a psychology text, and we won't try to answer the question of in what ways and to what extent people's behavior is influenced by unconscious motivations. However, if the reader agrees that unconscious motivations exist, then we can say that a game may have an implicit purpose of which no observers have any awareness.

Given our limited access to our own minds, and our near lack of access to others' minds, it's clear why probably in most cases it's unclear to all or almost all observers of a game what all of the implicit purposes of the game are.

Let's now switch gears and poke at one of the more dubious examples I gave of a game, to see what we can learn about games in the process.

TODO: Explain prisoner's dilemma and address whether it's a game

Let's now switch gears again. Let's give some examples of things that are not games, which fail to be games in interesting ways that might tell us something about games.

Here's an example of a non-game: making toast. If you are a native English speaker: does it sound natural to describe making toast as a game? For me, the answer is that it does not sound natural. Making toast is not a game. It's some other kind of activity. Food preparation.

Here are some more examples of activities that are not usually called games: fixing your toaster; driving to work; working; sleeping; having sex; thinking; conversation; serving on a jury in a court of law; voting. People don't usually call any of these things games, and yet many of them have certain similarities to games. Serving on a jury and voting both have game-like qualities, being group activities governed by socially agreed upon systems of rules within which people make decisions in order to fulfill the objective of the activity (making a fair decision on the case being presented, or electing representatives and resolving plebiscites, respectively). Conversation, and language use in general, have many game-like qualities, being subject to many elaborate, largely unspoken rules. Game-like activities can be found strewn throughout life if you look for them.

One social norm that seems to apply across societies in general is that even if you are not playing a game that others are playing, you shouldn't violate the rules of their game. For example, if two people are playing chess, it would be against social norms probably anywhere in the world to move the pieces on their board, as a non-player in the game. One can say that games like chess are embedded within a larger meta-game or gamelike activity, the game of society, which has meta-rules like "don't break the rules of other people's games."

We have collected some examples and non-examples of games, and we have a substantial middle ground of things that arguably have both gamelike and non-gamelike qualities, including voting, serving on a jury, and, usually, working. Let's use this data to evaluate some possible generalizations about games.

**Do games always have rules?** Can we think of an example of a game that has no rules? Conversation, one might argue, is a game with no rules. In some sense this is true; people are free to say whatever they want. However, conversation does have many unstated norms that are usually not violated.

Paul Grice argued that participants in conversations usually follow certain [maxims](https://www.sas.upenn.edu/~haroldfs/dravling/grice.html). They are (to quote):

1. **The maxim of quantity**, where one tries to be as informative as one possibly can, and gives as much information as is needed, and no more.
2. **The maxim of quality**, where one tries to be truthful, and does not give information that is false or that is not supported by evidence.
3. **The maxim of relation**, where one tries to be relevant, and says things that are pertinent to the discussion.
4. **The maxim of manner**, when one tries to be as clear, as brief, and as orderly as one can in what one says, and where one avoids obscurity and ambiguity.

Obviously these rules are violated by speakers on a regular basis, but other speakers who perceive the violations of these rules tend to perceive them as social violations or imperfections in some sense. If one agrees with that, then one agrees in this sense that Grice's maxims are rules that speakers in conversations follow.

Every conversation will follow rules of grammar and prononunciation particular to the language(s) being used in the conversation. Further examples of kinds of rules conversations usually follow are rules of etiquette, rules about what things it is and is not appropriate to talk about in a particular context, rules about what words are unacceptable to say, and so forth. Therefore we can say, as a generalization, that conversations follow rules. Therefore we can say the game of conversation is not a counterexample to the claim that games always have rules.

Other possible counterexamples, so far as I'm aware, can be disposed of by thinking along similar lines. It looks to me like any appearance of a gamelike activity lacking rules is due to failure to look sufficiently broadly for rules governing the activity. In interpreting this statement, it should be understood that rules need not be inviolable to be rules.

When speaking English, people usually follow rules of grammar. Sometimes people violate the rules of grammar they normally follow. Different English speakers sometimes follow different rules of grammar. For example, African American vernacular English (AAVE) has different rules of grammar than standard American English. "He be comin" is grammatically valid AAVE, but not grammatically valid standard American English. People sometimes follow different linguistic rules in different contexts, as for example when a black person speaks AAVE with their family and standard American English at work. Following different linguistic rules in different contexts is called "code-switching."

Everybody has their own unique linguistic habits. Everybody pronounces words slightly differently, understands the meanings of words slightly differently, and so forth. Mostly these differences are too tiny to identify, but the fact that everybody differs slightly in how they produce and process language is illustrated for example by the fact that it is possible to identify people's voices and people's handwriting. Therefore one can say there are as many **idiolects** (variants specific to an individual) of a natural language as there are speakers of that language.

The foregoing illustrates that there is a great deal of complexity and inconsistency when it comes to rules of English grammar. We can still say as a generalization that English speakers, and speakers of every other language, follow the rules of grammar particular to their dialects most of the time when speaking. This illustrates the nuance that can apply when discussing the rules of gamelike activities. Rules of gamelike activities can be very flexible, granular, fluid, and invisible.

So far as our discussion has led us to be able to see, the generalization is true that **games and gamelike activities follow rules**. If there are exceptions to this generalization, they seem to be obscure.

The nature of rules is well worth exploring in more depth. However, for the moment I will delay that discussion. Let us now explore other possible generalizations about games.

**Are games always competitive?** The answer appears to be **no**. For some childrens' games, such as [peekaboo](https://en.wikipedia.org/wiki/Peekaboo) and [ring around the rosie](https://en.wikipedia.org/wiki/Ring_a_Ring_o'_Roses), it's difficult to see any sense in which they are competitive. However, most games are competitive in some sense. Even solitary games usually involve self-competition, trying to learn and do better.

**Are games always cooperative?** Any game which involves multiple people is cooperative in the sense that playing a game requires the players to agree to play the game (as opposed to doing anything else), to put effort towards its execution, and to abide by the rules of the game. Therefore we can conclude that multi-player games are always cooperative on some level, and usually competitive on another level.

Jordan Peterson made this point in one of his lectures for his course Maps of Meaning. He gave an example much like what follows. In a game of hockey, the members of each team cooperate with each other in their competition with the other team. In addition, the members of each team compete with their team members for position in the meritocracy of the team. Finally, all the players cooperate with each other in their agreement to play the game and in their execution of gameplay according to the rules. There are a number of different levels of cooperation and competition in this case.

In solitary games the obvious comment would be that there is no cooperation because cooperation requires multiple people. This is true in an obvious sense. However, it's also false in a less obvious sense, in that playing a game requires internal coordination on the part of a person. In order to play a game, a person has to coordinate many different parts of their mind and body, orchestrating their activities in such a way as to accomplish a single task. In the same sense, every activity whatsoever done by a person involves self-cooperation. One could fairly object that the concept of self-cooperation is an undue extension of the term "cooperation," and I will not press the point.

What conclusion are we led to about whether games are always cooperative? In this case we're led to **no single conclusion**. What we've said indicates that if self-cooperation is a form of cooperation, then games are always cooperative (as is every human activity), and on the other hand, if self-cooperation is not a form of cooperation, then games are not always cooperative. In addition, what we've said indicates that multi-player games are always cooperative.

What can we say overall about the meaning of the word "game?" On this, let's quote from Wittgenstein, in the Philosophical Investigations, part I, remarks 66-67:

"66. Consider for example the proceedings that we call "games". I mean board-games, card-games, ball-games, Olympic games, and so on. What is common to them all?—Don't say: "There must be something common, or they would not be called 'games' "—but look and see whether there is anything common to all.—For if you look at them you will not see something that is common to all, but similarities, relationships, and a whole series of them at that. To repeat: don't think, but look!—Look for example at board-games, with their multifarious relationships. Now pass to card-games; here you find many correspondences with the first group, but many common features drop out, and others appear. When we pass next to ballgames, much that is common is retained, but much is lost.—Are they all 'amusing'? Compare chess with noughts and crosses. Or is there always winning and losing, or competition between players? Think of patience. In ball games there is winning and losing; but when a child throws his ball at the wall and catches it again, this feature has disappeared. Look at the parts played by skill and luck; and at the difference between skill in chess and skill in tennis. Think now of games like ring-a-ring-a-roses; here is the element of amusement, but how many other characteristic features have disappeared! And we can go through the many, many other groups of games in the same way; can see how similarities crop up and disappear.

"And the result of this examination is: we see a complicated network of similarities overlapping and criss-crossing: sometimes overall similarities, sometimes similarities of detail."

"67. I can think of no better expression to characterize these similarities than "family resemblances"; for the various resemblances between members of a family: build, features, colour of eyes, gait, temperament, etc. etc. overlap and criss-cross in the same way.—And I shall say: 'games' form a family."




## Rules and laws

I have previously concluded that games always have rules. However, we have not discussed at any length what rules are. Understanding rules is quite central to understanding games, and to understanding the principles of winning arguments. To understand rules, it is also helpful to compare the meaning of the word "rule" with the meaning of the word "law." Since the terms are close in meaning, comparing and contrasting the meanings of the terms is informative about both. Therefore we will embark on a unified analysis of rules and laws.

There are many different laws and sets of laws of varying kinds, degrees, and scopes of importance and validity. Examples of laws (or at any rate things that people call laws) include: the [laws and regulations](https://en.wikipedia.org/wiki/Primary_and_secondary_legislation) of each [state](https://en.wikipedia.org/wiki/State_(polity)), [region](https://en.wikipedia.org/wiki/Administrative_division), [municipality](https://en.wikipedia.org/wiki/Municipality), and so forth; religious systems of law such as [sharia law](https://en.wikipedia.org/wiki/Sharia), the [Ten Commandments](https://en.wikipedia.org/wiki/Ten_Commandments) and [Talmudic law](https://en.wikipedia.org/wiki/Orthodox_Judaism); the laws of [physics](https://en.wikipedia.org/wiki/Physics), [chemistry](https://en.wikipedia.org/wiki/Chemistry), [biology](https://en.wikipedia.org/wiki/Biology), [statistics](https://en.wikipedia.org/wiki/Statistics), [logic](https://en.wikipedia.org/wiki/Logic), and [mathematics](https://en.wikipedia.org/wiki/Mathematics), and other fields of study which have produced laws; satirical laws like [Murphy's law](https://en.wikipedia.org/wiki/Murphy's_law) and [Godwin's law](https://en.wikipedia.org/wiki/Godwin's_law); sociological laws like [Duverger's law](https://en.wikipedia.org/wiki/Duverger's_law); mystical laws like the [law of attraction](https://en.wikipedia.org/wiki/Law_of_attraction_(New_Thought)) and the [Law of One](http://www.lawofone.info/synopsis.php); and so forth. 

[Examples of rules](https://en.wikipedia.org/wiki/Rule) (or at any rate things that people call rules) include, firstly, the rules of any game. Secondly, there are many rules (or things that people call rules) which are not literally rules of any game, such as: the [M'Naghten rules](https://en.wikipedia.org/wiki/M'Naghten_rules); the [right-hand rule](https://en.wikipedia.org/wiki/Right-hand_rule); the [five-second rule](https://en.wikipedia.org/wiki/Five-second_rule) and other [rules of thumb](https://en.wikipedia.org/wiki/Rule_of_thumb); [unspoken rules](https://en.wikipedia.org/wiki/Unspoken_rule); [rules of etiquette](https://en.wikipedia.org/wiki/Etiquette); rules of grammar; and rules of inference in logic (which we shall discuss at length later in the section titled Logic).

What kinds of things can follow rules? Clearly humans can follow rules. Systems of physical objects can follow rules, as for example all systems of medium-sized physical objects seem to follow the laws of Newtonian physics. Arguments can follow rules; for example, an argument can be logically valid, meaning it proceeds only according to logically correct rules of inference. Correct, fully detailed mathematical proofs are examples of logically valid arguments. In short, many things, human and non-human, can obey rules.

I am not aware of any counterexamples to the following generalization: all (things we ordinarily call) rules are defined and established by humans.

This generalization does not necessarily extend to laws. Many laws are clearly defined and established by humans, such as the laws of the legal systems of states, regions, and municipalities. Other laws, arguably, are not defined and established by humans:

* Though descriptions of physical theories such as Newtonian physics are products of humans, some would argue that Newtonian physics (or some hypothetical complete physical theory) is a description of laws of nature that exist objectively, independently of humans, regardless of whether we know about said laws. If laws of nature exist objectively, then they weren't established by humans.
* Many would argue that systems of religious law, such as sharia law or the Ten Commandments, were created by God and therefore not defined or established by humans.

In summary, some but arguably not all laws are defined and established by humans, whereas essentially all things people call rules are defined and established by humans, so far as the author knows.

There is some potential overlap between the categories of rules and laws. For example, the following statement seems fair: the laws of Newtonian physics are rules describing the motion of physical bodies. From that statement it follows that the laws of Newtonian physics are both rules and laws. If we accept that there are many (or in fact any) things which we can reasonably call both rules and laws, then it follows that there are no properties which all rules have and all laws lack, or vice versa.

Is every rule a law? Is every law a rule? "The laws of chess" and "the rules of the universe" are odd sounding phrases, probably, to most native English speakers. "The laws of chess" sounds odd, perhaps, because it suggests that the rules of chess have some quality of inevitability, whereas in fact people regularly play [variants](https://en.wikipedia.org/wiki/Chess960) [of](https://en.wikipedia.org/wiki/Three-dimensional_chess) [chess](https://en.wikipedia.org/wiki/List_of_chess_variants), cheat at chess, misunderstand the rules of chess, etc. "The rules of the universe" sounds odd, perhaps, because there's nothing we ordinarily call a rule that governs something as big and grand as the universe; only things we ordinarily call laws apply at this scale. These phrases, "the laws of chess" and "the rules of the universe," are still probably understandable in context, and they need not have the illogical connotations we have described for them, but they can refer simply to the rules of chess and the laws of the universe, respectively.

Our linguistic experiments suggest, firstly, that there is a delicate difference in meaning between "rule" and "law," and secondly, that there is a great deal of similarity in meaning between "rule" and "law."

The similarity in meaning between "rule" and "law" is so great that one hypothesis one might venture is that "rule" and "law" are essentially different words for the same concept, which we apply habitually to different kinds of things, without any deeper distinction existing. One way of describing the hypothesized vague, habitual distinction is to observe that laws are usually broad in their domain of applicability, whereas rules are usually narrow in their domain of applicability.

One objection to the view that "rule" and "law" are essentially the same concept is as follows. All things we habitually call rules seem to be made by humans. A qualifier to this is that rules can also be made by the creations of humans, as when computer programs generate rules for other programs to follow. Rules govern humans and the operations of the creations of humans. Laws, on the other hand, according to the objection, are not always created by humans, and sometimes they govern nature rather than humans or the creations of humans. If one accepts the foregoing, then one will acknowledge a substantive distinction between rules and laws.

For the sake of clear nomenclature, I will use the term "natural law" to refer to laws which are not created by humans. By definition, then, natural laws include any laws created by God, if God exists. I am not assuming that any natural laws exist, but we have a word for any that do exist (as well as any that don't exist).

The nature and extent of the difference in meaning between "rule" and "law" is, at the end of the day, a question of opinion. The subtleties of the distinction are interesting. What's perhaps more interesting, though, is looking more into the basic meanings of the terms "rule" and "law." 

It would be helpful towards that goal to establish more relations between "rule" and other terms we have studied. We have generalized that games and gamelike activities follow rules. Can we also generalize that rules occur in the context of games and gamelike activities?

Let's look back to the examples of rules we gave. Do all of them occur in the context of games or gamelike activities? Let's examine. The M'Naghten rules are rules for legal proceedings, which are a gamelike activity used to settle legal cases. The right-hand rule is a mini-game for remembering orientation conventions in 3D vector math. The five-second rule is a mini-game (lacking any factual basis) which we play to justify eating food off the floor. The [rule of 72](https://en.wikipedia.org/wiki/Rule_of_72) is a rule of thumb that one can employ in the gamelike activity of investment portfolio construction. One illustration that investment portfolio construction is a gamelike activity is that [a number of games](https://www.google.com/?q=stock+market+simulator) have been closely modeled after the activity of trading the stock market. Trading the stock market has, in turn, drawn comparison to gambling games such as poker.

Bearing in mind the flexibility of the concept "game or gamelike activity," it seems fair to generalize that rules occur in the context of games or gamelike activities. This generalization gives us further conceptual bearing for thinking about rules: we can always think about rules in the context of games or gamelike activities.

This generalization is violated by the statement "the laws of Newtonian physics are rules governing the motion of physical bodies," if we consider the laws of Newtonian physics to be objective features of nature rather than a human-constructed system for understanding nature. In other words, at least one of these four things is false:

1. Rules always occur in the context of games or gamelike activities.
2. The laws of Newtonian physics are objective features of nature rather than a human-constructed system for understanding nature.
3. The laws of Newtonian physics are rules.
4. Nature itself is not a gamelike activity.

If statements 1-3 are true, then we can conclude that nature itself is a gamelike activity, since if the laws of Newtonian physics are objective features of nature, then the context to which they apply is nature itself. If the laws of Newtonian physics are rules, then it follows that nature itself is a gamelike activity, in direct contradiction of statement 4. Hence, we are required by logic to reject at least one of statements 1-4.

All of these statements can be thought of as terminological rules. Statement 1 says that if we're willing to call something a rule, we should be willing to call its context a game or gamelike activity. Statement 3 says we should be willing to refer to the laws of Newtonian physics as rules. Statement 4 says we should not be willing to describe nature itself as a gamelike activity.

Statement 2 is a compound of a terminological rule and a statement about the world. We can think of it as a combination into one statement of the following two statements:

**Statement 2w:** There are objective laws of nature correlating to human-constructed descriptions of the laws of Newtonian physics.

**Statement 2t:** We should use the phrase "the laws of Newtonian physics" to refer to said objective laws of nature, as opposed to using the phrase "the laws of Newtonian physics" to refer to said human-constructed descriptions.

Statement 2w is a statement about the world, whereas statement 2t is a terminological rule.

For statement 2t to make sense, statement 2w must be true. If statement 2w is not true, then there are no objective laws of nature correlating to the laws of Newtonian physics, making "said objective laws of nature" in statement 2t unable to refer to anything.

One can accept statement 2w and reject statement 2t. If one neither accepts nor rejects statement 2w, if one maintains that one does not know whether or not statement 2w is true, one can still reject statement 2t.

My view is that I can't accept or reject statement 2w because I don't have the knowledge to say whether it's true or false. Why's that?

For starters, Newtonian physics is known to be correct only in restricted contexts and to a certain degree of approximation. Newtonian physics was formulated by inductive generalization from a certain body of phenomena, namely the motions of objects that can be seen with the naked eye. When it comes to very small objects, very large scale phenomena, very high speeds, very high energy levels, etc., Newtonian physics ceases to correctly predict our observations, and other theories, like quantum physics and general relativity, are required to get the right answers. Quantum physics and general relativity, in turn, have proven extremely difficult to unify into a single logically consistent theory explaining all observations. All of this suggests that Newtonian physics, as well as all existing theories, represent only our best current state of understanding. This casts doubt on the idea of assuming that the laws of Newtonian physics as described by physicists are direct correlates of objective laws of nature, rather than being human constructions that approximate the actual behavior of nature to a high degree of accuracy in a wide yet limited variety of cases.

Here is an additional reason to doubt statement 2w. As Kant has argued in the *Critique of Pure Reason*, we cannot have direct knowledge of the world outside ourselves. Our sense perceptions and experiences are constructions of our minds which are presumed to reflect an outside world through many layers of indirection, through processes such as light transmission, retinal stimulation, edge detection, object detection, associative cognition, etc. Our theories of the world are abstractions over our observations, i.e. generalizations over series of sense perceptions had by humans over time. Yet we have no direct observational knowledge that there was a past, that there is an external world, or that there are other minds; the only thing we observe directly is our own conscious experience in the present moment. Then can we, with intellectual fairness, assume that the outside world, a thing of which we have no direct experience, is made in the image of our models of the outside world?

Statement 2w is in doubt on multiple fronts, and probably many are not willing to assume it's true. Hence, we should not assume statement 2t makes sense. Hence, we should not follow it as a terminological rule. In other words, we should not understand the phrase "the laws of Newtonian physics" to refer to objective laws of nature correlating to the laws of Newtonian physics as described by humans.

Instead, in this text I will use the phrase "the laws of Newtonian physics" to refer to said human-constructed descriptions, or to the ideas those descriptions denote.

The same problem we have encountered with Newtonian physics occurs with other phrases that refer either to laws or nature or to human-constructed descriptions of supposed laws of nature. Examples of phrases presenting this problem include "the laws of general relativity," "the laws of quantum mechanics," "the laws of chemistry," "the laws of biology," etc. In all such cases, in this text we shall interpret the phrases as referring to human constructed descriptions of laws, or to the ideas expressed by those descriptions, and not to objective laws of nature. This is, as with the case of the laws of Newtonian physics, not an attempt to say that there aren't corresponding objective laws of nature (though many of the same difficulties with asserting positively the existence of such laws present themselves in other cases as well). It's simply a terminological choice driven by the desire not to take a position on what objective laws of nature exist.

This terminological choice collapses a substantive distinction in meaning we've seen between the terms "rule" and "law," namely that "law" can refer to laws of nature whereas "rule" seems to refer to the rules of humans. Under our sharpened terminology, the natural laws we know (the laws of physics, chemistry, etc.) are just a kind of rule. For example, the laws of Newtonian physics are the rules of the game of Newtonian physics. Newtonian physics is a gamelike activity that humans practice in order to build bridges, go to the moon, etc. Similarly for the rest of natural science.

Do any distinctions in meaning remain for us between "rule" and "law?" Let's consider the case of the laws of legal systems of nations, states, municipalities, etc., or "legal laws" as I shall say. Are legal laws rules? It seems natural to say so. By our principles, that means that legal laws are rules that apply in the context of some game or gamelike activity. The contexts that the laws of a legal system apply to are all situations in the jurisdiction of the legal system about which laws have been made in the given legal system.

In what ways are situations to which legal laws apply like games, and in what ways are they unlike games? Situations to which legal laws apply are always like games in the respect that in them one is required to follow rules. Since laws can be made about anything, situations about which there are legal laws can be arbitrarily non-gamelike. Let's ask, then, about the gamelike and non-gamelike characteristics of typical situations about which there are legal laws.

Let's start with violence. Most forms of violence are illegal in most jurisdictions. Violence is not a very gamelike thing. What laws against violence say is that one should never commit (covered forms of) violence. In other words, laws against violence require people to follow the rule of non-violence in most of their dealings. In what ways is non-violence like a game, and in what ways is it unlike a game?

Non-violence postulates certain rules, which vary depending on who you're asking. These rules usually amount to prohibitions on violating the bodies of other people, where violating the bodies of other people ranges from violations such as touching somebody without permission to violations such as mangling a person limb from limb. These rules serve the purpose of preventing people from being harmed and maintaining social cohesion by prohibiting interpersonal conflicts from escalating to the point of violence. Rules of non-violence are based on the observation, long validated by history, that violence almost always leads to consequences more deplorable than the problems it was trying to solve.

The following suggests itself: non-violence is part of the rules we follow in the game of society. On this way of thinking, society is a game humans play whose purposes include the survival and reproduction of the society and its members. Different societies are different games with different rules. However, all of the ones I'm aware of include rules against violence, because games of society accomplish their purposes better when such rules are instituted.

We can immediately generalize this answer as follows. Legal laws are among the rules of the social game that the members of a society play in order to constitute that society.

Thus far I have gotten rid of two distinctions between laws and rules. I have terminologically separated objective laws of nature out of usages of the term "law" in its unqualified usage. I have also categorized legal laws as rules (of the social games that members of a society play in order to constitute that society). Aside from the qualifier that objective laws of nature are obviously laws in some sense, can we draw any distinction between laws and rules within the terminological framework I have set up? It seems not; within this terminological framework, laws (in the unqualified sense) seem to be a type of rules in every case.

It still feels odd to speak of the "laws of chess." In the terminological framework we've arrived at, we have no substantive distinction between rules and laws, but there is still a distinction of habitual application of the two terms to different things. The laws of Newtonian physics are rules we are generally happy to call laws. The rules of chess, not so much. In general, we seem to apply the term "law" to rules that cover a larger jurisdiction than other rules.

Let's summarize what we've said about rules up to this point. Rules are defined and established by humans. Pretty much anything can follow rules. Games have rules, and rules occur in the context of games and gamelike activities. There is no substantive difference in meaning between "rule" and "law," understanding the unqualified term "law" to exclude laws of nature (but to include human-constructed descriptions thereof). Laws are a kind of rule, but the term "law" isn't applied to all rules, but only to certain rules whose jurisdictions are particularly wide.

So far we have established some relationships between rules and other things: rules are related to the humans who make them, the games they're part of, and the people and things that follow them. However, we have not yet examined in enough detail what rules are in themselves. What are rules?

It's not useful to answer this question by giving a dictionary definition of "rule." "Rule" is such a central, basic concept in human thought that explaining it in terms of simpler concepts is impossible. Instead, we need to explain what rules are in a much more indirect fashion, by examining the concept of rules, as it's used in practice, from many different angles.

Essentially any rule can be written in the form of a statement (possibly a very long one). The statement of a rule says what is true in the context of the rule if the rule is followed. When what the rule says isn't true, we say the rule has been broken.

Rules are of two types: **descriptive rules** and **prescriptive rules**. The statement of a descriptive rule states that empirically, the statement of a rule holds true. The laws of Newtonian physics are examples of descriptive rules. The statement of a prescriptive rule, on the other hand, states that people should choose to follow the rule. Legal laws are examples of prescriptive rules.

Anybody can state a descriptive rule. Descriptive rules can be correct or incorrect in a few different ways. If the statement of a descriptive rule is true in all cases, the rule is universally correct. If the statement of a descriptive rule is true in the great majority of cases, with rare exceptions, the rule is correct as a generalization. Descriptive rules that only hold in some cases are also interesting, but probably "rule" isn't the best word for them; maybe "pattern" is better. A descriptive rule is correct or incorrect regardless of who states it. There is no authority besides reality on what descriptive rules are correct.

Prescriptive rules work a little differently. Anybody can state prescriptive rules, but typically they need to persuade others to consent to follow them, which others are typically free not to do. Prescriptive rules are also made by various rule making entities with self-proclaimed and recognized authority based on consensus and/or force. Examples of rule making authorities include governments, international organizations like the UN and the EU, standards organizations like ISO and ANSI, and so forth.

Prescriptive rules can only be about human behavior. Descriptive rules can be about people or things, but descriptive rules about human behavior will never hold universally, because people have freedom of choice.

Dictionaries are examples of sets of descriptive rules about human behavior. Dictionaries describe the senses of words as most commonly used by English speakers. However, English speakers can and occasionally do use words in senses not described in dictionaries.

Dictionaries can also be thought of as sets of prescriptive rules, for example if you're of the opinion that people ought to spell words the way they're found in the dictionary, or if you're of the opinion that people ought to use words that are in the dictionary only in senses defined in the dictionary.

What is it that rules and laws do in the world? Rules and laws have effects. How can we describe their effects?

All laws bind us and/or the world, in some sense and at least in some cases. The sense in which laws are binding varies.

* The laws of physics are binding in the sense that physical theories generally postulate laws that always hold within their domain of applicability, so that any counterexamples would falsify the theory.
* Sociological laws like Duverger's law and Godwin's law are expected to have some counterexamples, and counterexamples are not necessarily considered to undermine the whole law. They are binding in the sense that they represent strong statistical trends that one tends to observe over time.
* The laws of governments are binding in the sense (and to the extent) that they can be enforced and offenses are punishable. Many consider the laws of governments to be binding in a moral sense in many cases. It seems to be a consensus among the people I speak to that laws of governments are not always binding in a moral sense, but I imagine this perspective is not shared by the whole world. For example, many Islamists undoubtedly would agree that sharia law is binding in a moral sense.
* Many believe in many cases that international law is binding on states in a moral sense. International law is binding in another sense (and to the extent) that it is enforceable and offenses are punishable, which varies widely from case to case.

I can't think of any counterexamples to the generalization that all laws are binding, to something in some sense in some cases. This, then, is one truism about laws which I will accept: all laws are binding.

TODO: Generalize to rules?

Let's try to study further the phenomenon of rules and laws binding phenomena. If we look at the phenomenon of binding, it seems to divide into two distinct subtypes: the case where the rules and laws are defined by a centralized authority with the ability to enforce rules/laws, and the case where there is no such centralized authority. Let us call these **authoritative binding** and **organic binding**, respectively.

The distinction between authoritative and organic binding is not sharp. In most cases, centralized rulemaking authorities have authority due to some level of consent/agreement to be ruled among the people who follow their rules. In many cases, there are varying levels of force used to enforce the authority of rulemaking authorities. In the case of governments, it seems they are generally able to rule only by a combination of general consent and the ability to use force.

The distinction between authoritative and organic binding is not the same as the distinction between descriptive and prescriptive rules. There are prescriptive rules which are authoritatively binding, like laws, and prescriptive rules which are organically binding, like standards of common decency. As far as I'm aware, there are no descriptive rules which are authoritatively binding; I think all descriptive rules are organically binding.

Prescriptive rules can be made authoritatively binding on people if one is able to use authority to instill sufficient fear in people of the consequences of breaking the rules that they follow the rules. Organic binding of prescriptive rules can also be based on fear, if people fear the consequences of breaking the rules, but not because they fear retribution by an authority. An example is the organically binding prescriptive rule "don't eat mushrooms you are unable to identify."

Prescriptive rules can also be organically binding on the basis of things other than fear. For example, rules of grammar are organically binding not as a result of fear, but mostly as a result of mostly-unconscious mental processes of language formation which follow rules of grammar in order to allow us to communicate more easily.

A prescriptive rule can be organically binding in a given social game if there is an approximation of a [Nash equilibrium](https://en.wikipedia.org/wiki/Nash_equilibrium) around following the rule. What I mean by this is, for essentially every player in the game, their incentives mean that they are better off following the rule, as long as those around them continue to follow the rule. In such a situation, people may violate the rule, but they generally experience consequences from doing so; others observe and anticipate those consequences; and as a result people generally follow the rule.

One simple kind of case of an approximate Nash equilibrium around following a rule is the kind of case where each player is individually better off following the rule, regardless of what others do. "Don't eat mushrooms you are unable to identify" is an example of a rule like this.

In other cases, whether people are better off following the rule depends on whether or not others follow the rule. For example, if others are working hard to get US dollars in your area, then you're probably better off if you work hard to get US dollars, so that you can buy things from all the people working for dollars in your area.

TODO

## Winning

Let's return to a question I asked a ways back. What is winning? Earlier I asked whether winning always happens to people in the context of some game. If true, this would be an interesting generalization that would let us apply the philosophy of games to understanding winning.

What seems to be the case is that **winning always occurs in the context of some game or gamelike activity**. "Game or gamelike activity" is, as we have seen, a very broad category, taking in things as disparate as soccer, capitalism, and life. For that reason, it's not a very strong claim to say that winning always occurs in the context of some game or gamelike activity. We'll assume this generalization going forward.

What is winning? Winning is some kind of condition which a player of a game, or a participant of a gamelike activity, can obtain or be in. Typically it's a condition defined by the rules of the game or activity. In typical cases, the conditions for winning are defined by the (explicit) rules of the game, and there is rarely question about whether and when somebody has won the game. However, these generalizations belie some complexities.

Consider, again, winning at life. Whether somebody is winning at life can only be said relative to some frame of evaluation.

For example, consider a person who amassed great wealth through ethically dubious yet legal means. From a straightforwardly capitalist point of view, one might say they were winning at life, because they are amassing wealth in the free market. From a Christian point of view, one might say they were not winning at life. This Christian judgment can be based on the belief that life is a game where the object is to seek the way of Christ, which the wealthy person in our example is not doing. These two frames of evaluation, capitalism and Christianity, provide two very different perspectives on whether the person of the example is winning at life.

Consider, as a further example, somebody who lived an impoverised life in a rural region of the world where they farmed, gained religious education, gained training as a warrior, and died young in combat. From some frames of evaluation, one could say this person had an underprivileged and ultimately oppressed life where their future as an individual was subjugated to the nonsensical needs of a national war machine. From some other frames of evaluation, one could say that this person led a virtuous and spiritual life which culminated in the honor of dying in a fight for that which is sacred. Again, each of these narratives provides very different conclusions as to whether this person is winning at life.

For any life you can describe, you can imagine multiple frames of evaluation which provide different conclusions about whether the liver of that life was winning. This is to say that facts alone are not sufficient to determine a judgment of winning at life or not winning at life. One also needs some additional ingredient, what I am generically calling a "frame of evaluation."

Winning at life, in this respect, is unlike winning at most games, in that fair observers will frequently disagree about whether somebody is winning at life, whereas for most games, fair observers will almost always agree about who the winner of the game is and whether there is a winner. This disanalogy is an interesting conceptual disconnect that seems worth working out, to see what can be learned.

The disanalogy reminds us of a question I asked a ways back and still haven't answered: is (human) life a game? 

Life is like a game in some ways. In life one must follow rules. In life there is winning and losing. Life is unlike typical games in that there is no privileged, official frame of evaluation for judging winning and losing at life.

"Life is a game" can be thought of as a terminological rule. It says, we should be willing to call life a game. I don't wish to assert or deny this prescriptive rule. I leave it up to the reader whether or not to call life a game.

Let's now dig further into the concept of frames of evaluation. The most practical application of frames of evaluation is the case where one adopts a certain frame of evaluation as a frame of evaluation one routinely and habitually applies to one's own life -- this we can call a value system -- and then one proceeds to attempt to win at life according to the standards of that frame of evaluation. Almost everybody does this to some extent.

People apply many different frames of evaluation to many different parts of their lives as their lives go on. These frames of evaluation generally evolve over time. Conflicts often exist, where different frames of evaluation applied simultaneously or at different times yield conflicting conclusions. This can lead to regret about past decisions, a sense of turmoil and inner conflict in one's present, etc.

If one wants to do something resembling winning at life, then it's useful to unify multiple conflicting frames of evaluation that one applies to one's life into a single frame of evaluation, which can and should evolve over time. The reason this is useful is that without a unified frame of evaluation to judge success and therefore guide decision making, one's decisions won't move one's life in a consistent direction, and rather than reaping the rewards that come from pursuing a well strategized life, one may instead drift about without ever finding lasting success.

This does not argue against drifting about for a time in life; this can be helpful for learning, self discovery, and so forth. It just argues that if one's interested in something resembling winning at life, then one should be interested in the pursuit of coherence in and the working out of contradictions between the frames of evaluation that one applies to one's life and one's choices, and in the eventual development of a philosophy and direction in life if one lacks those things in good measure.

We have analyzed the concept of winning at life at some length. Let's now turn back to the general concept of winning. To understand winning better, it would be interesting to have a theory of winning which might explain some of the confusing observations we've made, such as that there are so many different, incompatible frames of evaluation with which to judge winning and losing at life.

My theory of winning is as follows: **to win is to achieve a purpose one has in a game or gamelike activity**.

Typically, when one is explicitly declared the winner of a game, this means that one has won according to the rules of the game, or in other words that one has achieved the explicit purpose stated in the rules of the game. When one achieves an explicit purpose one has in playing a game, we'll call this **explicit winning**.

An example of explicit winning at life is the case where somebody publicly, explicitly declares their purpose(s) in life, and goes on to achieve said purpose(s). Life of course has no official rules and no official conditions for winning, but nonetheless it seems fair to refer to achieving one's purpose(s) in life as winning at life, and if those purposes are explicitly declared, then it is explicit winning.

When one achieves an implicit purpose one has in playing a game, this typically carries the feeling of victory, but if the purpose is implicit then the celebration will typically also be implicit, meaning in this case internal. We'll call achieving an implicit purpose in a game **implicit winning**.

In most cases, when we talk about winning, we're talking about explicit winning. However, it certainly seems that success in life is not predicated on others' awareness of one's intentions, so that it seems unreasonable to discount implicit winning as a form of winning.

We can think of many examples of implicit winning. One is playing chess with a potential romantic interest and accomplishing the implicit purpose of having meaningful and pleasant social interaction with them which increases the probability of future romantic success with them, perhaps in addition to the explicit purpose of winning the game. Another example of implicit winning is taking care of some financial chores and accomplishing the implicit purpose of increasing one's sense of financial confidence, in addition to the explicit purpose of refinancing one's debt or whatever it was. Another example of implicit winning is finishing a job at work and doing it well, accomplishing the implicit purpose of giving one's life purpose and giving oneself a reason for self-pride in a job well done, as well as the explicit purpose of fulfilling one's work obligations.

## Winning debates

Having analyzed the concept of winning, we can now shed more light on the concepts of winning arguments and winning debates. We are back where we were at the start of the Introduction, at my attempt to explain the meaning of the title, Winning Arguments.

In the first three paragraphs of the Introduction, we distinguished between two senses of "winning arguments," corresponding to two senses of "argument," i.e. "argument" in the sense of "debate," and "argument" in the sense of "a series of statements designed to provide reason to believe some conclusion(s)." We refer to the former as debates and the latter as arguments.

Thus, we have two concepts stated by the title, both of which we need to analyze: the concept of winning arguments, and the concept of winning debates. "A winning argument," we presumed, means essentially "a persuasive argument;" but a deeper conceptual analysis of the phrase remains to be done. "Winning debates" refers to the activity of winning in debates.

Let's start by digging deeper into the concept of winning debates. The phrase "winning debates" presupposes that debates are a kind of game or gamelike activity. Are they? Well, are debates like games? Let's ask some more questions that shed light on that.

Recall I defined debates to be "exchanges of communication where participants discuss with each other the merits and demerits of some claims that they are mutually interested in and believe themselves to disagree about or are uncertain about."

Are debates competitive? Typically so, as participants compete to persuade other participants of their point of view. Are debates cooperative? Yes, in the sense that to engage in a coherent debate, participants need to understand each others' statements and respond with relevant, appropriate statements.

Do debates follow rules? As I have noted before, participants in a debate are usually free to say whatever they want. As such there are no descriptive rules (about the speech of participants) that all debates can be observed to follow. Similarly, there is no rulemaking authority with the power to enforce prescriptive rules applying to all debates. In short, there are no rules that all debates follow. Nor do I have any reason to expect in the future that there will be such rules.

Debates can, however, be observed to follow rules. For example, the speech within debates generally follows rules of grammar and so forth. Other rules of interest applying to debates include rules of logic, rules of politeness and common decency, and other norms governing linguistic communication, such as [Grice's conversational maxims](https://www.sas.upenn.edu/~haroldfs/dravling/grice.html). As I have already observed, none of these rules are always followed in debates. However, they are often followed. Perhaps more interestingly, following these rules, along with various other widely accepted rules of language use and debate, tends to help one win debates. Why this is the case, and what it means to win debates, are questions that we haven't fully addressed, either in this text or as a species. 

Debates are evidently fairly gamelike. This renders palatable the usage of the phrase "winning debates." What is it to win a debate? I have said that to win is to achieve a purpose one has in a game or gamelike activity. Therefore, one can be said to win a debate if one achieves a purpose one has in it.

People can have many different purposes in a debate. Here are some examples of purposes that people can have in speaking in debates:

* To persuade others of a certain point of view on a topic.
* To determine the truth about a topic.
* To be included in the social group having the debate.
* To impress others with one's intelligence and rhetorical skill, and thereby increase one's social status.
* To blow off steam.
* To humiliate one's debate opponents.

Here are some examples of purposes that people can have in listening to debates:

* To learn about the topic and/or form one's opinion on it.
* To learn about the participants in the debate.
* To be included in the social group having the debate.
* To be entertained.

Debates can have a variety of different structures. The most common structure might be the **two-fixed-opposed-sides debate**, which has the following characteristics:

* Two positions are being debated.
* The two positions are (believed by the participants to be) incompatible with each other, meaning that one cannot coherently hold both positions at the same time. In a common special case, the two positions hold that a certain proposition is true or is false, respectively.
* The positions being debated do not change throughout the course of the debate.
* The side that each speaking participant is arguing for does not change throughout the course of the debate.

Another structure, which contrasts in interesting ways with the two-fixed-opposed-sides debate, is the **truth-seeking debate**, which has the following characteristics:

* An open-ended set of positions are being debated.
* Participants do not have any fixed outcome in mind for the debate and are prepared to change their minds as a result of the debate.
* Participants may change their positions at any time and as many times as they choose.
* Participants may refrain from holding a position.

There are, of course, going to be debates which fit neither of these descriptions. However, these two forms of debates seem to be some of the most common and workable debate structures. TODO: Explore other possibilities

These two structures have substantially different conditions for winning, because they have substantially different purposes. In the two-fixed-opposed-sides debate, generally the participants share the assumption that exactly one of the two positions is correct, and the condition for winning, as understood by the debate participants, is typically more or less to establish to the satisfaction of the observers of the debate that one's own side has the more persuasive arguments in its favor. The purpose of a two-fixed-opposed-sides debate is usually to establish dominance of one of the two positions over the other.

In a truth-seeking debate, the purpose and therefore the conditions for winning are quite different. The purpose is not to establish dominance of one position over another. Usually, the purpose is to arrive at a consensus that a certain position represents the truth on the topic of interest. If every participant's principal purpose was to reach such consensus, then when consensus is achieved, we can say that everybody has won, because everybody has achieved their principal purpose. On the other hand, if consensus is not reached, then we would probably say nobody has won, because nobody has achieved their principal purpose. In short, the goal of a truth-seeking debate is consensus rather than dominance, and in a truth-seeking debate everybody wins or doesn't win together, rather than one side winning and another losing.

The foregoing comments give us some idea of what it means to win debates. There are many different kinds of debates where different kinds of winning are possible, but we have at least a basic grip on that diversity at this point. Now we have fulfilled one of the first objectives I set in the introduction, which was to explain the phrase "winning debates."

Accomplishing the purpose(s) one has in a debate generally entails persuading others of a point of view, and/or exchanging ideas in a way which appears to move oneself and/or others closer to the truth. Arguments, certainly, are great not only as tools to persuade others of a pre-conceived point of view, but also and even more so as tools to explore conceptual space, acting as guides to move us forward towards the truth.

Speaking practically, I would say that the following two rules are the most important rules of winning debates:

**1. Be right.**

There is little it's better to have on your side in a debate than the truth.

The most important rule for winning debates is to **avoid getting into debates that you are going to lose in the first place.** If you'd like to build a reputation as somebody who speaks the truth, you should think before you speak and not get into debates that you are going to lose.

If you are just learning to win debates, that is basically the opposite of what you should do. If you are just learning to win debates, you would do well to be willing to get into any debate, defend any position, and not worry too much about being wrong. When you're learning to debate, just take advantage of opportunities to practice.

Skilled debaters still need to practice to stay skilled. However, skilled debaters probably have a highly developed skill of playing out debates in their head, and the amount of time they need to spend debating with others is likely to be reduced by their ability to practice and extrapolate hypothetical debate lines in their head. (Most people probably have debates in their head. However, inexperienced debaters probably won't be able to anticipate the arguments that would be leveled against their positions in a real debate.)

If you're going to debate people in a fixed-opposed-sides format, then you should make sure that your side is the one that is correct, and then you've taken the first step towards winning. If you're going to engage in a truth-seeking debate, just make sure that's also the purpose of your debate partners, and you don't need to worry about losing.

**2. Prepare.**

Many forms of preparation are required to be an impressive debater on a topic. One needs general facility with language and the techniques of debate. One needs background knowledge on the subject matter of debate. One needs a thorough knowledge of the various arguments for and against the position one wants to argue for. And it should be the case that taken all together, those arguments favor one's own position. This will always be a matter of judgment, and in many cases the best one can hope for is that the arguments will favor one's position in most people's judgment.

Even if you are well prepared, in a debate your debate partners will likely bring up arguments you didn't think of, and these arguments may create big problems for the view you entered the debate with. Hold great respect for what your debate partner knows that you don't know, because you don't know what they know.

We are usually overconfident that our current views are correct. When we notice our own overconfidence in our beliefs, we can over-correct and end up with under-confidence in what we know. Training away our overconfidence in our beliefs and finding a balanced degree of confidence in each belief that we hold is the work of a lifetime. Learning to quickly perform balancing of our confidence levels on the basis of a given information set is an important aspect of debate preparation.








## Winning arguments

What are winning arguments? Recall I defined an "argument" to be "a series of statements designed to provide reason to believe some conclusion(s)." I presumed that a winning argument is something like a persuasive argument.

Based on our prior conceptual analysis of "winning," we can state that a winning argument is, in general, an argument which wins in some sense and in some context, with the context being some form of game. Typically, the game is debate. Typically, a winning argument is one that wins in debates.

That tells us the "why" of winning arguments. The more interesting and more difficult question is "how." How do we construct winning arguments? The first step, and also in my opinion the hardest step, is learning how to discern between winning and non-winning arguments. In other words, the meat of the problem is to answer the "what" question. That is, what are winning arguments?

The "how" of constructing winning arguments is exactly what we aim to get at in this text. The text itself is concerned with theory, as opposed to the exercises, which are concerned with practice. The text is primarily concerned with the "what" question: what are winning arguments?

In the coming sections we will explore the "what" question in great depth. This is us laying groundwork for the theory of rhetoric. We will start by turning our attention to language, the very stuff of which arguments are made. To understand how to construct winning arguments, we must first understand our building material very well.

## Language

What is language? Language involves many different things and can be analyzed from many different perspectives. The next paragraph is an example that we'll use as a point of focus for introducing language.

Just before writing this sentence, I said the sentence "the dog runs." I said it out loud in my apartment. I heard myself, and as far as I know, nobody else heard me. As far as I know, my voice wasn't recorded in any medium. Anybody listening to my reading of this text will have been hearing statements that were referring to the written text and not to the recording they're hearing, until they got to this sentence. Anybody who read the preceding sentence in the written text will be reading a written sentence that talks about a corresponding spoken sentence that hadn't been said as of the time of its writing.

The preceding paragraph illustrates some interesting features of (natural) language, including that **(natural) language is multi-medial** and that **(natural) language is self-referential**.

When I say that natural language is self-referential, what I mean is that natural language can reference and discuss language. For example, this sentence talks about itself. Any sentence containing the phrase "this sentence" has the property of talking about itself.

When I say that (natural) language is multi-medial, what I mean is that language can exist in more than one medium. An English sentence like "the dog runs" can occur in spoken form, as vibrations in the atmosphere; in written form, as graphite or ink markings on a piece of paper; in written form, as bits stored on a computer hard drive; in written form, as light emanating from a computer monitor; in spoken form, as analog electrical signals traveling through an audio cable; in spoken form, as bits representing a digital audio signal traveling through a fiber optic network cable; and so on and so forth. I can think the sentence "the dog runs," and I can do so in different ways. For example, I can mentally recite the sentence to myself, and I can do so in different voices; or I can visualize the written sentence in my mind, and I can do so in different font styles. 

One interesting observation is that all of the items mentioned in the preceding paragraph can be called "the sentence 'the dog runs.'" E.g., "I wrote the sentence 'the dog runs' on a piece of paper," or "anybody listening to a digital audio recording of this paragraph will hear the sentence 'the dog runs.'"

There is a logical difficulty with saying that all of these different items literally are the sentence "the dog runs." Suppose for example that we accept the following premises:

1. *x* is a spoken sentence.
2. *x* is the sentence "the dog runs."
3. *y* is a written sentence.
4. *y* is the sentence "the dog runs."

From premises 2 and 4 we can infer that *x* is *y*, by the transitive property of the identity copula.

By the identity copula, I mean the word "is," used in the sense of "is one and the same thing as," as in the sentence "Earth is the third planet from the Sun," and the sentence "2+2 is 4."

The transitive property of the identity copula is the property that if *a* is *b* and *b* is *c*, then *a* is *c*. In this case, let *a* be *x*, *c* be *y*, and *b* be "the sentence 'the dog runs.'" In this case, the property states that if *x* is the sentence "the dog runs" and *y* is the sentence "the dog runs," then *x* is *y*. Of course 'is' is used in the preceding sentence in the sense of the identity copula, i.e. meaning "one and the same as."

The transitive property of the identity copula is perfectly analogous to the [transitive property of equality](http://www.mathwords.com/t/transitive_property.htm) in math. If you think that the = sign in math is simply a way of writing the identity copula, then these two properties are the same property.

Returning to premises 1-4, we have seen that they imply *x* is *y*, at least if we interpret the "is" in premises 2 and 4 as being the identity copula. But *x* is a written sentence and *y* is a spoken sentence. This contradicts the fact that no written sentence is a spoken sentence. This is the logical difficulty I wished to point to.

What this argument implies is that we cannot accept all of premises 1-4, interpreting "is" as the identity copula in premises 2 and 4 and assuming that the transitive property of the identity copula is a true principle about the identity copula.

Premises 1-4 are plainly true according to common sense and common ways of speaking, for appropriate values of *x* and *y*. As such, rejecting the idea that premises 1-4 are true for some *x* and some *y* is not an appealing option. Rejecting the transitive property of the identity copula also seems to be an unappealing option, because it as well seems obviously true. What's obviously false in this situation is that two different and distinct things, both of which we can call "the sentence 'the dog runs,'" are one and the same thing.

Common sense suggests that we should not interpret premises 1-4 in a way which leads immediately to a false conclusion. The remaining and most appealing way to do that is to interpret "is" in premises 2 and 4 as something other than the identity copula.

For example, "is" in premises 2 and 4 could be short for "is an instantiation of," so that premises 2 and 4 literally mean "*x* is an instantiation of the sentence 'the dog runs'" and "*y* is an instantiation of the sentence 'the dog runs.'" This gets rid of the logical contradiction. It is not the case that if *x* is an instantiation of *z* and *y* is an instantiantion of *z*, then *x* is *y*, unless *z* has only one instantiations. However, quite plainly, sentences can have multiple instantiations. However, quite plainly, sentences can have multiple instantiations.

This solution to the puzzle leaves us with a new puzzle: what is the sentence 'the dog runs?' Clearly we can point to many instantiations of the sentence 'the dog runs,' but the solution we're considering prevents us from saying that any instantiation (or at least more than one instantiation) of the sentence 'the dog runs' is itself the sentence 'the dog runs,' since that would bring us back into our logical contradiction. If none of the instantiations of the sentence 'the dog runs' are the sentence 'the dog runs,' then what is the sentence 'the dog runs?' Is it some sort of metaphysical entity, like a [Platonic form](https://en.wikipedia.org/wiki/Platonic_form), existing outside of space and time?

Another possible way of answering the puzzle is to deny that there is any object which we can literally call "the sentence 'the dog runs.'" The structure of English grammar certainly suggests that there is an object we can call "the sentence 'the dog runs,'" since "the sentence 'the dog runs'" is a noun phrase which can be used to construct infinitely many meaningful statements about this sentence. As such, this way of answering leaves me (and philosophers galore) rather confused about the meaning of phrases like "the sentence 'the dog runs;'" however, that doesn't make this way of answering wrong, and I'm not saying this way of answering is wrong.

This puzzle is one of a variety of logical puzzles that have to do with language's self-referential capabilities. One we will discuss at more length later is the liar paradox. This is the puzzle concerning the sentence "this sentence is false." Is the sentence true or false? You can reason that if it's true, then it's false, and if it's false, then it's true. The paradoxes of self-referencing language are hard. I will talk about them at greater length in the section titled Paradoxes.

Let us therefore turn back to unpacking the notion of language. Consider again the sentence "the dog runs."

Let's consider the sequence of events that occurs when I say "the dog runs." First, I form a mental intention to say the sentence. Then, my brain sends signals which cause a sequence of events to occur in my body.

My tongue is raised to touch my teeth, creating a barrier between the area above my tongue which is contiguous with my respiratory system, and the empty space inside my mouth which is contiguous with the outside atmosphere. My respiratory system pushes air out into my mouth, creating a pressure differential between these two areas. Because of its precise placement near my teeth, the tip of my tongue starts to vibrate against my teeth, creating a "th" sound. I suddenly open up a gap between my tongue and my teeth, releasing the pressure differential and completing the word "the." A similar sequence of physical occurrences completes the words "dog runs." All of this bodily motion is achieved in humans through a powerful and precise muscular system controlled by a sophisticated and fine-tuned nervous system.

These mechanical events in my body cause vibrations in the atmosphere, like waves in a pool of water, which propagate according to the rules of [fluid dynamics](https://en.wikipedia.org/wiki/Fluid_dynamics). Any objects in the nearby area of contiguous atmosphere are going to be disturbed by my speech, but usually only very slightly. Generally the effects will be entirely negligible, except on objects which are specially sensitive to sound vibrations, such as human ears and microphones.

The most interesting action happens when my speech irritates another human's ears while they are paying attention to it. This causes nerve signals to fire in their brain which cause them to have an experience of meaning whose content is partially controlled by precise variations in the patterns of sound vibrations I produce.

Spoken language that is intelligible to a listener is a very special kind of complex of sound vibrations. Only very specifically shaped sounds constitute language that is intelligible to a given listener. Intelligible language is like a psychoactive drug, in the following way. Psychoactive drugs affect the mental experiences of a person by being shaped in very specific ways which allow them to attach to neural receptors. Intelligible linguistic utterances affect the mental experience of a person by being shaped in very specific ways which allow them to attach to that person's inner mechanisms for synthesizing meaning.

The synthesis of meaning by processing language is a reaction between two things: a piece of language, and a person's psychology. A piece of language is a comparatively small, simple thing, whereas a person's psychology is an extremely complex thing. In addition, language is a highly observable and analyzable phenomenon, whereas human psychology seems to be mostly inscrutable (with all due respect to any psychologists who would disagree with this).

My statement that psychology is mostly inscrutable means that unlike in many other domains, humans have been unable to produce a body of psychological theory which provides a rigorous (e.g. mathematical) framework for modeling the psychological state of a person, or the features of their psychological state which are typically salient in problem-solving contexts, and allows for accurate forecasting of their likely behaviors.

Let's break that down slightly. Call a domain of inquiry "scrutable" if humans are able to produce a body of theory about that domain which provides a rigorous (e.g. mathematical) framework for modeling the states of objects in that domain, or the features of their states which are typically salient in problem-solving contexts, allowing for accurate forecasting of the objects' behaviors. Then my statement that psychology is mostly inscrutable means that mostly, it is not scrutable in the aforementioned sense.

This statement does not assume that humans' behaviors can be deterministically predicted; this may be practically or conceptually impossible, as far as I know. That's why I use the term "forecast," suggesting a method that would provide a probability distribution (or something of like that) of behaviors that a person is likely to exhibit looking forward in time, given their current psychological state and surrounding circumstances.

In any case, I have given a thesis about the limitations of present day knowledge of psychology. My thesis is not that it's impossible for individual humans to achieve an understanding of human psychology which allows them to model salient features of a person's psychological state sufficiently to predict their likely behaviors, and to do this with many people in many situations given sufficient information. My thesis describes a limitation on the psychological knowledge that in my judgment a person can straightforwardly gather from the available corpus of psychological research and pedagogy.

I do not assume all readers will agree that psychology is mostly inscrutable in the sense I have described, although to be honest I imagine most will agree or be willing to accept this thesis. Some of what follows depends on this thesis, and I have tried to make it clear when the argument I am making depends on the thesis that psychology is mostly inscrutable. The following paragraph is an example of a place where I invoke the thesis.

The (arguable) inscrutability of psychology infects all attempts to study linguistic meaning from a psychological perspective. It is debatable whether any totally non-psychological theory can justifiably be called a theory of linguistic meaning. However, many philosophers have advanced non-psychological theories of linguistic meaning. 

One prominent philosopher who advanced a non-psychological theory of linguistic meaning early in his career was Ludwig Wittgenstein. In his book the *Tractatus Logico-Philosophicus*, he gives a theory of meaning according to which language can be thought of as making pictures of the world, which could be expressed in a mathematically perfect logical language that is in some sense [isomorphic](https://en.wikipedia.org/wiki/Isomorphism) to the world. Apologies to the late Wittgenstein if I have misrepresented his view. The *Tractatus* gives a theory of linguistic meaning which entirely removes the subjects, the speakers and the listeners, from the issue, making meaning a relationship between language and the world, rather than a relationship between language and a subject. Later in his career, Wittgenstein repudiated this style of philosophy of language. His later studies of language, as represented in his *Philosophical Investigations*, evidence an appreciation for the importance of people, speakers and listeners, in the study of language and meaning. Later Wittgenstein, however, still largely shuns psychology, at least in my exposure to him. As far as I know, later Wittgenstein's primary focus in studying the language user is on behavior, and not on psychology.

A distinction that sheds light on some of the issues I have raised is the distinction between three types of linguistic meaning: sentence meaning, speaker meaning, and listener meaning. According to proponents of the concept of sentence meaning, every sentence has a **sentence meaning**, which is what that sentence means in itself according to the conventions of the language. In addition, every meaningful linguistic utterance has a **speaker meaning**, which is what the speaker meant by the utterance. Finally, whenever a listener listens to an utterance, there is a **listener meaning** specific to that listener, which is what it meant to them or what they thought it meant.

Proponents of the sentence meaning/speaker meaning distinction often think that the sentence meaning of a sentence can be determined by applying some sort of [recursive algorithm](https://en.wikipedia.org/wiki/Recursive_algorithm) over the grammar of the sentence, finding the meanings of the smallest meaningful fragments of the sentence (e.g. the words), and iteratively building up the meanings of larger sentence fragments until one has the whole sentence. Such analysis of meaning can be done with some variety of success on artificial formal languages, such as computer programming languages. The field of [formal semantics](https://en.wikipedia.org/wiki/Formal_semantics) is the modern successor of early efforts, such as Wittgenstein's, to develop concepts of sentence meaning along these lines.

Whether there is such a thing as sentence meaning for natural languages such as English is debatable. One can *define* notions of sentence meaning for simple, artificial languages with precise rules of sentence formation. However, nobody can give a *complete* definition of sentence meaning for English, because the complexity of English is vast and constantly increasing. If you wanted a definition of sentence meaning for English, I think you'd need to pay a whole team of philosophers to maintain and update it, and it wouldn't ever work for every English sentence. Moreover, if there were sufficient demand for such a definition of sentence meaning to fund such an enterprise, it's likely there would be multiple competing enterprises with conflicting definitions of English sentence meaning. The whole exercise would lack any clear point. In each case, what you'd get would arguable not be the one true notion of sentence meaning, but just that shop's opinion on how English sentence meaning should be defined. Thus if we imagine the scenario where we had an actual definition of sentence meaning for English, we are led to think that we would have more than one definition for the notion of sentence meaning for English.

Defenders of a single true notion of sentence meaning for English will probably have to say that the one true notion of sentence meaning is out there in the sky somewhere, never to be seen in full by us humans, and that people who pursue the concept of English sentence meaning must content themselves with doing their best to use reason to find the truth about English sentence meaning. It's unclear to me whether a descriptivist about English (by which I mean somebody who agrees that English has no centralized authority regarding rules of usage and at the end of the day people can use English however they want) can coherently maintain the position that there is a single true notion of English sentence meaning out there in the sky.

Probably most readers are skeptical of the idea that there is a single true notion of English sentence meaning. We are left with the possibility of multiple definitions or concepts of English sentence meaning. In addition, we are left with the concepts of speaker meaning (what speakers mean) and listener meaning (what listeners think speakers mean).

However, there is still a conventional notion of the conventional meanings of sentences that are sufficiently literal that they are not open to much variety of reasonable interpretation. Let us call this notion **the conventional notion of literal sentence meaning**.

"The conventional notion of literal sentence meaning" does not refer to one exactly defined notion of sentence meaning. Rather, the phrase is open to interpretation, and its meaning will vary according to context and according to the views of the participants in a conversation where the phrase is used. The phrase can be used in conversations where it serves a useful purpose in advancing the conversation. The phrase can be used in a conversation if participants in the conversation are sufficiently comfortable with using the phrase and they are comfortable that a shared understanding of the phrase exists which is sufficiently robust to solve the conversational problems at hand.

I will discuss meaning more extensively in the section titled Meaning. 

Speaking very broadly, there are three big things to study about language: syntax, semantics, and pragmatics.

**Syntax**, as I shall define it, is the study of language in itself, i.e. the study of the physical artifacts and phenomena which we call language: the spoken word, the written word, and so forth. The field of syntax doesn't study the people who use language; it just studies and forms theories of the structure of linguistic utterances and artifacts themselves.

**Semantics**, as I shall define it, is the study of the meaning of language. As we have seen in our discussion so far, and as we will see some more in the section titled Meaning, linguistic meaning is a highly difficult and opaque topic, presenting deep intellectual challenges.

**Pragmatics**, as I shall define it, is the study of language in the context of its usage by people.

These three fields are probably not entirely disjoint, and they don't cover everything there is to discuss about language. (There is the history of language, and the biology of language, for example.) However, they are a good way of subdividing the space of topics related to language that we are going to cover. More broadly, the mature philosophical approaches to studying language that I'm aware of are subsumed under these categories. 

The preceding paragraphs serve as an extremely high-level introduction to some of the central issues in the philosophy of language and to the study of language as a whole. In the rest of this text we will focus our study of language into specific topics which directly pertain to winning arguments. The reader is encouraged to learn every important lesson they can about language. If one learns to use language well, there is a great deal one can do with that.

## Statements

The first three paragraphs of the Introduction explained the meaning of the title, and the entirety of the text since then has been an attempt to explain the meaning of the first three paragraphs of the Introduction:

> Winning arguments is what I aim to show how to do in this text. I will show how this can be done by constructing winning arguments. As just illustrated, the phrase "winning arguments" has at least two important senses.
>
> First, "winning arguments" can be interpreted to refer to an activity, the activity of winning arguments, where "argument" here is used in the sense of "debate."
>
> Second, "winning arguments" can be interpreted as a noun phrase, where "argument" is used in the sense of "a series of statements designed to provide reason to believe some conclusion(s)." In this interpretation of the phrase, "winning" is an adjective, presumably meaning something like "persuasive."

Back in the Introduction, I gave a series of words from the first three paragraphs that needed explanation:

> Let's return to our original task of clarifying the meaning of the first three paragraphs of this Introduction. So far we've clarified the meanings of two critical words, "debate" and "argument." Yet many words of nebulous, dubious, or unclear meaning remain. First and foremost, "winning," but also (with the evident nebulousness, dubiousness or unclarity depending in part on where and how deep you've traveled into philosophy) "true," "reason," "believe," "persuasive," and "statement." Let's analyze the meanings of these words, starting with "winning."

We've done our analysis of "winning," but the rest of these words remain to be analyzed: "true," "reason," "believe," and "statement." In this section we shall analyze the word "statement."

What is a statement? A statement is a kind of sentence. Here are some dictionary definitions of "statement" that I looked up on Google:

* a definite or clear expression of something in speech or writing.
* an official account of facts, views, or plans, especially one for release to the media.
* a formal account of events given by a witness, defendant, or other party to the police or in a court of law.

In this section I am interested in statements in the sense (somewhat crudely expressed by this definition, in my opinion) of "a definite or clear expression of something in speech or writing."

The study of winning arguments is mostly a study of statements and the relationships between statements. Therefore, we should take care to develop a good understanding of statements.

Logicians frequently provide various definitions of the word "statement." In this text, I shall use the following definition of the word "statement." **A statement is a sentence which can be believed or disbelieved.** This definition picks out a certain wide class of sentences, spanning across all natural languages and many formal languages. This class probably agrees in essential intent, if not in actual [extension](https://en.wikipedia.org/wiki/Extension_(semantics)), with most modern logicians' definitions of "statement."

Here are some examples of statements:

* I am cold.
* This is a pen.
* It is early in the morning.
* After we harvest the wheat we will store it in the silos.
* Within the lives of others we can find some of the most important insights about ourselves.
* Every statement is either true or false.
* If the axioms of math can prove themselves to be incapable of proving any statement about numbers to be both true and false, then the axioms of math can prove any statement about numbers.
* 2+2=4.
* 2+2=5.

Here are some examples of sentences that are not statements:

* Why am I cold?
* Get over here!
* Fuck you!
* Help!

"Why am I cold?" is a question. "Get over here!" and "help!" are imperative sentences. An [imperative sentence](https://www.thoughtco.com/imperative-sentence-grammar-1691152) is "a type of sentence that gives advice or instructions or that expresses a request or a command." "Fuck you!" can be literally interpreted as an imperative sentence (telling the target to fuck themselves). However, "fuck you!" is perhaps better thought of as an [ejaculation](https://en.wikipedia.org/wiki/Ejaculation_(grammar)). Clearly, none of these sentences can be believed or disbelieved. For example, I make no sense if I say, "I believe that why am I cold?" or "I believe that fuck you!" Since they can't be believed or disbelieved, "why am I cold?" and "fuck you!" are not statements; similarly with "help!"

Statements, like other sentences, tend to follow rules of grammar. Rules of grammar vary between languages, but there are various common themes. The full complexity of grammar is manifest in the grammar of statements. The grammar of statements, which is the study of grammar minus the grammar of non-statement sentences, is an interesting study in its own right. In addition, an understanding of the grammar of statements is important background knowledge for what follows. Therefore, our next step in understanding statements is to embark on a study of the grammar of statements.

There are many approaches to the study of grammar. Indeed, there are a number of different kinds of grammatical theory of note:

* A **natural language grammar** attempts to describe the grammar of a natural language.
  * A **descriptive natural language grammar** attempts to describe the rules of grammar actually followed (in ordinary cases) by some population of language speakers.
  * A **prescriptive natural language grammar** defines the rules of grammar that some population of speakers should use, at least according to the author(s) of the grammar.
* A **formal grammar** exactly describes the grammar of an artificial language, a so-called **formal language**. Formal grammars are usually written in notation with precise, formal meaning, which renders it entirely unambiguous what does and does not constitute valid syntax for a statement of the formal language.
* A **theory of grammar** is a theory which says something about grammars as a whole, or about some restricted class of grammars. For instance, if one wishes to explain the concept of formal grammars in a thorough way, then this requires a theory of formal grammars. The [Chomsky hierarchy](https://en.wikipedia.org/wiki/Chomsky_hierarchy) is an example of a precise theory of formal grammars, explaining what a formal grammar is and categorizing them according to how computationally difficult it is to parse statements in them.

There is a lot of interesting stuff to unpack here. Let's start by learning a simple formal language of statements. We're going to explain how to write statements in a toy language whose only sentences are statements. This language is called **(the language of) first-order logic**. First-order logic is notable in that it has an extremely simple grammar, and essentially any statement can be expressed in first-order logic.

Our presentation of first-order logic is notationally different from most other presentations of first-order logic, in that I opted to use English words in place of logical symbols, making the notation more naturally readable for English speakers, but less compact.

In essence the version of first-order logic I present should be equivalent to all other presentations of first-order logic, despite interesting differences. The reader can, as an exercise, find another presentation of first-order logic and find for themselves the reasons why that system is for all intents and purposes interchangeable with ours, despite their differences. Our presentation differs in tricky ways (as well as simple ways) from most presentations of first-order logic, so that this can be an interesting exercise for a student of mathematical logic.

Here are some examples of statements in our version of first-order logic:

* (*a* is a dog)
* ((*a* is a dog) and (*a* runs))
* (for all *a*, (if (*a* is Santa Claus) then (*a* is a North Pole inhabitant)))
* (for all *a*, (if (*a* is a person) then (for some *b*, ((*b* is a person) and (*b* loves *a*)))))

As you can see, these statements look a lot like statements in English, but not quite. Let's go through the rules that define the grammar of this language.

There are the following kinds of words in (our presentation of) first-order logic: variable names, object literals, predicates, [copulas](https://en.wikipedia.org/wiki/Copula_(linguistics)#English), such as verbs, and connective words.

* For **variable names** I will use single italicized lower case letters: *a*, *b*, *c*...
* For **object literals** I will use English phrases denoting objects, e.g. "the President of the United States" or "this chicken." The latter example illustrates that English phrases denoting objects can be context-sensitive in meaning.
* For **predicates** I will use upper case letters (P, Q, R, ...) and ordinary English phrases denoting categories of objects, specific objects, or properties (e.g. "a dog," "the President of the United States," "clean").
* For **copulas** I will use ordinary English copulas, e.g. "loves" TODO more examples
* The following are all the **connective words:** **if**, **then**, **and**, **or**, **not**, **for**, **all**, **some**, **is**.

An **object term** (of our presentation of first-order logic) is a variable name or an object literal. In other words an object term is any piece of syntax that can denote an object.

We will also need notations for variables ranging over different types of words:

* When we need a variable that ranges over object terms, i.e. an *object meta-variable*, I will use bolded lower case letters starting with "a": **a**, **b**, **c**, ...
* When we need a variable that ranges over predicates, i.e. a *predicate variable*, I will use bolded upper case letters starting with "P": **P**, **Q**, **R**, ...
* When we need a variable that ranges over statements, i.e. a *statement variable*, I will use bolded upper case letters starting with "A": **A**, **B**, **C**, ...
* When we need a variable that ranges over copulas, I will use a bolded lower case **v**.

A **lexical unit** (of our presentation of first-order logic) is a word, a parenthesis, or a comma.

A **statement** (of our presentation of first-order logic) is any sequence of lexical units which can be formed according to the following rules:

1. If **a** is an object term and **P** is a predicate, then (**a** is **P**) is a statement.
3. If **a** is an object term and **v** is an [English copula](https://en.wikipedia.org/wiki/Copula_(linguistics)#English), such as a verb, then (**a** **v**) is a statement.
4. If **a** and **b** are object terms and **v** is a verb, then (**a** **v** **b**) is a statement.
5. If **A** is a statement, then (not **A**) is a statement.
6. If **A** is a statement and **B** is a statement, then:
    * (if **A** then **B**) is a statement.
    * (**A** and **B**) is a statement.
    * (**A** or **B**) is a statement.
7. If **A** is a statement and **a** is a variable name, then:
    * (for all **a**, **A**) is a statement.
    * (for some **a**, **A**) is a statement.

Let us show how these grammar rules can be used to derive the examples I gave above of statements:

**(*a* is a dog) is a statement.**

* *a* is a variable name.
* "a dog" is a predicate (denoting a category).
* By rule 1, (*a* is a dog) is a statement.

**((*a* is a dog) and (*a* runs)) is a statement.**

* *a* is a variable name.
* "runs" is a verb, and therefore a copula.
* By rule 2, (*a* runs) is a statement.
* (*a* is a dog) is a statement (see above).
* By rule 6, ((*a* is a dog) and (*a* runs)) is a statement.

**(for all *a*, (if (*a* is Santa Claus) then (*a* is a North Pole inhabitant))) is a statement.**

* *a* is a variable name.
* "Santa Claus" is a predicate (denoting an object).
* By rule 1, (*a* is Santa Claus) is a statement.
* "a North Pole inhabitant" is a predicate (denoting a property).
* By rule 1, (*a* is a North Pole inhabitant) is a statement.
* By rule 6, (if (*a* is Santa Claus) then (*a* is a North Pole inhabitant)) is a statement.
* By rule 7, (for all *a*, (if (*a* is Santa Claus) then (*a* is a North Pole inhabitant))) is a statement.

The reader should understand the foregoing to the extent that they can produce an unlimited number of statements in first-order logic; produce for each of them derivations conforming to the pattern I have demonstrated; and distinguish between valid and invalid syntax for statements of first-order logic.

The reader should also understand what statements in first-order logic mean. For the most part, this may be fairly self-evident, but it is worth taking a moment to clarify explicitly what each form of statement means:

* (**a** is **P**) means that whatever object the object term **a** denotes in the current context satisfies the predicate **P**, or in other words has the property **P**, belongs to the category of objects **P**, or is the object **P**.
* (**a** **v**) and (**a** **v** **b**), where **v** is an [English copula](https://en.wikipedia.org/wiki/Copula_(linguistics)#English), such as a verb, and **a** and **b** are object terms, means that the corresponding English statement is true for whatever object(s) the object term(s) **a** and **b** denote in the current context.
* (**A** and **B**) means that **A** and **B** are both true.
* (**A** or **B**) means that at least one of **A** or **B**, and possibly both, are true. The "or" in first-order logic is therefore an *inclusive or*. This can be distinguished from an *exclusive or*, which differs from an inclusive or in that an exclusive or is false when both disjuncts are true. That is, an exclusive or requires exactly one of its disjuncts to be true, as opposed to at least one as with inclusive or.
* (not **A**) means that **A** is not true, or that **A** is false, depending who you ask. Whether "not true" and "false" are different properties also depends who you ask.
* (if **A** then **B**) means that if **A** is true, then **B** is true.
* (for all **a**, **A**) means that in any variant on the current context created by setting the object denoted by the variable **a** to some object, **A** is true.
* (for some **a**, **A**) means that in at least one variant on the current context created by setting the object denoted by the variable **a** to some object, **A** is true.

Many connective words/phrases have conventional names:

* **and** is called **conjunction**. A statement of the form (**A** and **B**) can be called **a conjunction**.
* **or** is called **disjunction**. A statement of the form (**A** or **B**) can be called **a disjunction**.
* **not** is called **negation**. A statement of the form (not **A**) can be called **a negation**.
* **if/then** is called **the conditional**. A statement of the form (if **A** then **B**) can be called **a conditional**.
* **for all** is called the **universal quantifier**, and is one of the two examples of a **quantifier** in first-order logic. A statement of the form (for all **a**, **A**) can be called **a universally quantified statement** or **a universal statement**.
* **for some** is called the **existential quantifier**, and is one of the two examples of a **quantifier** in first-order logic. A statement of the form (for some **a**, **A**) can be called **an existentially quantified statement** or **an existential statement**.

An occurrence of a variable name in a statement is called a **bound occurrence** if it is enclosed by a quantifier over the same variable; otherwise it is called a **free occurrence**. For example, in the statement (for some *x*, (*x* is a prairie dog)), the occurrence of *x* in (*x* is a prairie dog) is a bound occurrence. In the statement ((*x* is a prairie dog) and (for some *y*, (*x* loves *y*))), the two occurrences of *x* are free, whereas the occurrence of *y* in (*x* loves *y*) is bound.

The explanations I gave of the meanings of statements in first-order logic assume the notion of a *context*. For the purposes of first-order logic, the context simply determines what objects the variables, and the object terms with context-sensitive meanings (e.g. "it") denote. You can think of a context as a mapping from variable names to objects, from predicates to sets of objects, and from copulas to sets of objects and pairs of objects (TODO: unpack this shit). Contexts are referred to by various names in the study of logic, with "interpretation" being one term in use. In some presentations of first-order logic, every variable name is required to be given a value by a context, while in other presentations, a context might give values only to some variables. In the latter approach, statements containing free occurrences of variables will be uninterpretable in a given context if that context does not assign values to those variables.

We will take the latter approach in this text. Specifically, we will consider a context to provide a *partial* mapping from object terms to objects, saying for some subset of the set of all of context-sensitive object terms (i.e. variables and context-sensitive object literals) what objects they denote. In our approach, statements containing free occurrences of variables whose denotations are not defined by a given context, and statements containing context-sensitive object literals whose denotations are not defined by that context, will be uninterpretable in that context.

The approach of requiring contexts to define the denotations of all object terms is mathematically convenient because it entails that every statement is interpretable in every context. However, the assumption that every term is defined in every context is unrealistic. In reality, statements are uninterpretable when they contain context-sensitive object terms whose denotations are not clarified by the context.

I will not attempt to further formalize this explanation of the meaning of the statements of first-order logic at this time. At this point it's hoped that the reader understands the meaning of statements of first-order logic in an informal way which enables them to read such statements. There are many intricacies to explore regarding the meanings of statements of first-order logic, but we will defer this discussion for later seciotns.

TODO: Exercises

Earlier I made the claim that essentially any statement can be expressed in first-order logic. Let us now explore this claim. The claim is interesting because if it is true, then we can think of first-order logic as a sort of a theory of statements, an idealized way of thinking about statements as a whole.

First-order logic is not the only formal language about which one may fairly make this claim. There are many formal languages about which one may fairly make this claim. Most of them bear some resemblance to first-order logic. First-order logic is a good example of the category.

The first-order logic statements we have seen, when read aloud, are in essence English sentences (although their use of variable names is not ordinary English). Clearly many English statements are already in essence statements of first-order logic, in the sense that a translation is obvious and closely resembles the original statement. In other cases, varying degrees of rephrasing are required to express an English statement in first-order logic.

In order to investigate further, we shall abandon contrived examples and look at real sentences from out in the wild. We will look at some semi-randomly chosen statements from books that are in my home, and try to translate them into first-order logic. I don't claim that my translations are the only possible translations into first-order logic of these English statements, and I don't claim that they are exact translations capturing every shading of meaning that the statements have for every English speaker. I do claim that they are basically good translations that preserve the core meaning of the original statements.

**This cake is well named, as it has a very delicate consistency.**

Translation: ((this cake is well named) and (this cake is very delicate in consistency) and (the statement (this cake is well named) is justified by the statement (this cake is very delicate in consistency)))

Sentence from: Irma S. Rombauer. The Joy of Cooking. Simon & Schuster Inc.

"This cake is well named as it has a very delicate consistency" seems to mean roughly "this cake is well named because it has a very delicate consistency." That is, the sentence expresses three things:

* The cake is well named.
* The cake has a very delicate consistency.
* The cake is well named because it has a very delicate consistency.

This third statement is expressing a relationship between the first two statements: namely, that "this cake has a very delicate consistency" justifies "this cake is well named." This is reflected in the translation, where the copula "is justified by" relates the two object literals "the statement (this cake is well named)" and "the statement (this cake is delicate in consistency)."

TODO: break down further

**Every passerby could read the sign, for every passerby could read Hebrew, Latin, or Greek --- the three great languages of the ancient world.**

Translation: ((Latin is a great language of the ancient world) and (Hebrew is a great language of the ancient world) and (Greek is a great language of the ancient world) and (for all x, (if (x is a great language of the ancient world) then ((x is Greek) or (x is Latin) or (x is Hebrew)))) and (for all x, (if ((x is a person) and (x is passing by the sign)) then ((x can read a great language of the ancient world) and (x can read the sign) and (the statement (x can read a great language of the ancient world) justifies the statement (x can read the sign)))))).

Sentence from: Max Lucado. He Chose the Nails. Thomas Nelson.

The size of this translation shows that many different logical propositions are contained in this not-exceptionally-long English sentence.

TODO: break down

The hawk-eyed reader may notice that I have taken some liberties with parentheses in this translation. For example, I wrote ((x is Greek) or (x is Latin) or (x is Hebrew)), but technically this statement cannot be produced by our syntax rules, because our syntax rules cannot produce three "or" clauses under one shared set of paretheses. To conform technically to our syntax, the statement must be written with two of the "or" clauses parenthesized together, in one of these two ways (with the added parentheses in bold):

(**(**(x is Greek) or (x is Latin)**)** or (x is Hebrew)

((x is Greek) or **(**(x is Latin) or (x is Hebrew)**)**)

Both of these statements mean the same thing and are true under exactly the same circumstances: namely, when at least one of the three clauses is true. Later we will be able to prove formally that these two statements are true under exactly the same circumstances. We omit the bolded parentheses are am deliberately ambiguous about which of these two statements we mean, purely as a matter of convenience, in an example of what is called an **abuse of notation**.

The other example of us taking liberty with parentheses in this translation is of the same kind, but with "and" instead of "or." The statement as a whole has the form:

((Latin is a great language of the ancient world) and (...) and (...) and (...) and (...))

**Besides the theories on the unity of the concept of being in the writings of Henry of Ghent and John Duns Scotus, there were other late medieval attempts to resolve this basic issue of metaphysics.**

Translation: (for some *a*, (for some *b*, ((Henry of Ghent wrote *a*) and (John Duns Scotus wrote *b*) and (*a* is a theory of the unity of the concept of being) and (*b* is a theory of the unity of the concept of being) and (*a* is late medieval) and (*b* is late medieval) and (the theory of the unity of the concept of being is a basic issue of metaphysics) and (for some *c*, ((not (*c* is *a*)) and (not (*c* is *b*)) and (*c* is a theory of the unity of the concept of being) and (*c* is late medieval))))))

Sentence from: Richard H. Popkin (ed.). The Columbia History of Western Philosophy. Columbia University Press.

**I myself in your situation, if I had an appointment with a Godin... Godet... Godot... anyhow you see who I mean, I'd wait till it was black night before I gave up.**

Translation: (if (I have an appointment with Godot) then (if (not (I am waiting for Godot)) then (the time of day is black night)))

Sentence from: Samuel Beckett. Waiting for Godot. Grove Press.

This translation omits the difficulty the speaker has in referring to Godot, and simply refers to the individual the speaker is referring to. If we wanted to translate the difficulty literally, we could write something like:

(for all *x*, (if ((*x* is Godin) or (*x* is Godet) or (*x* is Godot)) then ((you know the referent of "*x*") and (if (I have an appointment with *x*) then (if (not (I am waiting for *x*)) then (the time of day is black night))))))

This example illustrates that there can be multiple plausible translations of an English statement into first-order logic. This is a usual feature of translation from any language into any other language.

In order to ensure their understanding of the foregoing, which is necessary for understanding of what follows, the reader should ensure they are able to translate statements from English into first-order logic. Perhaps it is evident to the reader how to do this from what has been said. The reader is encouraged to find English statements and translate them into first-order logic. Especially if this exercise is difficult, the reader can try the provided exercises, which include answers and walk through the process of arriving at those answers.

TODO: Exercises

The reader is encouraged to try to find limits to what first-order logic can express. The reader is encouraged not to conclude that first-order logic can't express something just because the reader can't quickly figure out how to express it. [philosophy.stackexchange.com](http://philosophy.stackexchange.com/questions/tagged/logic) is one place to ask questions and find answers to already answered questions about this kind of topic, questions like "how can this statement be translated into first-order logic?" Some statements may lack any wholly satisfactory translation into first-order logic. We will explore this topic in more detail later.

TODO: Discuss general techniques for eliminating English grammar constructs not present in first-order logic

TODO: Discuss philosophy of translation into first-order logic in more depth, including limitations of translation

Let's step back and consider what we've learned so far. We set out to study the grammar of statements. We studied the grammar of statements in a version of first-order logic. We also developed a practical understanding of how to translate English statements into first-order logic. Thus, we have seen that although the grammar of English statements is very complex, for many practical purposes we can reduce the study of English statements to the study of statements in a much simpler and more precisely defined language: the language of first-order logic.

This is because for essentially every English statement, we can find a statement of first-order logic which means essentially the same thing. Almost every lesson that we learn about first-order logic will translate over to English fairly straightforwardly. But first-order logic is much more amenable to rigorous study than English is, because numerous distracting sources of non-essential complexity have been eliminated in first-order logic. Therefore the introduction of first-order logic can be expected to substantially simplify our lives in the study of statements and allow us to get further along in understanding them.

However, it would be wrong of us to carry out our study of statements only in first-order logic indefinitely. Ultimately everything we learn must be applied to English statements. Arguments are almost always made in natural languages, of which English is the example used in this text. Working in English must not be a handicap for us. As debaters we benefit from wishing to become such masters of the full complexity of the natural language(s) we use that the complexity is something we turn to our advantage rather than something that stymies us. However, practically speaking, mastery of English, insofar as English differs from first-order logic, is more a matter of acquaintance and art than it is of theory and technique. Mastery of first-order logic, on the other hand, is mostly a matter of theory and technique. Acquaintance and art come only from practice, and in this book our focus outside of the exercises is on theory and technique.

This simply means that the reader will mostly have to figure out for themselves how to apply the theory and technique of logic to natural language arguments. The reader should seek to synthesize for themselves a deep, intuitive understanding of the theory and technique of logic, and allow it to sink into their mind until it underpins their thinking even on an unconscious level. This, in my experience, is what enables the reflexive, sophisticated application of logic to natural language. 

## Speech acts

One important concept in the philosophy of language is the distinction between acts of speech, and speech acts. This distinction seems to have been first introduced in a systematic way by [J.L. Austin (1962)](http://pubman.mpdl.mpg.de/pubman/item/escidoc:2271128:3/component/escidoc:2271430/austin_1962_how-to-do-things-with-words.pdf). 

 * An **act of speech** is, in other words, the action of speaking.
 * A **speech act** is an action performed by speaking.

Here "speaking" and "speech" should be taken as inclusive of writing, and linguistic communication in general.

Examples of speech acts include:

* The "I do" of a marriage ceremony by which one agrees to marry somebody.
* The signature on a legally binding contract.
* Asserting that the sky is blue. This belongs to the category of speech acts called **assertions**.
* Denying that the sky is blue. Belongs to the category of **denials**.
* Asking somebody to pass the salt. Category of **requests**.
* Asking somebody whether they sky is blue. Category of **questions**.
* Demanding that somebody leave your house. Category of **demands**.
* Yelling "fuck you" at somebody. Category of **insults**.
* Ordering the soldiers you command to fire at will. Category of **orders**.
* Ordering a cup of coffee at a restaurant. Category of **orders** (in a different but related sense).

We could go on.

In debates, three main types of speech act are employed: assertions, denials, and questions. These three types of speech act are the ones that are primarily relevant to us. Mostly we will talk about assertion. Let's take a moment to analyze these three types of speech act in more depth.

TODO

## Truth

What is truth? What does it mean for something to be true? Here are two definitions of "truth" that I looked up on Google:

1. "the quality or state of being true"
2. "that which is true or in accordance with fact or reality"

Some definitions of "true" that I found on Google: 

1. "in accordance with fact or reality"
2. "accurate or exact."

"Truth" we can summarize, essentially, as the property of being true, and to be true is to be in accordance with fact or reality, or accurate or exact.

These dictionary definitions don't help us get to the bottom of the issue, though; they replace one term we don't understand ("true") with related terms that we also don't understand ("fact," "reality," etc.). What we really need is a *theory* of the meaning of the word "true:" a theory that explains how the term is used, which we can examine to get insight into the meaning.

Before we can develop a theory of truth, we need to gather some observations about truth. Let's start by using the words "true" and "truth," and "false" and "falsehood," in a mixture of obviously true statements, and truisms whose truth might be less clear in some cases:

* It is true that smoking causes lung cancer.
* "Smoking causes lung cancer" is a true statement.
* It is false that water is made of methane.
* "Water is made of methane" is a false statement.
* No statement is both true and false.
* Every statement is either true or false.
* What's true is true and what's false is false, independently of what people believe, say, or wish.
* Truth is something worth pursuing.
* Truth is the opposite of falsehood.

Not everybody agrees with all of these statements. Let's examine the ones that are controversial.

**No statement is both true and false.**

This truism is sometimes called **the law of non-contradiction**. This is the least controversial of our controversial statements. Almost everybody who comments on the topic agrees that a statement that is both true and false is an impossibility and would be an absurdity.

Opponents of "no statement is both true and false" are sometimes called **dialetheists**. Dialetheism is the view that there are true contradictions, i.e. statements that are both true and false (at exactly the same time, in exactly the same sense). Examples of dialetheists include Graham Priest, Jc Beall, and the author. It is not a purpose of this text to argue for dialetheism; though the author is a dialetheist, for the purposes of this text the reader will not be discouraged from regarding dialetheists as a strange group of people with a bizarre view that ought to be rejected.

Here is a typical argument in favor of dialetheism. This is an argument called the **liar paradox**. Consider the statement "this statement is false." Call this statement L. In other words, L is the statement "L is false." If L is true, then L is false, because that's what L says. If L is false, then it's false that L is false (because that's what L says), meaning that L is true (since every statement is either true or false). In short, if L is true then L is false, and if L is false then L is true. Since L is either true or false, L is therefore both true and false.

One can reject this argument in favor of dialetheism in many different ways. In the modern academic debate on dialetheism, the liar paradox is rarely presented as an argument in favor of dialetheism, because so many ways of blocking the argument are known; rather, the liar paradox, the argument itself, is taken as an object of study in the debate on dialetheism.

The usual response to the liar paradox, the response of most of the world, is what we can call the "indifferent shrug." This is a mode of response where one disregards the argument and its conclusion without providing any reason to do so.

The indifferent shrug is not necessarily an irrational response to the liar paradox, in my opinion. Life is short and there are many things to do in the world. If somebody feels that they should not devote their time to evaluating an argument with a patently absurd and yet pointless conclusion, I can't necessarily say their decision making is poor.

However, it is undeniable that the indifferent shrug is not a satisfactory response to everybody. I would therefore like to helpfully provide what I think is a better response to the liar paradox for people who don't wish to agree with me that there are true contradictions and also don't find the indifferent shrug to be a satisfactory response. However, I will not do that right now, as we need further background material first. Therefore let's move on to our next controversial statement about truth.

**Every statement is either true or false.**

This truism is sometimes called the **law of the excluded middle**. It states, in other words, that there are no statements which are neither true nor false.

Aristotle is the earliest writer I'm aware of to have asserted this law, when he wrote "there cannot be an intermediate between contradictories, but of one subject we must either affirm or deny any one predicate." (*Metaphysics*, Book IV, Part 7) 

The law of the excluded middle is a feature of the standard rules for first-order logic, and it is a popular idea among logicians that the law is true. However, it is also a fairly popular idea that the law is not true. Here are some possible examples of statements that are neither true nor false:

* "Christianity is a good religion." Whether Christianity is a good religion depends on what one thinks makes for a good religion. Some would argue there is no such thing as a good religion, and Christianity has been a net bad for the world. Others would argue that Christianity is not only a good religion, but the only good religion. There are many perspectives in between. One may argue that this multiplicity of conflicting perspectives, each with at least a grain of truth to it, means that "Christianity is a good religion" is neither true nor false.
* "Science is reliable." Reliable in what sense? Science is not reliable in the sense that following the scientific method doesn't guarantee that you will arrive at the truth, and scientists seem to make mistakes and get things wrong frequently. Science is reliable in the sense that we can rely on it to continue to provide us with new facts about the world as long as people continue to follow the method. Science is probably reliable and unreliable in other senses too. So "science is reliable" isn't a specific enough statement to be true or false.
* "Liberals are tolerant." Different liberals are tolerant of different things to different degrees. Liberals vary between each other in how tolerant they are, and individual liberals vary in how tolerant they are of different things. For example, some liberals might be tolerant of homosexuals but intolerant of religious believers.
* "The King of America is short." Of course there is no King of America, so the statement isn't true. However, if it were false, that would mean its negation was true, and the negation of "the King of America is short" is "the King of America is not short," which certainly isn't true either.
* "The [continuum hypothesis](https://en.wikipedia.org/wiki/Continuum_hypothesis) is true." The continuum hypothesis is a statement about sets which can be neither proven nor disproven on the basis of any widely accepted statements about sets. The continuum hypothesis, being a possibly unsolvable question about a type of thing, sets, that may themselves be an imagination of humans, may be neither true nor false.

It's not obviously necessary to accept any of these as genuine counterexamples to the law of the excluded middle.

* "Christianity is a good religion," you can argue, is either true or false given further definition of "good." Like any statement, it requires context clarifying the meaning of the terms in order to be true or false, but given that, it is either true or false, one can argue.
* "Science is reliable" can be addressed in the same way. Given context clarifying the meaning of "reliable," the statement is true or false, one can argue.
* "Liberals are tolerant" can be addressed in the same way.
* "The King of America is short" is not true or false, because the meaning or referent of the term "the King of America" is not clarified by the context of the world as it exists today and has existed in the past. This needs to be understood as giving us a limitation on the law of the excluded middle. As applied to our version of first order logic, the limitation is that the law only applies to statements that are interpretable in the given context. This makes our original statement of the law of the excluded middle, "every statement is either true or false," not literally true. One can, however, understand the original statement as being truncated language, a simplified statement of the law, rather than being a falsehood.
* One can certainly maintain that the continuum hypothesis is either true or false. For example, one can be a mathematicial Platonist about sets. I.e., one can maintain that there is an objective reality of sets existing in a Platonic realm outside of space-time, and that one with perfect knowledge of this reality (e.g. God) would be able to know whether or not the continuum hypothesis was true or false by observing the universe of sets.

My aim is not to say that the reader should accept these arguments as showing that the law of the excluded middle is true, but merely to show that the law of the excluded middle is remarkably defensible and can be defended against all the counterexamples I can give. The reader is encouraged to form their own opinion on whether the law of the excluded middle is true.

One can reject that the law of the excluded middle applies to all statements, while maintaining that there are some limited classes of statements wherein every statement is either true or false.

When it comes to sufficiently precise statements of fact about ordinary medium-sized physical objects, such statements are always either true or false, if there is an objective reality which conforms to our ordinary common sense beliefs about physical reality, namely that there is a fully existent physical reality whose parts all exist in a single determinate state where every detail that could be investigated exists in a determinate state even when it's not being observed.

A person can reject the principle that sufficiently precise statements of fact about ordinary medium-sized physical objects are always either true or false, if they reject the premise that there is an objective reality whose parts all exist in a fully determinate state even when not being observed. I am not aware of any conclusive arguments for the stated premise, so there is basis for controversy about whether sufficiently precise statements of fact about ordinary medium-sized physical objects are always either true or false.

Many classes of statements are **decidable**, meaning it is possible to write a computer program which decides whether statements in that class are true or false. In other words the program takes as input a statement in the class and as output it (correctly) says either that the statement is true or that the statement is false. If a class of statements is decidable, then most would agree that every statement in the class is either true or false. The argument, essentially, is that in principle one could run the program and the program would correctly tell you either that the statement is true or that it's false; but presumably the statement was already true or false, whichever it is, before you ran the program. Therefore it's already true or false even if we don't run the program. I'm not aware of much controversy about this reasoning, but you can reject it if you're willing to say that mathematical statements don't become true or false until people prove or disprove them.

An example of a class of decidable statements are "bounded-quantifier arithmetical statements," or **BQA statements** as I will call them. TODO

Let's take stock.

Most of the time in the course of life, we are happy to assume that statements are either true or false. Most of the time assuming that a statement is either true or false will not lead us into any kind of error. However, sometimes it is inappropriate to assume that a statement is either true or false, as with the statement "Christianity is good," or "science is reliable."

It is generally safe to assume that sufficiently precise statements of fact about ordinary medium-sized physical objects are either true or false. It is generally safe to assume that mathematical statements are either true or false, because mathematicians regularly do so in the course of proofs; it is a generally accepted rule of mathematics that mathematical statements are either true or false.

However, some schools of schools of thought on math, such as most [constructivist](https://en.wikipedia.org/wiki/Constructivism_(mathematics)) schools, reject the idea that every mathematical statement is either true or false.

For example, consider some universally quantified mathematical statement, i.e. a mathematical statement of the form (for all **x**, **A**). Let's call this statement P. Let's suppose P cannot be proven constructively, and that no counterexamples to P can be constructed, i.e. P cannot be disproven constructively. Then a constructivist might say that P is neither true nor false.

Exactly how broadly we can assume that statements are either true or false is a matter of controversy. Most would agree that statements in decidable classes, like BQA statements, are all either true or false. Most think the same about sufficiently precise statements of fact about medium-sized physical objects. I believe that most mathematicians accept the law of the excluded middle as applied to math. Some philosophers think we can assume the law of excluded middle much more broadly.

The reader is encouraged to use their own judgment in applying the law of the excluded middle, and to form their own opinion on the issues I have raised if they are interested. Practically speaking, I think the reader will find the law of the excluded middle is a useful logical tool which they feel comfortable applying in essentially any real world case where it's applicable.

**What's true is true and what's false is false, independently of what people believe, say, or wish.**

This truism strikes me as basically untrue, in that what's true is dependent on what people say, and more specifically on how people talk. For example, "water is not made of methane" is true in part because of the conventional definitions of "water" and "methane." If "methane" was instead defined to mean H2O, then the statement would be false. So what's true is dependent on what people say. This reasoning works for every statement, since every statement is made up of words which need some previously established meanings for the statement to be intelligible.

What if we assume some fixed framework of definitions? Is what's true true, and what's false false, independently of what people believe, say, or wish, as long as we hold fixed that framework of definitions of words? At least when talking about sufficiently precise statements of fact about medium-sized physical objects, the truism seems basically to hold true under these conditions and in this sense and in my experience. You can form your own opinion, of course.

**Truth is something worth pursuing.**

This truism is not always accepted. In the author's opinion, looking at our experiences in life and at historical events supports the view that things are better in almost all cases when people have the truth about issues that matter.

 * When we understand the causes of diseases, we are in a position to prevent and cure them with medical science.
 * When we know the truth about the politicians who represent us, we can hold them accountable more easily and increase the likelihood that the politicians in office are good, ethical people. 
 * When we understand how the natural world works, we can make technology that allows us to farm more efficiently and produce far more food with a given amount of human labor, allowing most of the human population in developed countries to occupy themselves with activities other than agriculture.
 * When we know the truth about scientific political debates such as the climate change debate, we can make the right decisions that will be best for the future.
 * When we know the truth about what's going on in our personal lives, we can make decisions that will be more likely to strengthen our relationships and avoid future suffering.
 * When we hold values that are based on deep and thorough analysis of the world as it actually is, our values are more likely to bias us towards making decisions that will be helpful in our lives and the lives of others.

In my opinion, the consequences of pursuing and sharing the truth are almost always preferable to the consequences of attempting to conceal, evade, ignore, denigrate, distort, or escape the truth. A life lived in truth and love, in my experience, is a happy and fulfilling life. Pursuing and sharing the truth brings great joy, and it brings lessons which help one in all aspects of life and living. By pursuing the truth, one can learn the lessons of morality more deeply, and experience the fulfillment of a life well lived. Pursuing the truth in bonds of love and trust with others who share the same goal greatly amplifies the efforts of all and produces a far better outcome, in my experience.

**Summary of the truisms discussion**

We've completed our discussion of the non-obvious truisms about truth that I listed. We have certainly unearthed a bit about truth in the process. Let's take stock.

The law of non-contradiction states that no statement is both true and false. This law is endorsed by almost everybody who speaks on the subject, except for some mavericks, such as dialetheists, who think that some statements are both true and false. One argument in favor of dialetheism is the liar paradox. This argument can be blocked in numerous ways, but we have yet to discuss that. The indifferent shrug, however, seems to be a fair enough response.

The law of the excluded middle states that every statement is either true or false. The law of the excluded middle is controversial, and neither side in the debate has struck a decisive blow, in the author's awareness. The reader is encouraged to form their own opinion.

What's true is true and what's false is false, independently of what people believe, say, or wish, at least when you're talking about sufficiently precise statements of fact about ordinary medium-size physical objects, and relative to a fixed framework of definitions of words.

Truth is worth pursuing. A life of pursuing truth (and love), in the author's opinion, is the best life available on this Earth.

**What is truth? What is true?**

Earlier I wrote:

> What we really need is a *theory* of the meaning of the word "true:" a theory that explains how the term is used, which we can examine to get insight into the meaning.

Many theories of the meaning of the word "true" are based on a principle called the **T-schema**. The T-schema is a principle which people have observed about the word "true," which can be stated abstractly as follows. For any statement **A**:

> The statement "**A**" is true if and only if **A**.

For example: "water is wet" is true if and only if water is wet, and "snow is warm" is true if and only if snow is warm.

Note: "**A** if and only if **B**" means the same as "if **A** then **B** and if **B** then **A**."

Theories of truth based on the T-schema been worked on by many people, including (for example) Alfred Tarski and Crispin Wright. A simple theory of truth based on the T-schema is [Horwichian minimalism](https://en.wikipedia.org/wiki/Deflationary_theory_of_truth#Horwich.27s_minimalism), a sort of view based on the writings of Paul Horwich. Horwichian minimalism, as I will formulate it, states essentially that the T-schema explains the meaning of the word "true" by stating the fundamental rule governing the usage of the word "true."

If the T-schema is a definition of "true," then it is what we can call an "axiomatic definition." An axiomatic definition of a word defines the meaning of the word by giving some statements involving the word that are true by the definition of the word.

The T-schema is an infinite set or schema of statements that are (arguably) true by definition of the word "true," that explain how to use the word "true" (in the usage of that word defined (in the sense of axiomatic definition) by the T-schema).

A further example of an axiomatic definition is the axiomatic definition of the word "and" given by the following two rules. First, from (**A** and **B**) you may infer **A**, and you may infer **B**. Second, from **A** and **B**, you may infer (**A** and **B**).

Now we can look at the precise version of my formulation of Horwichian minimalism:

**Horwichian minimalism.** The T-schema is an axiomatic definition of "true."

I do not claim that my formulation of Horwichian minimalism is either essentially original, or the same in spirit as Paul Horwich's view, or the same as the understandings of other philosophers who have endorsed Horwichian minimalism. Nonetheless, I will henceforth use the phrase "Horwichian minimalism" to mean the view that the T-schema is an axiomatic definition of "true."

I myself believe (this formulation of) Horwichian minimalism. It is a very modest view. All it claims is that the T-schema defines a meaning for "true." It doesn't claim this is the only possible meaning for "true."

The notion of axiomatic definition is a small variation on Bob Hale and Crispin Wright's concept of an [implicit definition](http://www.st-andrews.ac.uk/arche/old/pages/papers/Implicit%20Definition%20and%20the%20A%20Priori.pdf). The concept of implicit definitions is explained in the opening paragraph to the linked paper:

> An explicit definition aims to supply a semantically equivalent expression of the
same syntactic type as its definiendum. Implicit definition, taken as the complement of
explicit, embraces a variety of subtypes. What all have in common is the idea that we may fix
the meaning of an expression by imposing some form of constraint on the use of longer
expressions—typically, whole sentences—containing it.

Hale and Wright define implicit definition as the complement of explicit definition. I disagree with their claim (in this paper) that all subtypes of implicit definition have in common the idea that we may fix the meaning of an expression by imposing some form of constraint on the use of longer expressions containing it. As a counterexample, I provide ostensive definitions, which are definitions of words made by (literally or figuratively) pointing at examples: for example, pointing at a dog and saying, "dog." Ostensive definitions are not explicit definitions, so they are implicit definitions, but they don't (in any sense that is apparent to me) fix the meaning of the words they define by imposing some form of constraint on the use of longer expressions containing them. It's possible that the category Hale and Wright defined in this paper contains more things than they intended it to. It's even possible that they made this observation and have since revised their thinking. I am not an expert on either philosopher's work, and I am merely pointing out possiblities not ruled out by the information at hand.

The category of axiomatic definitions seems to be narrower even than the category of implicit definitions in Hale and Wright's (arguably) narrower sense, of definitions which fix the meaning of an expression by imposing some form of constraint on the use of longer expressions containing it. Finding an example of a non-axiomatic definition meeting Hale and Wright's narrower condition is left as exercise to the reader. I haven't solved this exercise myself, and while it may be tricky I suspect that it is solvable. Please contact me if you come up with a solution, or a good argument that there is none. 

Hale and Wright point out some controversy about whether or not implicit definitions are a legitimate form of definition. Such controversy also applies to axiomatic definitions, which are the typical examples of implicit definitions. Personally, I see little reason for fuss. To me it's natural that you can explain the meaning of a word by giving rules that explain how to use it. You can teach somebody how to use the word "and" by teaching them to follow the rules of inference described before. And you can teach somebody how to use the word "true" by teaching them the T-schema.

Of course, the T-schema defines only one possible way of using the word "true," and people might use it in other ways.

So far I have presented one definition, sense, or meaning for the word "true." This is the meaning axiomatically defined by the T-schema (according to Horwichian minimalism). However, there are certainly other possible meanings.

For example, one might define "true" as "accurate to reality." This definition will be equivalent to the T-schema within the context of any conversation where by asserting a statement, one implicitly asserts that the statement is accurate to reality. (In my life, conversations I have at work in my professional capacity are examples of such conversations.)

As far as I am aware, any definition of "true" which tells a person how to use the word "true" and is consistent with common usage, is based on the T-schema or equivalent to it in appropriate contexts. If you find any counterexample to this statement, please tell me about it.

The T-schema by itself is not enough to explain how to use the word "true." Essentially, the T-schema references questions about truth to questions about norms of assertion. If you can rightly assert a statement, then you can rightly assert that that statement is true. Instead of asking, when is a statement true, you can ask, when can you rightly assert a statement? The latter is a question that this entire text is aimed at addressing. 

Still, some readers may feel that this misses the point. If we reduce questions about truth to questions about norms about assertion, then perhaps some readers feel we are no longer asking the questions they are interested in, because readers want to know what's true in the sense of what's real, what's actual. I don't want to convey the appearance of sidestepping these meaty questions in favor of surface questions about what we can say.

It is the author's hope that the reader can get closer to what's true in the sense of what's real and what's actual on the basis of what they are learning in this book. I do not claim to know what's real and what's actual, and therefore I cannot claim to show the reader the path to come to know what's real and what's actual. However, it is my opinion that applying the techniques of this text, taken all together and used with art, skill, and fairness, will tend to help one figure out what's real and what's actual in practical terms, in most problem domains that humans can get a grip on. No guarantees can be made that the methods we discuss will lead one to an accurate understanding of reality in any particular situation. I am unaware of any totally sure, provably infallible methods of knowledge gathering. Consistent with that, I am comfortable calling this text a method of seeking the truth. 

**Other theories of truth**

I have so far described one systematic theory of the meaning of "true:" namely, Horwichian minimalism. How does Horwichian minimalism compare to other theories of truth? I will compare it to (a) a generic postmodern theory of truth, and (b) a generic pluralist theory of truth, a la Michael P. Lynch.

Our generic postmodern theory of truth runs as follows: "truth is relative." Truth is relative to a context, an observer, a point of view. Thus there are many different truths, none absolute.

Horwichian minimalism does not go as far as this postmodern theory of truth. It does not positively assert that there is no absolute truth. It is silent on whether there is such a thing as absolute truth. However, Horwichian minimalism agrees with this postmodern theory of truth as far as they both go. It agrees that truth is relative, in a sense: the interpretation of "true" is relative to a conversational context which can establish norms governing assertion and thereby determine what can be called true in that context.

Our generic pluralist theory of truth runs as follows: "there are multiple kinds of truth." Horwichian minimalism agrees with this, as different conversational contexts produce different versions of "true" which behave substantially differently. However, some pluralist theories of truth will define meanings of "true" which are different from the minimalist meaning of "true" provided by the T-schema. My view does not discourage the progress of such projects, since my view allows for the consideration of definitions of "true" other than the Horwichian minimalist definition of "true."

Horwichian minimalism is not the most informative theory of truth, and it is only a theory. That's why I'm open to other theories of truth. To me, the value of Horwichian minimalism is that it gives us one viable way of understanding the meaning of "true," of treating our confusions around this word. It references questions about truth to questions about norms of assertion. This proves in practice to be a productive way of thinking about truth. Understanding norms of assertion takes in much of what humans know about seeking the truth. It is the primary topic of the rest of this text.

## Epistemology

So far we have discussed to some extent the "what" of truth. We have yet to discuss the "how." How does one get to the truth? For some readers, I imagine that understanding how to seek the truth is their primary aim in reading this text. I promised in [the "how to read this text" section](#how-to-use-this-text) that you can use this text "as a practical guide to winning arguments, to reasoning about any subject, to seeking the truth about any subject, and to misleading people about any subject." I have therefore promised to discuss seeking the truth.

This is an extremely hairy topic. To get ourselves started, let's pick up some threads that were left hanging in the previous section and notice some puzzles we haven't yet discussed.

In discussing the truism that truth is something worth pursuing, I argued that truth is valuable and indeed worth pursuing. On the other hand, in discussing the word "true," the only explanation of its meaning that I offered was the T-schema and the theory of Horwichian minimalism.

Recall that the T-schema is the infinite set of statements of the form "the statement **A** is true if and only if **A**," for all statements **A** (in some language, e.g. English). Recall that Horwichian minimalism is the view that the T-schema is an axiomatic definition of "true." Recall that an axiomatic definition of a term defines the meaning of the term by giving some statements involving the term that are true by the definition of the term.

Thus, we have two related and yet very different conceptions: the conception of *truth* as a value, and of *true* as an axiomatically defined, context-sensitive, meta-linguistic term that is used to describe statements.

Intuitively, the meanings of *truth* and *true* should have a lot to do with each other, but perhaps it's difficult (it was for me) to see right away how the conceptions of *truth* and *true* I have provided are at all related.

As it happens, we don't need to look terribly deep to see the connection. Horwichian minimalism, as we have observed, lets us reference questions about truth to questions about norms of assertion. Therefore, it follows from Horwichian minimalism that questions about truth can be construed as normative questions about how we should behave (namely what speech acts, specifically what assertions and denials, it is warranted for us to perform).

What is the relationship between the value of truth, and norms of assertion? Norms of assertion, like other norms, are often rooted in values. The value of truth is a simple example. The value of truth undergirds the Gricean maxim of quality (a basic norm of assertion), "where one tries to be truthful, and does not give information that is false or that is not supported by evidence."  

There are values besides truth that undergird our norms of assertion. For example, consider Socrates, who seems to have valued critical, unblinking inquiry into the truth about essentially all matters, but is also on record as fully and uncritically endorsing the state religion of Athens, which residents of Athens were not legally allowed to criticize. It's possible that Socrates genuinely believed in the state religion of Athens. Let's suppose, though, for the sake of argument, that Socrates did not believe in the state religion of Athens. In this case, Socrates was self-censoring, misrepresenting his own views, in order to avoid being put to death (something which he was ultimately unsuccessful in avoiding). In this case, Socrates was basing his norms of assertion on something other than the same values behind his valuing of truth. In this case, Socrates was additionally basing his norms of assertion on the laws of Athens and his desire not to break them.

I think most people base their norms of assertion on values apart from and in addition to their value of truth. Probably most people today live in circumstances where the consequences of saying certain true things in certain contexts in their lives are unacceptable to them. I do think there are people who don't believe anything they're unwilling to say, and don't say anything they don't believe, but I think they're in the minority, and I don't count myself among them.

Is it true, then, as I ventured, that often the values undergirding a person's value of truth, and the values undergirding the norms of assertion they consider correct, coincide? We've concluded that typically they come apart to at least a small degree; any individuals who are exceptions to that rule are unusual.

From a Horwichian minimalist perspective, there is some difficulty in seeing how these two can come apart, since Horwichian minimalism does not allow for much space between truth and assertibility. Horwichian minimalism certainly does not say that there can't be true things we can't say in a given context. It merely entails that in any context where you could appropriately assert a statement **A**, you could also appropriately assert the statement "**A** is true," and vice versa.

What does it mean, though, for a statement to be true and not appropriately assertible in a given context, under Horwichian minimalism? I would explain this as follows. Suppose that I consider the statement **A** to be true, but I don't consider it appropriate to assert **A** in some context (or perhaps all contexts) in my life. In the context of my internal dialogue, the conversation I am continually having with myself in my head, the statement **A** is appropriate to "assert." In some (or perhaps all) interpersonal conversational contexts that I happen to encounter, though, **A** is not appropriate to assert.




We can perhaps place people on a spectrum, with people on one end who base their norms of assertion little or not at all on their value of truth, and people on the other end who base their norms of assertion entirely or almost so on their value of truth. We can call the people on the former end "insincere," and the people on the latter end "sincere." Sincere people believe what they assert is true, at the time they assert it; insincere people don't necessarily. Sincere people believe what they deny is false, at the time they assert it; insincere people don't necessarily.

Sincere people can exhibit a wide variety of different beliefs, behavior, and styles of conversation and debate. I think radical fanatics, for example, are usually sincere. Sincerity is certainly not a sufficient condition for goodness.

Differences between different sincere people can have to do, among many other things, with differences in the values that give them the sense of valuing truth. For example, if a Catholic sincerely asserts that they value truth and that truth comes from the Catholic church, then they are actually stating a political thesis, and this political thesis is inextricable from their personal conception of truth. The same is true of a Protestant who sincerely asserts that truth comes from our individual faculties of perceiving truth, and that truth doesn't come from appeal to authority. The Protestant is also stating a political thesis, though of a more negative nature: namely that truth doesn't come from appeal to authority. Again, this political thesis is inextricable from this Protestant's personal conception of truth.

When two people say "I value truth," they don't necessarily both mean the same thing. There are many reasons that people value truth, and many values undergirding people's valuing of truth. People value truth for practical reasons, because it helps them accomplish other purposes they have. People also value truth for itself. What valuing truth for itself seems to mean, for most people, is something like having a concern for reality, for the actual, for facts, for evidence, and for knowledge, and for having access to these things as an end in itself, a sort of existential end in life. I count myself in the camp of people who value truth for itself in this sense.

That brings us to epistemology. "Epistemology," in mainstream philosophical usage, is a long word for the theoretical study of knowledge. Epistemology asks, essentially, what is knowledge, and how can we get it? Epistemology is most often studied by people who value truth and knowledge as ends in themselves, and undoubtedly the field is biased by that fact.

The approximately 2,500 year history of the field of epistemology (as known to us through the historical record) is colored throughout by a dichotomy between long-standing pessimism about the possibility of humans acquiring knowledge on the one hand, and on the other hand the over-optimistic intellectual arrogance manifested in philosophical project after philosophical project by generation after generation, who purported again and again to finally deliver the human species into knowledge.

What is knowledge? One long-standing, once-popular theory goes back to Plato's Socrates, in the *Theaetetus*. This theory states that knowledge is justified true belief. In other words, for all statements **A**, I know **A** if and only if **A** is true, I believe **A**, and my belief in **A** is justified.

This theory of knowledge is widely believed to have been debunked by [Gettier (1963)](https://academic.oup.com/analysis/article-abstract/23/6/121/109949/Is-Justified-True-Belief-Knowledge?redirectedFrom=fulltext). Quoting [Wikipedia](https://en.wikipedia.org/wiki/Epistemology#Gettier_problem):

> One of the cases involves two men, Smith and Jones, who are awaiting the results of their applications for the same job. Each man has ten coins in his pocket. Smith has excellent reasons to believe that Jones will get the job and, furthermore, knows that Jones has ten coins in his pocket (he recently counted them). From this Smith infers, "the man who will get the job has ten coins in his pocket." However, Smith is unaware that he also has ten coins in his own pocket. Furthermore, Smith, not Jones, is going to get the job. While Smith has strong evidence to believe that Jones will get the job, he is wrong. Smith has a justified true belief that the man who will get the job has ten coins in his pocket; however, according to Gettier, Smith does not know that the man who will get the job has ten coins in his pocket, because Smith's belief is "...true by virtue of the number of coins in Jones's pocket, while Smith does not know how many coins are in Smith's pocket, and bases his belief...on a count of the coins in Jones's pocket, whom he falsely believes to be the man who will get the job." These cases fail to be knowledge because the subject's belief is justified, but only happens to be true by virtue of luck. In other words, he made the correct choice (in this case predicting an outcome) for the wrong reasons. This example is similar to those often given when discussing belief and truth, wherein a person's belief of what will happen can coincidentally be correct without his or her having the actual knowledge to base it on.

My understanding of the current state of [the academic debate on what knowledge is](https://philpapers.org/browse/knowledge) is that many proposals are out there, and many proposed counterexamples to proposals are out there, but no consensus has formed around an alternative conception of how we should define knowledge. The debate is huge, extremely intricate, and, again, totally unresolved. This, in turn, makes it hard to make progress on the debate on whether humans can obtain knowledge.

I don't claim to have the ability to obtain knowledge. I don't claim that nobody can obtain knowledge, but I also don't know how anybody would. This text isn't meant to break the stalemate in the debate on whether we have knowledge. I make no pretense to be able to resolve the debate, and I make no pretense to know what knowledge is, to have knowledge, or to offer the possibility of knowledge.

At this point some readers may be confused about why I am so hesitant to claim the capability of knowledge. It's worth clarifying the factors that I see as blocking me from making such a claim.

First and most important is that I don't know what knowledge is. I probably can't know that something is knowledge if I don't know what knowledge is. Yet most of the time we assume that if you know something, then you know that you know it, you know that you know that you know it, and so forth. Since I don't know what knowledge is, I may know stuff, but if so I don't know that I know it.

Though I don't claim literally to possess knowledge and to know that I possess it and so forth, I will in practical contexts assert that I know something. Generally I do so when I am confident that I can defend the claim. If pressed specifically on my use of the word "know," then I would substitute a weaker term (though my word choice is rarely the key issue in non-philosophical conversations).

My lack of clarity around how to define or use the word "knowledge" is one difficulty I have around claiming possession of knowledge. However, it's not my only difficulty.

The other difficulty is that my experiences are consistent with a lot of different things being true. For example, I could be a [brain in a vat](https://en.wikipedia.org/wiki/Brain_in_a_vat) experiencing a simulated reality created by attaching my brain to computers that fire appropriate signals at my brain to make it seem like it's in a human body on the planet Earth. My experiences are entirely consistent with this possibility.

My experiences are consistent with the possibility that the whole world has only existed for five minutes, and all of my older memories were implanted in me by whatever mischevious God created this universe. 

My experiences are consistent with the possibility that I am the only conscious person in the world. I believe that others are conscious, but I don't see how I would know. I believe that if there is a God, then God could create elaborate holograms that are exactly like the world I experience in every way, full of totally realistic people, but in which I'm actually the only conscious person. I don't believe I know that this is not the case.

Similarly, my experiences are consistent with the possibility that parts of the physical world only exist while I'm looking at them.

I don't imagine that everybody will find these skeptical arguments compelling. If the reader is still convinced after what I've said that they know things, then that's OK. My purpose is to teach how to win arguments and seek the truth, not to persuade the reader that they don't know anything.

We are left in an apparently awkward position. We have committed ourselves to a positive project of learning how to win arguments and seek the truth about any topic. However, I have just denied any ambition in this text of developing knowledge. How can we reconcile these seemingly contradictory positions?

The answer to this lies in the distinction between *seeking knowledge* and *seeking the truth*. To seek knowledge is to seek to know things. To seek the truth is to seek to have true beliefs, or perhaps even just true thoughts that one doesn't necessarily believe.

It's widely agreed that knowledge is some condition stronger than justified true belief. If I know *X*, most Western philosophers would agree that I therefore have a justified true belief that *X*. Thanks to Gettier, few would agree that the conditional goes the other way. All knowledge is justified true belief, but some justified true beliefs are not knowledge. Knowledge is a condition stronger than justified true belief.

A condition that's weaker than justified true belief is plain true belief. As somebody who doesn't know how to get knowledge, I aim to believe things that are true, by hook or by crook, doing whatever I think is most likely to work to get me true beliefs. I also aim to have my beliefs be justified whenever possible and desirable, which is most of the time. My belief is that good processes for arriving at beliefs will tend to also produce good justifications for those beliefs. TODO: Should this be strengthened: should beliefs always be justified? Whether or not good processes for arriving at beliefs always produce good justifications for those beliefs depends on what "good" means in the given context, and on how one is construing the meaning of "justification."

So far we have considered a series of progressively weaker conditions: knowledge, justified true belief, and true belief. A condition that's even weaker than true belief is plain truth. I find value in thinking of the truth, even if I don't end up believing it or knowing it. One of the great lessons of philosophy, in my opinion, is the value of speculation. Speculation increases one's likelihood of setting one's eyes on the truth. Setting one's eyes on the truth is step one. It needs to come before believing, knowing, or being able to justify the truth. 

Whenever there's an event, any news coverage that comes out is subject to various degrees of uncertainty, and it's possible to imagine multiple possibilities regarding the truth of the matter. In any news report, it's possible the journalist simply made something up. If a number of different news organizations are reporting the same thing, then either it really happened, or they are in a coordinated conspiracy to make something up, or some of them are making something up and others are listening to the ones making it up. When news coverage is sincere, it can still be inaccurate. When news coverage is accurate, it can still be biased towards a particular political or other type of perspective. There are many layers of interesting interpretation that can be applied to news coverage. Especially when it comes to reporting on events like wars where intelligence can be unreliable and motives for deception run high, often there are many interpretations of what really happened that are consistent with the known facts.

Maybe the reader has found this section and the preceding one on Truth to be climactic; or maybe the reader has found them anti-climactic. I have essentially argued that the field of epistemology, insofar as it has been conceived of as a positive project of finding and verifying the means of obtaining knowledge, has not advanced one step from where it began 2,500 years ago. I do not deny the possibility that future progress in epistemology will deliver us into knowing, knowing that we know, knowing that we know that we know, and so forth. But my own opinion is that, like [cold fusion](https://en.wikipedia.org/wiki/Cold_fusion), we haven't achieved that.

Let's close out our discussion of knowledge with the enjoyable and yet perhaps also uncomfortable opening paragraph from [*On Truth and Lies in a Nonmoral Sense*,](http://pastehtml.com/view/crz4xb2u4.html) [by Nietzsche](https://en.wikipedia.org/wiki/On_Truth_and_Lies_in_a_Nonmoral_Sense).

> Once upon a time, in some out of the way corner of that universe which is dispersed into numberless twinkling solar systems, there was a star upon which clever beasts invented knowing. That was the most arrogant and mendacious minute of ”world history,” but nevertheless, it was only a minute. After nature had drawn a few breaths, the star cooled and congealed, and the clever beasts had to die. One might invent such a fable, and yet he still would not have adequately illustrated how miserable, how shadowy and transient, how aimless and arbitrary the human intellect looks within nature. There were eternities during which it did not exist. And when it is all over with the human intellect, nothing will have happened. For this intellect has no additional mission which would lead it beyond human life. Rather, it is human, and only its possessor and begetter takes it so solemnly-as though the world’s axis turned within it. But if we could communicate with the gnat, we would learn that he likewise flies through the air with the same solemnity, that he feels the flying center of the universe within himself. There is nothing so reprehensible and unimportant in nature that it would not immediately swell up like a balloon at the slightest puff of this power of knowing. And just as every porter wants to have an admirer, so even the proudest of men, the philosopher, supposes that he sees on all sides the eyes of the universe telescopically focused upon his action and thought.

In this text, we're abandoning the topic of knowledge henceforth. However, in my view this does not call for an abandonment of epistemology; instead, in my view it calls for a different formulation of the purposes of epistemology. I will therefore repurpose the term "epistemology," using it to refer to the study of seeking the truth. This is a general umbrella of topics which for us includes truth, true belief, justified true belief, and similar "epistemic" concepts.

With this slightly different conception of epistemology in hand, let us now return to the starting point of our investigation of epistemology.

In essence, we are interested in studying and evaluating potential methods of seeking the truth. We want tools and techonology that enable us to get to the truth. We want tools and technology that work, that actually achieve this purpose. Therefore we want to evaluate various methods of getting to the truth, and to be able to discriminate between effective and ineffective ones.

However, in order to grab the problem by the roots, we need to step back a bit. I noted that there are certain values underlying a truth-seeking attitude or an attitude of sincerity. I also noted that exactly what values are involved will vary between individuals. One way of putting it is to say that truth-seeking attitudes or attitudes of sincerity are like people themselves, in that no two are the same, yet they share uncountable and sometimes indescribable differences and similarities with each other.

As the author, my objective is to help the reader to water their own truth-seeking and their own sincerity, to let it grow in whatever shape is appropriate to it. My objective is not to replicate my own self in others. As such, I can't tell the reader what should be involved in their own attitudes of truth-seeking or sincerity. I also can't choose for the reader whether or not to grow their attitudes of truth-seeking and sincerity at all.

At core, the attitude of truth-seeking is a striving for reality, for what's actual, as I have noted a few times. We can't say this goal necessarily makes sense on the basis of what I've said. In seeking after reality, one can argue that if we knew what we were looking for or how to get there, then we wouldn't need to be seeking.

The experience of philosophy can be compared to groping in a dark system of passageways looking for a way out. Occasionally, by some good fortune or cleverness, one finds one's way out into a brightly lit clearing where one can see many more dark, unexplored passageways terminating. One can continue spelunking indefinitely in this way, finding ever larger clearings with ever more passageways leading out of them. One can rightly wonder whether one will eventually be able to map and explore the entire system of passageways and clearings. One can also rightly wonder whether it's possible to get out of the system of passageways and clearings entirely, and if so what lies beyond it. Many philosophers have thought they had left the system of passageways and clearings entirely, only to discover that they were merely in a very large clearing.

This metaphor is an elaboration of Plato's [allegory of the cave](https://en.wikipedia.org/wiki/Allegory_of_the_Cave). In Plato's allegory, people who were trapped in a dark cave, forced to watch illusions projected onto a wall, are one day let out into the outside world where they get to see the sunlit day, where the sunlight is compared to the light of truth. The passageways and clearings metaphor points out the great joke of philosophy, which is that what we find in philosophy is that the bright sky you emerge out into from Plato's cave later turns out to be just a clearing. 

Is it illusions all the way up? Perhaps. It doesn't really matter, from the perspective of this lifetime. Even if there is truly a way out of the system of passageways and clearings into the daylight of truth, I have no great expectation of reaching it in this lifetime.

The pursuit of philosophy, done boldly and with integrity, shatters many illusions. Behind them, I am happy to say, we find other illusions: but brighter, bigger, more open illusions.

Can humans exist without illusion? Perhaps not. If we can't have knowledge, nonetheless there needs to be a fabric to our psychological lives. What else but illusion, or what we can more charitably call opinion? Plausibly, as Nietzsche suggested in On Truth and Lies in a Non-Moral Sense, "we produce these representations in and from ourselves with the same necessity with which the spider spins." (This quote was paraphrased in [this Partially Examined Life podcast](https://www.youtube.com/watch?v=WA2-s8TJrPc&t=31s), which is how I learned about it.)

To phrase the point more charitably, humans need to form opinions about the world; we make them on the basis of flawed information; and they are therefore subject to revision and update.

This point is a truism when said this more charitable way. I first presented it in the most extreme formulation I could in order to make as clear as possible where we should look for interesting implications of what's being said and for potential objections to the theory.

The general weakness of what we have said so far is that it is overly wiggly and relativistic, and overly abstract, lacking in practical applicability. Our epistemology so far has many appropriate degrees of freedom. But, it is like a helpless infant, not yet useful for anything. This is because it lacks constraints. We need to figure out how constraints get into the picture.

Let's take stock of the degrees of freedom we gathered into our epistemology in the preceding section.

* It is not agreed what knowledge is.
* It is not agreed whether humans have knowledge.
* Arguably, we might know stuff without knowing that we know it, and knowing that we know that we know it, etc.
* Instead of knowledge, for various purposes we might settle for justified true belief, or mere true belief, or merely setting eyes on the truth.
* There are many ways one can understand the meaning and value of "truth" and "true." The interpretation of these words is relative to the context.
* Questions about truth can be understood as normative questions by referencing them to norms of assertion.

Those are some of the degrees of freedom that seem to exist in epistemology based on what we've said. Now let's try to identify some of the epistemic constraints under which humans operate. Most of the time it is epistemic constraints, and not epistemic degrees of freedom, that we really care about. The reason for this is that epistemic constraints enable us to say what is not the case, providing a type of certainty that we can use to solve practical problems.

Let's do a thought experiment to introduce the notion of epistemic constraints. Imagine that your individual conscious mind was in total control of its own experience. This would be the case for an individual consciousness that was the entirety of the universe it was in, that therefore experienced nothing other than itself and its own self-created imaginations and illusions. If such a consciousness was like our own, we can imagine that it would readily discover itself to be in total control of its reality, and that it would experience whatever it pleased forever. Let us call such a consciousness a **totally isolated consciousness**.

It's conceptually plausible, in my opinion, that such a consciousness, without spontaneous experience based on external forces, might not ever form any ideas, feelings, or other experiences apart from the experience of self-awareness of a self which is nothing but bare awareness of awareness. On the other hand, we can also imagine a totally isolated consciousness with the possibility of imagination.

If a totally isolated consciousness had the possibility of imagination, then it could create realities within itself. These realities, though imaginary, would be just as real as any other part of the universe that the totally isolated consciousness was. The consciousness, however, would presumably always be aware that these creations were its own and could be gotten rid of or replaced whenever it wanted. This consciousness would therefore have near-total epistemic freedom, but it might lack the epistemic freedom to believe in the experience of a reality outside itself that it was unable to control.

The only way I can think of that a totally isolated consciousness could gain this freedom would be if it were able to trick parts of itself into losing awareness of its membership in the rest of itself. Those parts of itself could interact with the rest of itself, mistaking the rest of itself to be some kind of external reality. Let us call such a part of a totally isolated consciousness a **separated sub-consciousness**.

Our experience as humans is quite different from the experience of a totally isolated consciousness, but analogous to the experience that a separated sub-consciousness of a totally isolated consciousness might have.

As humans, we have the experience of forces outside ourselves that make our own subjective experiences not entirely subject to control by our individual conscious minds. We have the experience of an enormous variety of different things and the ability to actualize an uncountable number of distinct possible futures, but not the ability to decide completely the contents of our experiences.

This, in my opinion, is basically where constraints in epistemology come from. A totally isolated consciousness would, I think, be essentially epistemically unconstrained, assuming it had the abilities of imagination and of forming separated sub-conciousnesses. A totally isolated consciousness without imagination might be nothing but a bare consciousness of consciousness. A totally isolated consciousness with imagination but without the ability to form separated sub-consciousnesses might have the epistemic constraint that it would be unable to believe in a reality outside its control.

Humans are not like totally isolated consciousnesses. We have epistemic constraints, and they come from the fact that we don't completely control our own experiences. We explain the uncontrolled part of our experiences by the theory that there is an external physical world populated by people much like ourselves, who also have consciousnesses and internal experiences. I don't think we know this, but it is nonetheless the fundamental theory underlying almost everything we do, and I don't propose to stop using the theory to navigate my experiences. I don't know there is an external world populated by people much like myself who also have consciousnesses and internal experiences. I do, however, operate under these assumptions, believe said assumptions, and assert that said assumptions are true.

More generally, let **X** be some simple statement about the ordinary world of common sense which I have clear evidence for: e.g., "there is a pen on the desk I'm typing at." I operate under the assumption that **X**, believe that **X**, and consider it warranted for me to assert that **X** is true, but I don't claim to know **X**.

What is the word "warrant" that I have used a couple of times now, most recently in the previous paragraph? As I'm using it in this text, "warrant" is a placeholder for whatever standard of assertibility is appropriate to a given context. Relative to a given conversational context, "it is warranted to assert **X**" means that asserting **X** is a good move in the game which is the given conversational context.

The concept of warranted assertion, understood in this way, takes in more than justification, evidence, or proof. It also takes in general concerns of appropriateness, such as relevance and politeness. It takes in every positive and negative force within the ambient social game which weighs on the decision to make or not make the assertion. Warranted assertion, understood in this way, is a highly situation-specific concept. In this conception, there is no general standard of warranted assertibility; there are only different standards appropriate to different situations (and in different people's opinions).

Though there is no general standard of warranted assertibility, there are things that should generally be in a standard of warranted assertibility. There are techniques of reasoning that have been observed to work generally, across all or many problem domains. There is a simple argument for accepting the use of these techniques of reasoning to govern norms of assertion when they are applicable: namely, that it works. 

In the rest of this text we are going to spend a lot of time thinking about what should generally go into our concepts of warranted assertibility. What rules of logical inference should play a role? What rules of probabilistic and inductive reasoning should play a role? What else should play a role? In each case, the questions are, how widely does it work, and where does it fail? Our goal is to build a toolkit of tools of reasoning, tools for governing norms of assertion, tools for advancing debates, which work across all or many problem domains.

## Meaning

What is meaning? We discussed this question briefly in the section titled Language. Let's recall in summary what I said back there.

I drew a distinction between three types of meaning: speaker meaning, listener meaning, and sentence meaning. Speaker meaning is what a speaker intends to mean by a sentence in a particular instance. Listener meaning is what a listener takes a sentence to mean in a particular instance. Sentence meaning is what a sentence means in itself according to the conventions of a language. 

In the field of formal semantics, people give mathematical definitions of sentence meaning for formal languages. The same kind of analysis can be done informally but not exactly or comprehensively with natural languages. I pointed out that it is not feasible to give a definition of English sentence meaning that works across the board, because of the complexity and variability of English language use. We can still usefully talk informally about "the conventional notion of English sentence meaning," even though the concept breaks down after a certain point.

I pointed out a competition between two general approaches to understanding linguistic meaning: psychological approaches, and non-psychological approaches. 

The problem with psychological approaches that I pointed out in the section on Language is that (arguably) psychology is mostly inscrutable. I think this is the biggest reason for the attractiveness of non-psychological approaches to understanding meaning.

In my opinion, the non-psychological approaches to the philosophy of linguistic meaning are off track in that they have failed to ask the right question. For me, linguistic meaning is by definition a kind of phenomenon that occurs inside human minds. I would compare a meaningful linguistic utterance to a key that opens some door in an appropriate listener's mind. A lot of non-psychological approaches to understanding linguistic meaning, in my opinion, can be compared to attempting to figure out what's behind a door by inspecting the shape of the key that opens it.

In summary, I take a psychological approach to the philosophy of linguistic meaning, because linguistic meaning is a phenomenon in the human mind.

More specifically, I take a phenomenological approach to the philosophy of linguistic meaning. This means that the basic objects of study in my theory are experiences of meaning caused by language. Since my own experiences are the only experiences I can directly observe, those are the basic objects of study that I have access to.

According to my theory, **a linguistic meaning** is an experience causing production of or caused by consumption of a linguistic utterance in a particular instance. The **speaker meaning** of an utterance is the meaning which the speaker of the utterance intended to convey. For each person who hears a given utterance in a particular instance, there may be zero or more **listener meanings**. A listener meaning of an utterance is any meaning which the listener takes from the utterance.

There are different kinds of listener meanings. In the most typical case of successful literal communication, there is one listener meaning, and it is the same (or nearly enough) as the speaker meaning. A listener may form no listener meanings, e.g. if they aren't paying attention or don't understand. A listener may form multiple conflicting ideas of what the speaker might have meant (a situation in which a follow-up question is usually recommended). A listener meaning may be a misunderstanding, where the listener forms a meaning and falsely assumes that it is the speaker meaning. A listener may also form a misunderstanding which they recognize to be an obvious misunderstanding, but which comes to mind nonetheless, e.g. perhaps because it is humorous. These are not the only kinds of listener meanings.

Speaker meanings can also involve complexities such as double meanings, sarcasm, and irony. When a speaker intends to convey a double meaning, it seems fine to me to say either that there are two speaker meanings, or that there is one speaker meaning with two aspects or layers.

The foregoing gives us a basic theory of what meaning is and how to study it further. According to the theory, linguistic meanings are experiences pertaining to utterances, and they are of two types: speaker meanings and listener meanings.

**Communication** is basically the attempt to coordinate speaker meanings and listener meanings in such a way that we achieve something we call shared understanding. This involves, among other things, a level of agreement on what statements are true and false, and the appearance of meaning the same things by words and sentences. 

There are many aspects to communication, and I encourage the reader to pursue education in communication beyond this book. TODO: Where?

A model of communication that I like is the [Shannon-Weaver model of communcation](http://ieeexplore.ieee.org/document/6773024/?reload=true&tp=&arnumber=6773024). According to this model, communication involves the following components:

 * The **sender**: a person, let's say.
 * The **receiver**: a person' let's say.
 * The **channel**: the medium of communication. E.g., the atmosphere.
 * The **encoder**: the technology used to create a transmission through the channel. E.g., the human vocal system.
 * The **decoder**: the technology used to receive a transmission through the channel. E.g., the human ear.
 * The **noise**: entropy which degrades transmissions through the medium. E.g., ambient background noise in the atmosphere.

According to the Shannon-Weaver model, communication always involves two-way **feedback**. Feedback is a process by which the sender+encoder and receiver+decoder coordinate messages in a way that allows them to verify to their satisfaction that shared understanding is occurring.

Solving difficult communication problems often requires using new kinds of efforts to achieve communicative feedback. One simple way of achieving communicative feedback is to repeat back what somebody said to you in your own words, to verify you understand. Requests for clarification are another simple form of feedback. Body language and facial expressions also provide feedback: e.g., teachers often rely on students' facial expressions for feedback on whether they are understanding the material. One of the most complex forms of communicative feedback is the process of philosophical debate. This is a form of feedback which one must sometimes employ in order to coordinate communication on deep or difficult-to-articulate problems.

Here's a way we haven't yet sliced the set of meanings. Some meanings are explicit, and some are implicit. For example, suppose my boss asks me, "could you schedule a meeting to discuss X?" Explicitly, he is asking me whether I am capable of doing something. Implicitly, he is requesting that I do something. This sentence therefore has an **explicit meaning** (querying a capability) and an **implicit meaning** (requesting an action).

An implicit speaker meaning we can also call an **implied meaning**. An implicit listener meaning we can also call an **inferred meaning**.

What is behind this distinction between implicit and explicit meanings? What is an explicit meaning? What is an implicit meaning? And how is the concept of explicit meaning related to the concept of sentence meaning, or conventional literal meaning? Are explicit meaning, sentence meaning, and conventional literal meaning all the same concept by different names, or are they different concepts?

Explicit meaning and sentence meaning are not the same concept. As you can see by inspecting the name, sentence meaning is a concept that applies only to the meanings of sentences. On the other hand, any piece of language can have an explicit meaning (including paragraphs, words, etc.). 

For the same reason, conventional literal meaning and sentence meaning are not the same concept.

Are explicit meaning and conventional literal meaning the same concept? I think so. As of yet I see no distinction. The concept of explicit/conventional literal meaning is, to recall, a fuzzy concept which apparently won't ever practically be fully detailed or fully well defined.

That brings our textual exploration of meaning in this text to a close. In the phenomenological theory of meaning which I endorse, the primary way of studying meaning is introspectively, studying the range of experiences that are possible to one's mind and understanding how experiences correlate to language in oneself and others. This is mostly a solitary pursuit, in my view, because of the impossibility of finding experiences of meaning outside one's own consciousness, and the difficulty of talking about the fine shadings and qualities of experience. I will always talk about this stuff as much as I can figure out how.

## Rationality

What is rationality? "Rationality," being a nebulous, imprecise term, can mean many different things. However, our goal here is not to explore everything the word could or should mean. Our goal is develop a usable, practical undarstanding of rationality.

It is not productive to try to answer question "what is rationality?" by coming up with a dictionary definition of rationality, a sentence of the form "rationality is..." Rationality is too complex a concept to explain with a dictionary definition.

Here is a first pass attempt at explaining rationality in practical terms. Rationality is in part a set of practices people employ in solving problems. Rationality is involved in the processes we use to organize ourselves into complex societies, develop technologies which improve our standard of living, cure diseases, discover the truth, and solve resource distribution problems (through systems such as regulated capitalist, socialist, and mixed-model economies), among many other things.

Given the immense practical importance of rationality, we don't want to approach the understanding of rationality as a purely theoretical problem. We want to approach it as a practical problem, so that our solution will be as useful as possible to as many people as possible. Our goal is not to develop the most rigorous theory possible, but to develop the most usable, and yet correct theory possible.

We can study rationality from a psychological perspective, by speculating about people's inner states, primarily their processes of belief formation, and by making prescriptive recommendations about how to form beliefs in order to be rational. 

I think it's very informative to think about rationality by thinking about the kind of moral virtues that a person should seek to have in order to be rational. Here some moral virtues that I think of as contributing to or being requirements for rationality (in no particular order):

* Fairness
* Even-handedness
* Patience
* Attention to detail
* Open-mindedness
* Skepticism
* Skepticism of authority
* Self-confidence
* Love for learning
* Skill at listening
* Skill at articulating
* Honesty
* Thirst for truth

Rationality is not a natural state of the human mind. It's a state which is achieved through hard and determined effort towards the right kinds of goals. It's a state which is never perfectly achieved. One is never finished in the development of one's rationality. It's a life-long learning experience, a path not a destination.

The heart of rationality I also call the Tao of rationality. The Tao of rationality is a mystery, a placeholder for our lack of comprehensive understanding of our own ability to reason, consequent of our minds' present inability to comprehend themselves in any great depth.

The Tao Te Ching purports to contain ancient wisdom applicable to every kind of problem. In this case we're mining it for wisdom about the practice of rationality. I'll give you a passage, and then I'll tell you what it brings to mind for me.

    The tao that can be told
    is not the eternal Tao
    The name that can be named
    is not the eternal Name.

    The unnamable is the eternally real.
    Naming is the origin
    of all particular things.

    Free from desire, you realize the mystery.
    Caught in desire, you see only the manifestations.

    Yet mystery and manifestations
    arise from the same source.
    This source is called darkness.

[From Chapter 1 of [Stephen Mitchell's translation of the Tao Te Ching](http://acc6.its.brooklyn.cuny.edu/~phalsall/texts/taote-v3.html).]


Human ability to reason outruns our ability to understand our processes of reasoning on a second-order level. Reasoning is a capability of our minds. Our minds are very complex and our understanding of them is very rudimentary.

Our processes of reasoning are the outcome of a process of biological and social evolution, consisting of the Darwinian evolution of our brains and the transmission and evolution of intellectual DNA forward through history.

Our rules for reasoning are essentially encoded in our languages. Our languages are complex organs with many subdivisions such as mathematical language and technical jargon of various fields, which are outposts dotted around a complex, generalized "everyday" language.

The most important wisdom about reasoning is contained in the rules governing our everyday languages. Good argumentation is mostly a matter of using everyday language in a way which adheres rigorously to common sense best practices of clarity and thoroughness. In other words, deeply understanding common sense about how to use language when attempting to discern the truth is the most important aspect of the development of rationality.

Each of us is much more hidden than we are visible to ourselves and each other, as most of our functioning goes on unobserved inside our bodies and our unconscious minds. Our rationality is a still pond which runs deep. On the surface it is receptive to outside impressions and it reflects the world back at the world. Its depths are dark and mysterious.

A person who wishes to become more rational must seek to manifest their inner rationality in a greater proportion of their conscious experience. They must seek to hone the skill of being that still pond which reflects the world back at the world. In my opinion, this is ultimately a spiritual quest, where one is led to seek to heal old emotional wounds, to face one's fears, and to nurture one's confidence and humility alike, in order to have fewer mental weights holding down one's rationality.

    The supreme good is like water,
    which nourishes all things without trying to.
    It is content with the low places that people disdain.
    Thus it is like the Tao.

    In dwelling, live close to the ground.
    In thinking, keep to the simple.
    In conflict, be fair and generous.

    [ch. 8]

Good reasoning is full of uniform and repeatable patterns. Some of these repeatable patterns can be systematized: for example, deductive logic, mathematics, and science all have a corpus of repeatable reasoning techniques of various degrees of formality. Understanding these patterns is important to the development of rationality.

However, knowing all the techniques of rationality does not give one the practical, procedural knowledge of being rational.

    When you have names and forms,
    know that they are provisional.
    When you have institutions,
    know where their functions should end.
    Knowing when to stop,
    you can avoid any danger.
    
    [ch. 32]

The heart of rationality is a groundedness in reality and a willingness to be swayed by reality created by a kind of emptiness and lack of preconception.

    We join spokes together in a wheel,
    but it is the center hole
    that makes the wagon move.

    We shape clay into a pot,
    but it is the emptiness inside
    that holds whatever we want.

    We hammer wood for a house,
    but it is the inner space
    that makes it livable.

    We work with being,
    but non-being is what we use.

    [ch. 11]

Of course, the moral virtues associated with rationality are merely one aspect of rationality. In my opinion they are a critical one which should be discussed explicitly in treatises on rationality. In my opinion, anybody who seeks to become more rational should seek to cultivate in themselves the virtues I listed above (fairness, even-handedness, etc.); to seek the company of people who have such virtues; and to learn from sources which have such virtues. I would further encourage the reader to reflect on the deeper nature of rationality in an introspective fashion: to study their own mind, how it works, how it processes reality, and to form judgments on which processes are rational and which are irrational.

In addition to looking at rationality from psychological, moral, and spiritual perspectives, we can also study rationality from a behavioral perspective, by studying human behavior that exhibits rationality and trying to formulate rules that describe and explain what makes rational behavior rational. 

Rationality has to do with two primary areas of human behavior: communication and decision making. We employ rationality in communicating with each other, as when employing arguments to persuade others of something. We also employ rationality in decision making, as when making a purchasing decision, and in innumerable other situations.

In practice most rationality-related issues can be studied in the context of norms of assertion. Studying norms of assertion is studying the majority of what there is to study about rationality, at least in my awareness. Of course other topics besides norms of assertion, e.g. beliefs and decision making, are important. Most rationality-related issues apply analogously across all subdomains of rationality (e.g. norms of assertion, beliefs, and decision making). Therefore by studying one of these subdomains, one learns about all of them. However, each should also be studied individually to learn about issues specific to that subdomain.

I find it more effective, as a way of teaching, to focus primarily on one of the many angles from which we can study rationality. This is because we can go deeper into that one angle by spending more time on it, and doing so sheds light on all the other angles. The primary angle I choose is norms of assertion primarily for the reasons that it's the one I understand best, and it's the one I best understand how to talk about.

One thing about norms of assertion that makes them easy to talk about is that unlike beliefs, which are mental phenomena and therefore only privately observable, assertions are objective, publicly observable occurrences.

Our language is primarily for talking about publicly observable things, and it's easier overall to have shared understanding of publicly observable things. Both of these factors lead me to favor focusing my philosophical writing on publicly observable things.

If I can explain the same thing either in terms of publicly observable things or in terms of privately observable things, I am more likely to choose to explain it in terms of publicly observable things, because I am more likely to think that route will lead to a clearer explanation.

Norms of assertion are an important subtopic in the more general topic of **laws of rationality**. The laws of rationality are all of the rules of speech and behavior such that if we break them, we can justly be called irrational. 

A simple example of a law of rationality is the law that if you agree to the assertion that (**A** and **B**), then you should also be willing to agree to the assertion that **A**. Probably the reader knows or imagines that there are many laws of rationality. Discovering exactly what they are is the problem.

On my reading, discovering what the laws of rationality are has been the foremost goal of the study of rationality since that study's inception. As long as we don't understand and apply the laws of rationality, we will run the risk of being irrational without having any idea we are being irrational. That's why I think it's valuable to learn well the understanding (or so called) humans have had of the laws of rationality for thousands of years, as well as the understanding (or so called) we have recently gained, and to try to push forward our evolving understanding (or so called) of the laws of rationality.

In the section on rules and laws, we noted that all laws are binding in some sense. In what sense are the laws of rationality binding? In many different senses, in many different contexts:

* In debates, the laws of rationality are binding in the sense that in the world of debates, there is a loose approximation of a Nash equilibrium around following the laws of rationality as well as one is able. The laws of rationality are broken on a regular basis in debates, probably in most debates. However, there is a general agreement that in some sense those who break the rules of rationality are not debating correctly, and those who break them are more likely to lose debates.
* In academic contexts, the laws of rationality are binding as a matter of professional standards. In the context of academic publishing, the laws of rationality are enforceable (and sometimes corruptible) by the peer review process.
* In many professional contexts, such as when performing a technical job such as software development or security analysis, the laws of rationality are binding as a matter of professional ethics, especially in mission-critical scenarios.
* In serious contexts where you need to solve a problem, rationality is usually applicable. In these cases, the laws of rationality are binding in the sense that following them usually maximizes your likelihood of success.
* There is a loose approximation of a Nash equilibrium in the global game of society around making decisions as rationally as one is able.

If following a set of principles of rationality reduced your likelihood of success, then those principles would be a flawed way of thinking about rationality. Observe that this is not a [no true Scotsman fallacy](https://en.wikipedia.org/wiki/No_true_Scotsman), because we are not changing the definition of rationality in an ad hoc way to deal with counterexamples. Rather, the principle that methods that systematically cause you to fail aren't rational is part of our common sense understanding of rationality. See Eliezer Yudkowsy, ["Rationality is Systematized Winning,"](http://lesswrong.com/lw/7i/rationality_is_systematized_winning/) if you wish to be persuaded further of this.

There is no centralized authority on rationality. Generally speaking, rationality's dominance can be attributed to the fact that it gets shit done, that it wins. No centralized enforcement is necessary to maintain its dominance; it's a natural consequence of the way that rationality relates to human society as a whole, which is a consequence of properties of rationality, human society, humans, and the world. This situation also means that the dominant understanding of rationality should, over time, naturally tend towards greater correctness. In short, the laws of rationality are organically binding.

Of course, rationality is in competition with other conflicting forces: for example, ignorance. Rationality isn't always dominant, and this qualifier should be stated, though I don't believe it conflicts with anything we've said.

Here's a basic law of rationality, a basic norm of assertion, which we'll call the **law of evidence**: if you assert a statement, you should (ideally) be able to explain your reasons for believing it, and those reasons should (ideally) be good ones.

If you assert a statement, and somebody asks you why it's true, and you can't provide any good answer, it's generally an uncomfortable situation where one feels some social pressure to take back the assertion. 

The law of evidence is widely accepted because it is a good rule to follow if you want the truth. If you want the truth, it's a good idea to be skeptical of what other people say, to ask for the reasons that people assert things, and to doubt people who can't give good reasons for what they assert. If you want to be regarded as a truth-teller, it's a good idea to be able to give good reasons for the things you assert.

The law of evidence is the basic rational norm of assertion, in a sense. Most other laws of rationality have to do with legislating what reasons do and do not adequately support an assertion. In that sense they are elaborations on the law of evidence. Legislating the quality of various reasons for assertions is our main task in the rest of this text. Before starting on that, though, we need to clarify what we are talking about when we talk about reasons.

## Reasons

What are reasons? I am specifically trying to probe the meaning of the word "reason" which is used in the first three paragraphs of the Introduction, which we are still in the process of unpacking. This usage is in the definition of "argument." I defined an argument as "a series of statements designed to provide reason to believe some conclusion(s)." I could also have written "reasons" or "reason(s)" in this definition in place of "reason," without really changing the meaning. We are interested in defining "reason" as the term is used in the definition of "argument." Though that's our primary goal, we'll need to explore the meaning of the word "reason" in a more general way in order to get there.

We say things like:

1. "Euclid's proof provides reason to believe that there are infinitely many prime numbers."
2. "Euclid reasoned that there are infinitely many prime numbers."
3. "Euclid's proof reasons that there are infinitely many prime numbers."
4. "Euclid had great mastery of reason."
5. "Euclid presumably had his reasons for doing math."

In sentence 1, "reason" looks like a noun, a kind of special substance contained somehow in Euclid's proof. In sentence 2, "reason" occurs in a verb form, denoting some kind of activity of Euclid. In sentence 3, "reason" occurs again in a verb form, but now apparently denoting some kind of activity or potency of Euclid's proof. In sentence 4, "reason" occurs as a noun, now seeming to denote an area of study or expertise. In sentence 5, "reason" occurs as a plural noun, now referring to motivations, justifications, and/or rationalizations that Euclid presumably had for his choice to pursue math.

"Reason" is a versatile term that can be used in many different ways. There is some common theme flowing through these different usages: some common thread between the rational substance contained in Euclid's proof, and the rational activity of Euclid, and the rational activity or potency of Euclid's proof, and Euclid's mastery of reason, and perhaps even Euclid's reasons for doing math. If we want to take Euclid's proof as a good example of reasoning, and study it to understand reasoning better, then we can try to examine the proof, and we can do so from various perspectives. We can also try to examine Euclid, and try to discover what qualities in him made him able to produce the proof and motivated him to do so.

Examining reason from all possible perspectives and giving equal time to each in this text would make our lives confusing and difficult. In practice, I think a more useful approach is to choose one primary perspective from which to examine reason, understand reason well from that perspective, and then use that as a jumping off point for developing a more holistic and integrative understanding of reason.

I have already chosen the sense of "reason" that we are primarily going to investigate. This is the sense used in the definition of "argument," which is "a series of statements designed to provide reason to believe some conclusion(s)." In other words, I am interested in the kind of reasons that arguments are supposed to provide for their conclusions. Let's now investigate the meaning of "reason" in this sense.

Arguments are series of statements, and reasons are something that they intend to provide for their conclusions. Taking this literally, reasons are some sort of supervenient phenomena which emerge from properly formulated arguments. This illustrates the risks that can be involved in taking language too literally when doing philosophy. We can be led to remarkable and confusing conclusions in this way.

We're not going to assume that there is literally a kind of entity in nature called a "reason." Statements that provide reasons exist, but we're not going to assume that we can equate a reason with the statements that provide it, and we're not going to assume that some statements are decorated with some sort of metaphysical entity called a reason.

If you like, you can think of "provide reason to believe" as a non-decomposable phrase denoting a relation between series of statements (arguments) on the left hand, and statements (conclusions) on the right hand. If this is correct, then there are many other English phrases which denote the same or approximately the same relation as "provide reason to believe," e.g. "provide justification," "provide evidence," "argue effectively," etc. And there are others which seem to denote different but related relations between arguments and conclusions, e.g. "prove," "demonstrate conclusively," "argue fallaciously," "argue poorly," etc. Taking all of these phrases to be non-decomposable phrases denoting relations having to do with providing reasons has the advantageous consequence of giving us a way to think about reasoning without getting stuck on the idea that there is some such thing as a "reason" which ought to be an object of our investigation.

Despite the appearances suggested by our grammar, what we're actually interested in are not a kind of entities called reasons, but a certain relation between arguments and their conclusions, the relation of providing reasons for.

We can therefore formulate our question as follows: what arguments provide reason to believe what conclusions? Obviously this is a very broad question, and what we're interested in is a general method or body of theory that lets us answer the question in any particular case, or at least in as many particular cases as possible.

Another way of formulating our question is as follows: which arguments are winners, and which are losers? Every properly formulated argument states what its conclusion is. If an argument provides good reason to believe its conclusion, then we can say the argument is a winner. If argument provides bad reasons or no reasons to believe its conclusion, then we can say the argument is a loser. Then we can describe what we're interested in as a general method or body of theory for distinguishing between winning and losing arguments.

The way to develop such a method or body of theory is to start by looking at lots of particular arguments, figure out which ones are winners and losers on a case by case basis, and on that basis begin to formulate general rules about what arguments are winners and losers. This is very slow, methodical work, and in doing it we are retracing the steps of philosophers who have thought about these issues for thousands of years. In developing the theory of discriminating between winning and losing arguments presented in the rest of this text, my goal is not to discover anything new, but to formulate what has already been understood by those who looked at this before, in the most correct and useful way possible.

What we are looking to study are **laws of reasoning**. Laws of reasoning are generalizations which guide us in understanding what arguments are winning.  Laws of reasoning help us to evaluate the quality of arguments by telling us what methods of argumentation do and do not work. They are the essential theoretical ammunition that one needs to win arguments.

One example of a law of reasoning is that properly formulated *reductio ad absurdum* arguments are winning. This law is basically correct. However, our formulation of it is still imprecise, and we should seek greater precision in describing the law. Furthermore, there is plenty of controversy around the *reductio ad absurdum* principle among logicians, which we should review. 

The overall primary aim of the text up to this point has been defining and analyzing important concepts that allow us clearly articulate the goal we are now setting to describe laws of reasoning. 

Of course, we don't just want to describe any laws of reasoning. We want to describe laws of reasoning that are correct, or true. It's a messy question what exactly this means, especially because there are very few laws of reasoning which entirely lack plausible counterexamples (cases where they allow one to infer false conclusions from plausibly true premises).

Let's now get into the weeds with our first important category of laws of reasoning: laws of logic.

## Logic

**Logic**, as I shall describe it, is a field of study where the primary topic is valid rules of logical inference. Let's unpack that.

A **rule of logical inference**, or **rule of inference**, is a rule which states that in any conversational context where a set of statements with given forms (**premises**) are warranted assertible, another statement (the **conclusion**) is warranted assertible. This is my definition.

Let's give some examples of rules of inference for statements in the language of first-order logic.

 * (**A** and **B**) entails **A**.
 * (**A** and **B**) entails **B**.
 * **A**, **B** entails (**A** and **B**).
 * **A** entails (**A** or **B**).
 * **B** entails (**A** or **B**).
 * (if **A** then **B**), **A** entails **B**.

The statement of each of these rules consists of: a sequence of statement forms, the word "entails," and a single statement form at the end. By a "statement form," I mean a first-order logic statement with meta-variables (**A** and **B** in these examples) holding the place of some parts of the statement.

Rules of logical inference can be thought of as descriptive rules, by taking them to describe regularities in people's standards of warranted assertibility. For example, in just about any conversational context, for just about any statements **A** and **B**, just about any speaker who considers (**A** and **B**) warranted assertible in that context will also consider **A** warranted assertible in that context. This is one way of interpreting the meaning of the rule of inference "(**A** and **B**) entails **A**."

Rules of logical inference can also be thought of as prescriptive rules, by taking them as defining norms of assertion. For example, the rule of inference "(**A** and **B**) entails **A**" can be taken to be the normative rule that in any context, for any statements **A** and **B** which are interpretable in that context, if a speaker considers (**A** and **B**) to be warranted assertible in that context, then they should also consider **A** to be warranted assertible in that context.

We are basically interested in the following questions. In general, what rules of logical inference are correct as descriptive rules? And, what rules of logical inference should we accept as prescriptive rules? These two questions are closely related. We want to figure out what level of consensus exists around each proposed rule of logical inference, which tells us how correct it is as a descriptive rule. This then becomes the primary consideration in deciding what rules of inference to accept as prescriptive rules.

Rules of logic are about as close as we can get to universal rules for debate. For all that philosophers disagree about almost everything, there is virtually no disagreement that in any or just about any context where a statement of the form (**A** and **B**) is warranted assertible, the statement **A** is also warranted assertible. This is a very simple and self-evident rule, which might not appear to be good for much. In itself, it isn't good for much.

The beauty of logic is that by chaining together long sequences of applications of simple, self-evident rules like this one, one can bring one's listeners along on a journey to a final conclusion that may be very surprising to them, that probably they would not have accepted if they hadn't been presented with such a compelling sequence of logical inferences. Logic ends up being one of the great sources of common ground in debates.

Rules of logical inference can also be called **argument forms**. The term "argument form" is somewhat more neutral in that "rule of inference" may carry the connotation "correct rule of inference" to many listeners, whereas the term "argument form" more explicitly encompasses incorrect rules of inference as well as correct ones. Again, though, both terms literally mean the same thing, as I am using them.

A **case** of an argument form is an argument resulting from substituting concrete expressions for the meta-variables in the argument form. For example, in the argument form "(**A** and **B**) entails **A**," the spaces held by meta-variables are the spaces held by **A** and **B**. Here are some cases of this argument form:

* (Spot is a dog and Spot runs) entails Spot is a dog.
* (Barack Obama is POTUS and POTUS is male) entails Barack Obama is POTUS.

Here are some non-examples of cases of this argument form:

* (Spot is a dog and Spot runs) entails Spot runs.
* (Barack Obama is POTUS and POTUS is male) entails the sky is blue.

I will call an argument form **valid** for a given person if and only if there are no **counterexamples** to the rule for that person. A counterexample to an argument form for a given person is a (hypothetical or real) truth-seeking debate context and a case of the argument form where they consider the premises warranted assertible and don't consider the conclusion warranted assertible. I will only consider a counterexample to an argument form to be genuine if even after participating in thorough discussion and evidencing a good understanding of the relevant issues, the person with the counterexample still finds the premises warranted assertible and the conclusion not warranted assertible.

When an argument form is valid for people in general, we will call it simply "valid." "(**A** and **B**) entails **A**" is an example of a valid argument form. We can also call it a valid rule of logical inference, since every argument form is a rule of logical inference and vice versa.

We are now in a position to articulate our main question about logic. **What rules of logical inference are valid?** This question is implicitly relative to some language. We will use the language of first order logic for our investigation.

What language we choose for our investigation is not an entirely neutral choice. When we give formal definitions of rules of inference for a formal language, the syntax of the language imposes constraints on the rules we can straightforwardly formulate. For example, in [second-order logic](https://en.wikipedia.org/wiki/Second-order_logic) we can easily express rules of inference that have no straightforward expression in first-order logic.

The syntax of first-order logic is specially chosen to make standard rules of logical inference easily expressible. First-order logic is as complex as necessary to define enough rules of logical inference to do all of mathematics, but not more complex than necessary to accomplish this. We can feel good about our choice of language for investigating rules of logical inference.

There is a standard, widely accepted answer to what rules of logical inference are valid for first-order logic. This answer is a set of rules called **classical first-order logic**, or **classical logic** as we shall abbreviate it. There is controversy among academic logicians about whether all the rules of classical logic are valid. Few logicians think there are any valid rules of inference for first-order logic that are not part of classical logic. A greater number of logicians think that not all rules of classical logic are valid. It should be noted that the logicians in this debate employ various definitions of "valid" which may not always coincide.

We will start our way into this central debate in the study of logic by looking at the rules of classical logic.

There are infinitely many rules of inference or argument forms that are valid according to classical logic. In order to describe the rules of classical logic in a finite amount of space, we need to use abstraction.

The way the rules of classical logic are conventionally presented is by giving a finite number of rules which allow all of the valid rules of inference or argument forms to be generated. There are a variety of ways of doing this: via [natural deduction](https://en.wikipedia.org/wiki/Natural_deduction) systems, via [sequent calculi](https://en.wikipedia.org/wiki/Sequent_calculus). Here I will do an informal presentation of a sequent calculus formulation of the rules of classical first order logic.

My presentation is most closely based on the style of presentation of first-order logic articulated in [Dave Ripley's](http://davewripley.rocks/) graduate philosophical logic course taught in spring 2014 at the University of Connecticut. Credit for the original conception of the rules of classical first-order logic is best claimed by Gottlob Frege, as far as I'm aware.

This presentation requires a concept that is new for us: the concept of multiple-conclusion sequents.

A **sequent** is simply an entailment between first order logic statements. ((Pa and Pb) entails Pa) is an example of a sequent.

A **multiple-conclusion sequent** is one with multiple conclusions. ((Pa or Pb) entails Pa, Pb) is an example of a multiple-conclusion sequent. In general, a multiple-conclusion sequent has the form (**A1**,...,**An** entails **B1**,...,**Bm**).

The notation **A1**,...,**An** stands for any finite sequence of statements. **n** is supposed to be a variable standing for a number. **n** could be zero, in which case this denotes an empty sequence of statements. **n** could also be one, or any higher number. **B1**,...,**Bm** is another instance of the same notation. Of course the sequences **A1**,...,**An** and **B1**,...,**Bm** may be of different length. A multiple conclusion sequent has zero or **premises** and zero or more **conclusions**. Our presentation of classical logic is based on multiple conclusion sequents, so henceforth "sequent" is short for "multiple-conclusion sequent."

A sequent (**A1**,...,**An** entails **B1**,...,**Bm**) should be interpreted for our purposes as stating that it is incoherent to assert all of **A1**, ..., **An** and to deny all of **B1**, ..., **Bm** at the same time. If what the sequent states is true, we say that the sequent is **valid**.

The sequent ((Pa and Pb) entails Pa) is valid. It states that it is incoherent to assert (Pa and Pb) while denying Pa.

The sequent ((Pa or Pb) entails Pa, Pb) is valid. It states that it is incoherent to assert (Pa or Pb) while denying both Pa and Pb.

This interpretation of the meaning of multiple conclusion sequents was taught to me by Dave Ripley, and as far as I know he is responsible for conceiving it. TODO: confirm

We have finished introducing the notion of multiple conclusion sequents. Let us proceed to the rules of classical logic.

The rules of classical logic are the rules that state what sequents are valid according to classical logic. A sequent is valid according to classical logic if and only if it can be deduced according to these rules.

**Rule of non-contradiction**

The first rule of classical logic states that any statement entails itself. For any statement **A**, (**A** entails **A**) is a valid sequent. This sequent states that it is incoherent to assert **A** and deny **A** at the same time.

**Conjunction rules**

The following rules in classical logic are related to conjunction ("and").

1. **Assertion strengthening.** Suppose (**A1**,...,**An**, **B**  entails **C1**,...,**Cm**) is a valid sequent. Then (**A1**,...,**An**, (**B** and **D**) entails **C1**,...,**Cm**) is a valid sequent. What changes between the "suppose" sequent and the "then" sequent is that **B** is replaced with (**B** and **D**). In other words, given an incoherent set of assertions and denials including the assertion of **B**, strengthening **B** to (**B** and **D**) gives you another incoherent set of assertions and denials. In a second version of this rule which is also a rule of classical logic, (**B** and **D**) is replaced with (**D** and **B**). A shorter (and less complete) way of stating the rule of assertion strengthening is to say that *if it's incoherent to assert **B**, then it's incoherent to assert (**B** and **D**) or to assert (**D** and **B**).*

2. **Denial weakening.** Suppose (**A1**,...,**An** entails **B**, **C1**,...,**Cm**) is a valid sequent, and (**D1**,...,**Dk** entails **E**, **F1**,...,**Fj**) is a valid sequent. Then (**A1**,...,**An**, **D1**,...,**Dk** entails (**B** and **E**), **C1**,...,**Cm**, **F1**,...,**Fj**) is a valid sequent. In the "suppose" we are given two incoherent sets of assertions and denials, the first containing a denial of **B** and the second containing a denial of **E**. The rule tells us that it is incoherent to assert the union of these two sets of assertions and denials, with the denials of **B** and **E** replaced with the denial of the conjunction (**B** and **E**). Denying the conjunction of (**B** and **E**) is weaker than denying each of **B** and **E** individually, because to deny the conjunction (**B** and **E**) is to deny that **B** and **E** are both true, which is equivalent in classical logic to asserting that at least one of **B** or **E** is false. It is also true that simply taking the union of these two incoherent sets of assertions and denials would give us another incoherent set, because adding anything at all to an incoherent set gives you another incoherent set. What the rule of denial weakening tells us is that it is still incoherent, given the setup of the "suppose," to combine the two sets and replace the separate denials of **B** and **E** with the weaker denial of just (**B** and **E**). A shorter (and less complete) way of stating the rule of denial weaking is to say that *if it's incoherent to deny **B** and it's incoherent to deny **E**, then it's incoherent to deny (**B** and **E**).*

**Disjunction rules**

The following rules of classical logic are related to disjunction ("or").

3. **Denial strengthening.** Suppose (**A1**,...,**An** entails **B**, **C1**,...,**Cm**) is a valid sequent. Then (**A1**,...,**An** entails (**B** or **D**), **C1**,...,**Cm**) is a valid sequent. What changes between the "suppose" sequent and the "then" sequent is that **B** is replaced with (**B** or **D**). In other words, given an incoherent set of assertions and denials including the denial of **B**, strengthening the denial of **B** to the denial of (**B** or **D**) gives you another incoherent set of assertions and denials. Denying (**B** or **D**) is equivalent in classical logic to asserting that **B** and **D** are both false, which is why it's stronger than denying just **B**. In a second version of this rule which is also a rule of classical logic, (**B** or **D**) is replaced with (**D** or **B**). A shorter (and less complete) way of stating the rule of denial strengthening is to say that *if it's incoherent to deny **B**, then it's incoherent to deny (**B** or **D**) or to deny (**D** or **B**).*

4. **Assertion weakening.** Suppose (**A1**,...,**An**, **B** entails **C1**,...,**Cm**) is a valid sequent, and (**D1**,...,**Dk**, **E** entails **F1**,...,**Fj**) is a valid sequent. Then (**A1**,...,**An**, **D1**,...,**Dk**, (**B** or **E**) entails **C1**,...,**Cm**, **F1**,...,**Fj**) is a valid sequent. In the "suppose" we are given two incoherent sets of assertions and denials, the first containing an assertion of **B** and the second containing an assertion of **E**. The rule tells us that it is incoherent to assert the union of these two sets of assertions and denials, with the separate assertions of **B** and **E** replaced with the mere assertion of the disjunction (**B** or **E**). It is also true that simply taking the union of these two incoherent sets of assertions and denials would give us another incoherent set, because adding anything at all to an incoherent set gives you another incoherent set. What the rule of assertion weakening tells us is that it is still incoherent, given the setup of the "suppose," to combine the two sets and replace the separate assertions of **B** and **E** with the weaker assertion of just (**B** or **E**). A shorter (and less complete) way of stating the rule of assertion weakening is to say that *if it's incoherent to assert **B** and it's incoherent to assert **E**, then it's incoherent to assert (**B** or **E**).*

**Conditional rules**

The following rules in classical logic are related to the conditional ("if/then").

5. **Conditional denial.** Suppose (**A1**,...,**An**, **B** entails **C**, **D1**,...,**Dm**) is a valid sequent. Then (**A1**,...,**An** entails (if **B** then **C**), **D1**,...,**Dm**) is a valid sequent. In this rule, the premise or assertion **B** of the sequent is moved to the conclusion or denial side as the premise of the conditional (if **B** then **C**). A shorter (and less complete) way of stating the rule of conditional denial is to say that *if it's incoherent to assert **B** and deny **C**, then it's incoherent to deny (if **B** then **C**).*

6. **Conditional assertion.** Suppose (**A1**,...,**An** entails **B**, **C1**,...,**Cm**) is a valid sequent and (**D1**,...,**Dk**, **E** entails **F1**,...,**Fj**) is a valid sequent. Then (**A1**,...,**An**, **D1**,...,**Dk**, (if **B** then **E**) entails **C1**,...,**Cm**, **F1**,...,**Fj**) is a valid sequent. A shorter (and less complete) way of stating the rule of conditional assertion is to say that *if it's incoherent to assert **E** and deny **B**, then it's incoherent to assert (if **B** then **E**).* This is one of the less intuitive rules of this presentation of classical logic. I will have more to say about it later.

**Negation rules**

The following rules in classical logic are related to negation ("not").

7. **Negation assertion.** Suppose (**A1**,...,**An** entails **B**, **C1**,...,**Cm**) is a valid sequent. Then (**A1**,...,**An**, (not **B**) entails **C1**,...,**Cm**) is a valid sequent. In this rule, the denial of **B** is transformed to an assertion of (not **B**). A shorter (and less complete) way of stating the rule of negation assertion is to say that *if it's incoherent to deny **B**, then it's incoherent to assert (not **B**).*

8. **Negation denial.** Suppose (**A1**,...,**An**, **B** entails **C1**,...,**Cm**) is a valid sequent. Then (**A1**,...,**An** entails (not **B**), **C1**,...,**Cm**) is a valid sequent. In this rule, the assertion of **B** is transformed to a denial of (not **B**). A shorter (and less complete) way of stating the rule of negation denial is to say that *if it's incoherent to assert **B** then it's incoherent to deny (not **B**).*

**Universal quantifier rules**

The following rules in classical logic are related the universal quantifier ("for all"). Stating these rules requires introducing a new notation. For any statement **A**, any variable name **x**, and any object term **t**, let **A**[**x** -> **t**] denote the statement resulting from replacing all instances of **x** in **A** with **t**.

9. **Counterexample.** Suppose (**A1**,...,**An**, **B**[**x** -> **t**] entails **C1**,...,**Cn**) is a valid sequent. Then (**A1**,...,**An**, (for all **x**, **B**) entails **C1**,...,**Cn**) is a valid sequent. The rule of counterexample states that if it is incoherent to assert **B** for one specific possible value of **x** (denoted by **t**), then it is incoherent to assert the universal generalization (for all **x**, **B**). In short, *it is incoherent to assert any universal generalization that has a counterexample.*

10. **Universal generalization.** Suppose (**A1**,...,**An** entails **B**[**x** -> **y**], **C1**,...,**Cn**) is a valid sequent, and that **y** does not occur as a free variable in any of the statements **A1**,...,**An**, **C1**,...,**Cn**. Then (**A1**,...,**An** entails (for all **x**, **B**), **C1**,...,**Cn**) is a valid sequent. The assumption that **y** does not occur as a free variable in any of the side premises **A1**,...,**An**, **C1**,...,**Cn** is a way of capturing the idea that **y** is a variable that could potentially refer to any object. The rule of universal generalization states in essence that *if it is incoherent to deny **B** for an arbitrary object, then it is incoherent to deny (for all **x**, **B**).*

**Existential quantifier rules**

The following rules in classical logic are related to the existential quantifier ("for some"). 

11. **Non-existence generalization.** Suppose (**A1**,...,**An**, **B**[**x** -> **y**] entails **C1**,...,**Cm**) is a valid sequent, and that **y** does not occur as a free variable in any of the statements **A1**,...,**An**, **C1**,...,**Cm**. Then (**A1**,...,**An**, (for some **x**, **B**) entails **C1**,...,**Cn**) is a valid sequent. The assumption that **f** does not occur as a free variable in any of the side premises **A1**,...,**An**, **C1**,...,**Cm** is a way of capturing the idea that **y** is a variable that could potentially refer to any object. The rule of non-existence generalization states in essence that *if it is inchoherent to assert **B** for an arbitrary object, then it is incoherent to assert (for some **x**, **B**).

12. **Example.** Suppose (**A1**,...,**An** entails **B**[**x** -> **t**], **C1**,...,**Cm**) is a valid sequent. Then (**A1**,...,**An** entails (for some **x**, **B**), **C1**,...,**Cm**) is a valid sequent. The rule of example states in essence that *if it is incoherent to deny **B** for some specific object, then it is incoherent to deny (for some **x**, **B**).*

**Structural rules**

The structural rules in classical logic are rules of inference that tell us that manipulating the structure of valid sequents in certain ways always yields other valid sequents. In summary, these rules tell us two things. First, that we can add premises and conclusions to a valid sequent to get another valid sequent; this is because adding more assertions or denials to an incoherent set of assertions or denials will never make it coherent. Second, that order and repetition of the assertions and denials does not matter for coherence.

The following are the structural rules of classical logic.

13. **Strengthening.** Suppose (**A1**,...,**An** entails **C1**,...,**Cm**) is a valid sequent. Then for any statement **B**, (**A1**,...,**An**, **B** entails **C1**,...,**Cm**) is a valid sequent, and (**A1**,...,**An** entails **B**, **C1**,...,**Cm**) is a valid sequent. The rule of strengthening states in essence that *if your position is incoherent, then your position is still incoherent if you strengthen it by asserting **B** or denying **B**.* This rule is called "weakening" in most other presentations of classical logic.

12. **Assertion contraction.** Suppose (**A1**,...,**An**, **B**, **B** entails **C1**,...,**Cm**) is a valid sequent. Then (**A1**,...,**An**, **B** entails **C1**,...,**Cm**) is a valid sequent. The rule of assertion contraction states in essence that *if a position is incoherent and asserts **B** more than one time, then it is still incoherent if asserts **B** one less time.*

13. **Denial contraction.** Suppose (**A1**,...,**An** entails **B**, **B**, **C1**,...,**Cm**) is a valid sequent. Then (**A1**,...,**An** entails **B**, **C1**,...,**Cm**) is a valid sequent. The rule of denial contraction states in essence that *if a position is incoherent and denies **B** more than once, then it is still incoherent if it denies **B** one less time.*

From the rules of strengthening, assertion contraction, and denial contraction, it follows that the number of times you assert or deny a statement does not matter for the coherence of your position. To arrive at this conclusion one also needs to use the rules of assertion permutation and denial permutation.

13. **Assertion permutation.** Suppose (**A1**,...,**An**, **B**, **C**, **D1**,...,**Dm** entails **E1**,...,**Ek**) is a valid sequent. Then (**A1**,...,**An**, **C**, **B**, **D1**,...,**Dm** entails **E1**,...,**Ek**). What changes between the "suppose" sequent and the "then" sequent is that the order of **B**, **C** is swapped to produce **C**, **B**. The rule of assertion permutation states in essence that *if a position is incoherent, then it's still incoherent after swapping the order of two assertions.*

14. **Denial permutation.** Suppose (**A1**,...,**An** entails **B1**,...,**Bm**, **C**, **D**, **E1**,...,**Ek**) is a valid sequent. Then (**A1**,...,**An** entails **B1**,...,**Bm**, **D**, **C**, **E1**,...,**Ek**) is a valid sequent. What changes between the "suppose" sequent and the "then" sequent is that the order of **C**, **D** is swapped to produce **D**, **C**. The rule of denial permutation states in essence that *if a position is incoherent, then it's still incoherent after swapping the order of two denials.*

From the rules of assertion permutation and denial permutation, it follows in generality that *the order of assertions and denials does not matter for coherence.* From all the structural rules together, it follows in generality that *the order and repetition of assertions and denials do not matter for coherence.*

The final structural rule in our presentation is the rule of **cut**. This rule is redundant; [Gentzen's cut elimination theorem](https://en.wikipedia.org/wiki/Cut-elimination_theorem) shows that any sequent that is valid in classical logic can be shown to be valid using just the 14 rules we have listed so far, without using rule 15, the cut rule. However, sequent derivations not using the cut rule will tend to be much longer than derivations using the cut rule.

15. **Cut.** Suppose that (**A1**,...,**An** entails **B1**,...,**Bm**, **C**) is a valid sequent, and that (**C**, **D1**,...,**Dk** entails **E1**,...,**Ek**) is a valid sequent. Then (**A1**,...,**An**, **D1**,...,**Dk** entails **B1**,...,**Bm**, **E1**,...,**Ek**) is a valid sequent. The cut rule is so named because the rule lets us combine two valid sequents, one with **C** in the conclusions and one with **C** in the premises, while cutting **C** out of the picture. The rule of cut states in essence that *if it's incoherent for you to assert **C** and it's incoherent for you to deny **C**, then your position is incoherent.*

That completes my presentation of the rules of classical first order logic. For another presentation which is more compact and easier to survey, see [Wikipedia's presentation of the LK sequent calculus](https://en.wikipedia.org/wiki/Sequent_calculus#The_system_LK). 

As I have stated before, it is a matter of controversy among logicians whether all the rules of classical logic are correct in all contexts. Before we survey that very intricate debate, I would like to explain how these rules can be used.

Each of these rules states a very basic principle about what kinds of sets of assertions and denials are incoherent. Most of them are so obvious as to appear trivial, perhaps trivial to the extent of near-pointlessness. The reason that rules of logic are useful and allow us to arrive at surprising, non-obvious conclusions is that this can be accomplished by chaining together long sequences of applications of rules of logic.

The most impressive example of the usefulness of logic is in math. Every mathematical statement that is true according to the consensus of mathematics can be arrived at by applying the rules of first order logic we have presented to derive progressively more conclusions from a set of basic axioms, such as the widely accepted axioms of [Zermelo-Fraenkel set theory](https://en.wikipedia.org/wiki/Zermelo%E2%80%93Fraenkel_set_theory). Higher mathematicians build ever more complex towers of thought, exploring an infinite space of true mathematical thoughts; this exploration can be continued indefinitely without ever needing to assume more axioms.

Logic is also indispensable in philosophy, and in any area of serious, truth-seeking human thought. The rules of logic are the most reliable generally accepted principles of reasoning that humans have.

The reason rules of logic are useful is that they can be chained together to form interesting arguments. Let's examine how this is done in the case of classical first-order logic as I have presented it.

Consider the following classic argument. Socrates is a man, and all men are mortal; therefore, Socrates is mortal. We can symbolize this argument as a sequent as follows: (Socrates is a man, (for all *x*, (if *x* is a man then *x* is mortal)) entails (Socrates is mortal)). This is a valid sequent/argument. Let's see how we can prove its validity according to the rules of classical logic.

1. The rule of non-contradiction implies that this is a valid sequent: ((Socrates is a man) entails (Socrates is a man)).
2. The rule of non-contradiction implies that this is a valid sequent: ((Socrates is mortal) entails (Socrates is mortal)).
3. The rule of conditional assertion and steps 1 and 2 imply that this is a valid sequent: ((Socrates is a man), (if (Socrates is a man) then (Socrates is mortal)) entails (Socrates is mortal)).
4. The rule of counterexample and step 3 imply that this is a valid sequent: ((Socrates is a man), (for all *x*, (if *x* is a man then *x* is mortal)) entails (Socrates is mortal)).

I will explain the thought process that I used to arrive at this proof, and unpack why the proof is correct.

In this presentation of classical logic, every proof that a sequent is valid must start by invoking the rule of non-contradiction. Recall that the rule of non-contradiction is the rule that for all statements **A**, the sequent (**A** entails **A**) is valid, or in other words it is incoherent to assert and deny a statement at the same time.

The rule of non-contradiction is the only rule we have which allows one to conclude that a sequent is valid without having previously concluded that some other sequent is valid. Except for the rule of non-contradiction, all of the rules we have are of the form "if one or more sequents of a given form are valid, then one or more related sequents of a different form are valid." To use the other rules besides non-contradiction, one must have some sequents that are valid already at hand. Originally they always come from the rule of non-contradiction. These considerations told me that for sure, my proof was going to start with an invocation of the rule of non-contradiction.

A useful technique for constructing proofs that sequents are valid is to try to work backwards from the desired conclusion to the beginning of the proof. In this case, the desired conclusion is that ((Socrates is a man), (for all *x*, (if *x* is a man then *x* is mortal)) entails (Socrates is mortal)).

The conclusion is a rather long first-order logic statement, and it contains details that are not necessary for the task at hand. We can simplify it and make it easier to work with by replacing the English phrases with symbols. We will symbolize the predicate "is a man" by the letter P. We will symbolize the predicate "is mortal" by the letter Q. And we will symbolize the object term "Socrates" by the letter a. Then our desired conclusion becomes: (Pa, (for all *x*, (if P*x* then Q*x*)) entails Qa). This is a little more surveyable.

Notice that, with the exceptions of non-contradiction and cut, all of the rules of our system build more complex statements out of simpler statements. For instance, rule 2, assertion strengthening, lets us go from **A** to (**A** and **D**) or (**D** and **A**). Rule 8, negation denial, lets us go from assertion of **A** to denial of (not **A**). Each rule of our system (with the exceptions of non-contradiction and cut) builds one new statement with one new logical connective that wasn't there in the premises of the rule.

We would like to start working backwards towards the completion of our proof by finding one or more valid sequents which let us derive the conclusion in one step, applying one rule of our system. Because of what our rules do, our objective is to find premises which let us build the outermost logical connective of one of the statements in our conclusion.

In this case we have only one option. We must attempt to build the "for all" quantifier in the statement (for all *x*, (if P*x* then Q*x*)). This is the only statement in our conclusion sequent that has any logical connectives to build.

We know that the rule we need employ is one of the universal quantifier rules. Specifically, it must be whichever of the two rules can be applied to produce assertions, since in this sequent (for all *x*, (if P*x* then Q*x*)) is an assertion. Therefore the rule we need to employ is the rule of counterexample. This tells us that the second to last step in our proof should be to derive a sequent of the form (**A1**,...,**An**, **B**[**x** -> **t**] entails **C1**,...,**Cn**), which the rule of counterexample will turn into the desired conclusion sequent, namely: (Pa, (for all *x*, (if P*x* then Q*x*)) entails Qa). 

Let's find that by matching our conclusion sequent against the form of the conclusion of the rule of counterexample. The form of the conclusion of the rule of counterexample is (**A1**,...,**An**, (for all **x**, **B**) entails **C1**,...,**Cn**). Our desired conclusion instantiates this form as follows:

* **A1**,...,**An** = Pa
* **x** = *x*
* **B** = (if P*x* then Q*x*)
* **C1**,...,**Cn** = Qa

(The interesting equation **x** = *x* expresses that the meta-variable **x** is instantiated to the variable *x*.)

Substituting these variables into the form of the premise of the rule of counterexample, we can say that our premise should be of the form:

(Pa, (if P**t** then Q**t**) entails Qa)

for some object term **t**. **t** is the only variable that's in the premise form of the rule of counterexample and not in the conclusion form. We need to pick a value for **t**. A sensible guess would be to pick **t** = a. As we will now see, this choice works out and lets us complete the proof.

The final step of the proof we are constructing is to invoke the rule of counterexample to go from the validity of (Pa, (if Pa then Qa) entails Qa) to the validity of (Pa, (for all *x*, (if P*x* then Q*x*)) entails Qa). (Pa, (if Pa then Qa) entails Qa) is indeed a valid sequent, as some reflection should show. In order to complete our proof, we have to prove that it is a valid sequent. We will do this by continuing to work backwards, now trying to find a step that will let us arrive at (Pa, (if Pa then Qa) entails Qa).

Our goal in this step should be to build one of the logical connectives in our goal sequent. There is only one choice: we need to build the "if/then" of the statement (if Pa then Qa). This tells us that we need to use one of the conditional rules: whichever one lets us build an assertion, since (if Pa then Qa) is an assertion in our goal sequent. Thus we need to use rule 6, the rule of conditional assertion.

The rule of conditional assertion reads as follows. 

Suppose (**A1**,...,**An** entails **B**, **C1**,...,**Cm**) is a valid sequent and (**D1**,...,**Dk**, **E** entails **F1**,...,**Fj**) is a valid sequent. Then (**A1**,...,**An**, **D1**,...,**Dk**, (if **B** then **E**) entails **C1**,...,**Cm**, **F1**,...,**Fj**) is a valid sequent.

We can match our goal sequent against the form of the conclusion sequent as follows:

* **A1**,...,**An**, **D1**,...,**Dk** = Pa
* **B** = Pa
* **E** = Qa
* **C1**,...,**Cm**, **F1**,...,**Fj** = Qa

We need to produce two premise sequents which the rule of conditional assertion will turn into our goal sequent. One of them will contain the assertions **A1**,...,**An** and the denials **C1**,...,**Cm**. The other will contain the assertions **D1**,...,**Dk** and the denials **F1**,...,**Fj**. In this case, we know that the combined sequence of assertions **A1**,...,**An**, **D1**,...,**Dk** is equal to the one-element sequence containing just "Pa." So Pa goes into either the **A** sequence or the **D** sequence, but we need to decide which. Similarly, Qa goes into either the **C** sequence or the **F** sequence, but we need to decide which.

Let's set that issue aside for the moment and state what we know about the forms our premises need to have. We are settled that **B** = Pa and **E** = Qa, so we can write our needed premises in this way:

* (**A1**,...,**An** entails Pa, **C1**,...,**Cm**)
* (**D1**,...,**Dk**, Qa entails **F1**,...,**Fj**)

Should Pa go into the **A** sequence or the **D** sequence? Should Qa go into the **C** sequence or the **F** sequence? If we put Pa in the **A** sequence and Qa in the **F** sequence, then both our premises become instances of the rule of non-contradiction:

* (Pa entails Pa)
* (Qa entails Qa)

So that is what we should do, and we have reached the beginning of our proof. Let's now write out the steps in forwards order instead of backwards order:

1. (Pa entails Pa) is valid, by the law of non-contradiction.
2. (Qa entails Qa) is valid, by the law of non-contradiction.
3. (Pa, (if Pa then Qa) entails Qa) is valid, by the law of conditional assertion and steps 1 and 2.
4. (Pa, (for all *x*, (if Pa then Qa)) entails Qa) is valid, by the law of counterexample and step 3.

Let's now write the finished version of the proof by substituting back the original English terms:

* P stands for "is a man."
* Q stands for "is mortal."
* a stands for "Socrates."

This gives us the following proof.

1. ((Socrates is a man) entails (Socrates is a man)) is valid, by the law of non-contradiction.
2. ((Socrates is mortal) entails (Socrates is mortal)) is valid, by the law of non-contradiction.
3. ((Socrates is a man), (if (Socrates is a man) then (Socrates is mortal)) entails (Socrates is mortal)) is valid, by the law of conditional assertion and steps 1 and 2.
4. ((Socrates is a man), (for all *x*, (if (*x* is a man) then (*x* is mortal))) entails (Socrates is mortal)) is valid, by the law of counterexample and step 3.

To sum up, the classic argument we have analyzed is valid according to classical logic. Given that Socrates is a man and all men are mortal, it follows that Socrates is mortal. It is incoherent, according to classical logic, to assert that Socrates is a man and all men are mortal while denying that Socrates is mortal.

The basic proof construction techniques that we have introduced in the context of this argument can be applied to construct arbitrarily complex proofs of the validity of valid first-order logic sequents. To go deeper into this topic, I refer you to the exercises. TODO: exercises

That completes our introduction to how to use the rules of classical first-order logic. We can use the rules of logic to establish that sets of assertions and denials are incoherent. The rules of classical logic generate an infinite set of valid sequents which describe what sets of assertions and denials are incoherent according to classical logic.

We went into our discussion of classical logic saying that we wanted to discover what rules of logical inference are valid. Rules of logical inference let us go from premises that are warranted assertible in a given context to conclusions that are (by the rule of inference) also warranted assertible in the context. We ended up with something slightly different: we got a system of rules telling us what sets of assertions and denials are incoherent. Let's see how we get back to the topic of rules of logical inference.

A rule of logical inference can also be called an argument form. For our purposes we can equate rules of inference or argument forms with single-conclusion sequents possibly containing meta-variables. Recall that the result of instantiating the meta-variables in an argument form is called a "case." 

Recall that I call an argument form "valid" for a given person when it lacks counterexamples for that person. A counterexample to an argument form for a given person is a (hypothetical or real) truth-seeking debate context and a case of the argument form where they consider the premises warranted assertible and don't consider the conclusion warranted assertible. Recall also that I call an argument form simply "valid" if it is valid for people in general.

We can call an argument form "valid according to classical logic" when every instance of the argument form is valid (as a sequent) according to the rules of classical logic.

Empirically, our psychological notion of validity coincides well (but not perfectly) with the classical logic notion of validity for most people, and the more concrete the problem domain is, the more this tends to be so. In other words, especially in concrete problem domains, it tends to be the case that an argument form is valid for people in general if and only if all instances of that argument form are valid according to the rules of classical logic. However, there are definite counterexamples to this tendency.

Here is one reason one might doubt the closeness of the connection I have stated between the psychological and classical logic notions of validity. One might ask, if it is incoherent to deny a conclusion in a given context, does it follow that it is warranted to assert the conclusion in that context? When a sequent is valid according to classical logic, classical logic tells us it is incoherent to deny the conclusion in contexts where the premises are held true. When an argument form is valid in the psychological sense, people consider the conclusion warranted assertible in contexts where the premises are held true (and thus warranted assertible).

So then, if it's incoherent to deny a statement in a given context given premises that are held true in that context, then is it warranted to assert it? Not always. For example, if the premises that are held true in the context are incoherent, then any additional assertions or denials will be incoherent (because adding more to an incoherent position gives you an incoherent position). But it is not warranted to assert anything at all in an incoherent position.

Let us then restrict our attention to contexts where the premises held true in the context are, taken together, coherent (i.e. not incoherent according to classical logic). In such contexts, if a statement is incoherent to deny, is it warranted to assert it? Perhaps not, as it might be incoherent to deny the statement and yet there might be a social taboo/norm of some kind prohibiting one from asserting it. Let's set aside this possibility as well. Are there any other reasonable, significant ways that a statement can be incoherent to deny and yet not warranted to assert? 

Yes, there are. Suppose I have a position that is not incoherent according to classical logic. Suppose my position makes it incoherent for me to deny **P**, and that I just learned this. Suppose **P** is such a shocking, implausible statement to me that I think it's probably false. I might not consider it warranted for me to assert **P**, because I might think that the fact that my position makes it incoherent for me to deny **P** means that there is something wrong in my position. As such I might consider it unwarranted for me to assert **P** but incumbent upon me to re-evaluate the assertions and denials in my position.

A sequent (**A1**,...,**An** entails **B**) states that is incoherent to assert **A1**,...,**An** and deny **B**. Even if somebody accepts all the rules of classical logic as applied to the case, and if they believe all of **A1**,...,**An** the validity of such a sequent cannot compel them to accept **B** as true, as they always have the option of rejecting one or more of **A1**,...,**An** instead of accepting **B**.

This reflects a broader truth about logical arguments in general. Logical arguments always proceed from premises to conclusions, but they never compel the reader to accept their conclusions. Logical arguments always cut two ways: they can compel the reader either to accept their conclusions or to reject some of their premises.

Logic is able to tell us that certain positions are incoherent. This is about all it can do. It can't tell us which of the many logically coherent sets of statements we should believe, disbelieve, assert, deny, hold to be true in a given context, hold to be false in a given context, etc.

I started out this section by presenting a one-directional notion of rules of logical inference, according to which rules of logical inference let us pass from true, warranted assertible statements to other true, warranted assertible statements. Our inquiry has shown us that this is an incomplete picture of how logic works. Every person who accepts the rules of logic and reads a logical argument has two options: to accept the conclusion or to reject one or more of the premises. In real debates logic is not necessarily used simply to pass from truth to truth. Instead, logic constrains humans to bounce about as they will in the space of logically coherent positions. In practice, of course, humans often find themselves in logically incoherent positions; it may take them a long time to notice that; and they may never notice.

Let us now return to the question we keep coming back to. Suppose that (**A1**,...,**An** entails **B**) is a valid sequent according to classical logic. Suppose that I accept the rules of classical logic. Suppose **A1**,...,**An** is a coherent set of assertions (or in other words that it is not incoherent according to classical logic, or in other words that (**A1**,...,**An** entails) is not a valid sequent (empty sequence of statements after "entails" intended)). Suppose that I accept all of **A1**,...,**An** as true and that for the purposes of this question I am not going to back down from any of these premises. Suppose that in the context under question I am not prohibited from asserting **B** by any social taboos/norms. It is incoherent for me to deny **B**. Is it therefore warranted for me to assert **B**? 

Now, finally, the answer seems to me to be "yes;" at least, I am unaware of any further qualifiers that need to be added. However, it does not follow from the rules we have already stated about classical logic that in these circumstances it is warranted for me to assert **B**. Rather, this seems to be an additional principle about classical logic:

16. **Law of inference.** Suppose (**A1**,...,**An** entails **B**) is a valid sequent. Suppose **A1**,...,**An** is coherent according to classical logic. Suppose it is warranted to assert **A1**,...,**An** in a given context. Then either it is warranted to assert **B** in the given context, or re-examination of the warrant to assert **A1**,...,**An** is warranted.

This is a restatement in the form of a rule of the question posed three paragraphs above. We have removed the qualifier that asserting **B** is not prohibited by any social taboos/norms. Any context where this would be a blocker to assertion is not a context where the rules of classical logic hold sway. Now we are truly finished going through the rules of classical logic.

Along the way through stating the rules of classical logic and describing how to use them, we have assembled a truly impressive series of qualifiers and disclaimers about the rules of classical logic.

Yet, we have not yet scratched the surface of the debates about what specific rules of logic are correct. Classical logic represents the dominant point of view about rules of logic are correct; but there are competing sets of rules for logic, so called **non-classical logics**, which are intended to address perceived deficiencies of classical logic.

In almost every case, non-classical logics are sets of rules which are *weaker* than the rules of classical logic, in the sense that the set of sets of assertions and denials that a non-classical logic counts as incoherent is typically a strict subset of the set of sets of assertions and denials that classical logic counts as incoherent.

How correct are the rules of classical logic? Given the complexity of the rules themselves and the trouble that has been involved in describing them, this may appear to be a difficult question. It is. Let's get started.

I will start by presenting the best argument I can to the effect that the rules of classical logic *are* correct.

Correct in what sense? The argument I will present can be adapted to argue that the rules of classical logic are correct in a variety of different senses. At the end of the argument I will discuss some of the senses of correctness that the argument can be said to demonstrate of the rules of classical logic.

Correct in what context? Rules are always correct or incorrect relative to some context; so, for what contexts should I argue the rules of classical logic are correct? For this argument I won't have any particular context in mind. The argument can be applied to any particular context to see how well it holds up in that context.

This argument is not in essence original to me, though some details are. In most respects this argument is part of the folk literature on logic. An example of a published presentation of a similar argument can be found in TODO.

The first step in the argument is to introduce the notion of **model theory**. Model theory is a mathematical theory which describes how to apply an interpretation to a statement of first-order logic.

TODO

## Fallacies

## Biases

## Induction

## Probability

## Statistics

## Beliefs

## Persuasion

## Paradoxes

## Foundations of math

## Faith
